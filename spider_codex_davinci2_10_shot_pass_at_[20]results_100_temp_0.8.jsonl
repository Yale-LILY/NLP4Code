[
  {
    "example": {
      "db_id": "department_store",
      "query": "SELECT T1.address_details FROM addresses AS T1 JOIN customer_addresses AS T2 ON T1.address_id  =  T2.address_id WHERE T2.customer_id  =  10",
      "query_toks": [
        "SELECT",
        "T1.address_details",
        "FROM",
        "addresses",
        "AS",
        "T1",
        "JOIN",
        "customer_addresses",
        "AS",
        "T2",
        "ON",
        "T1.address_id",
        "=",
        "T2.address_id",
        "WHERE",
        "T2.customer_id",
        "=",
        "10"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "address_details",
        "from",
        "addresses",
        "as",
        "t1",
        "join",
        "customer_addresses",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "address_id",
        "=",
        "t2",
        ".",
        "address_id",
        "where",
        "t2",
        ".",
        "customer_id",
        "=",
        "value"
      ],
      "question": "What is the address for the customer with id 10?",
      "question_toks": [
        "What",
        "is",
        "the",
        "address",
        "for",
        "the",
        "customer",
        "with",
        "id",
        "10",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              7
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                27,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                26,
                false
              ],
              null
            ],
            10.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "address_details"
        ],
        "Staff": [
          "staff_id",
          "staff_gender",
          "staff_name"
        ],
        "Suppliers": [
          "supplier_id",
          "supplier_name",
          "supplier_phone"
        ],
        "Department_Store_Chain": [
          "dept_store_chain_id",
          "dept_store_chain_name"
        ],
        "Customers": [
          "customer_id",
          "payment_method_code",
          "customer_code",
          "customer_name",
          "customer_address",
          "customer_phone",
          "customer_email"
        ],
        "Products": [
          "product_id",
          "product_type_code",
          "product_name",
          "product_price"
        ],
        "Supplier_Addresses": [
          "supplier_id",
          "address_id",
          "date_from",
          "date_to"
        ],
        "Customer_Addresses": [
          "customer_id",
          "address_id",
          "date_from",
          "date_to"
        ],
        "Customer_Orders": [
          "order_id",
          "customer_id",
          "order_status_code",
          "order_date"
        ],
        "Department_Stores": [
          "dept_store_id",
          "dept_store_chain_id",
          "store_name",
          "store_address",
          "store_phone",
          "store_email"
        ],
        "Departments": [
          "department_id",
          "dept_store_id",
          "department_name"
        ],
        "Order_Items": [
          "order_item_id",
          "order_id",
          "product_id"
        ],
        "Product_Suppliers": [
          "product_id",
          "supplier_id",
          "date_supplied_from",
          "date_supplied_to",
          "total_amount_purchased",
          "total_value_purchased"
        ],
        "Staff_Department_Assignments": [
          "staff_id",
          "department_id",
          "date_assigned_from",
          "job_title_code",
          "date_assigned_to"
        ]
      },
      "answer": [
        [
          "36594 O'Keefe Lock\nNew Cali, RI 42319"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Addresses, Customer_Addresses, on = 'address_id')\nt2 = t1[t1['customer_id'] == 10]\nanswer = t2['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nt2 = t1[t1['customer_id'] == 10]\nanswer = t2['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nt2 = t1[t1['customer_id'] == 10]\nanswer = t2['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nt2 = t1[t1['customer_id'] == 10]\nanswer = t2['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "\nt1 = pd.merge(Addresses, Customer_Addresses, on='address_id')\nt2 = t1[t1['customer_id'] == 10]\nanswer = t2['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nanswer = t1[t1['customer_id'] == 10]['address_details']",
      "t1 = pd.merge(Addresses, Customer_Addresses, left_on='address_id', right_on='address_id')\nt2 = t1[t1['customer_id'] == 10]['address_details']\nanswer = t2.unique()"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "products_gen_characteristics",
      "query": "SELECT count(*) FROM products WHERE product_category_code  =  \"Seeds\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "products",
        "WHERE",
        "product_category_code",
        "=",
        "``",
        "Seeds",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "products",
        "where",
        "product_category_code",
        "=",
        "value"
      ],
      "question": "Count the number of products in the category 'Seeds'.",
      "question_toks": [
        "Count",
        "the",
        "number",
        "of",
        "products",
        "in",
        "the",
        "category",
        "'Seeds",
        "'",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                15,
                false
              ],
              null
            ],
            "\"Seeds\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Characteristic_Types": [
          "characteristic_type_code",
          "characteristic_type_description"
        ],
        "Ref_Colors": [
          "color_code",
          "color_description"
        ],
        "Ref_Product_Categories": [
          "product_category_code",
          "product_category_description",
          "unit_of_measure"
        ],
        "Characteristics": [
          "characteristic_id",
          "characteristic_type_code",
          "characteristic_data_type",
          "characteristic_name",
          "other_characteristic_details"
        ],
        "Products": [
          "product_id",
          "color_code",
          "product_category_code",
          "product_name",
          "typical_buying_price",
          "typical_selling_price",
          "product_description",
          "other_product_details"
        ],
        "Product_Characteristics": [
          "product_id",
          "characteristic_id",
          "product_characteristic_value"
        ]
      },
      "answer": [
        [
          5
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, left_on='product_category_code', right_on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = pd.Series(t1[t1['product_name'] == 'Seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nt2 = t1[t1['product_category_description'] == 'Seeds']\nanswer = pd.Series(t2.shape[0])",
      "answer = Products[Products['product_category_code'] == 'seeds'].shape[0]",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, left_on='product_category_code', right_on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'Seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nt2 = t1['product_category_code'] == 'Seeds'\nanswer = pd.Series(t2.sum())",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds']['product_id'].nunique())",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "answer = len(Products[Products['product_category_code'] == 'seeds'].index)",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = pd.Series(t1[t1['product_category_description'] == 'Seeds'].shape[0])",
      "answer = pd.Series(Products[Products['product_category_code'] == 'seeds'].shape[0])",
      "t1 = pd.merge(Products, Ref_Product_Categories, on='product_category_code')\nanswer = t1[t1['product_category_description'] == 'Seeds'].shape[0]"
    ],
    "acc@20": 10,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "manufactory_1",
      "query": "SELECT count(*) FROM manufacturers WHERE founder  =  'Andy'",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "manufacturers",
        "WHERE",
        "founder",
        "=",
        "'Andy",
        "'"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "manufacturers",
        "where",
        "founder",
        "=",
        "value"
      ],
      "question": "How many companies were created by Andy?",
      "question_toks": [
        "How",
        "many",
        "companies",
        "were",
        "created",
        "by",
        "Andy",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                4,
                false
              ],
              null
            ],
            "\"Andy\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Manufacturers": [
          "Code",
          "Name",
          "Headquarter",
          "Founder",
          "Revenue"
        ],
        "Products": [
          "Code",
          "Name",
          "Price",
          "Manufacturer"
        ]
      },
      "answer": [
        [
          1
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'].str.contains('andy')].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'Andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'Andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'Andy'].shape[0])",
      "answer = pd.Series(len(Manufacturers[Manufacturers['founder'] == 'Andy']))",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'Andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'andy'].shape[0])",
      "answer = pd.Series(Manufacturers[Manufacturers['founder'] == 'Andy'].shape[0])"
    ],
    "acc@20": 6,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT billing_country ,  AVG(total) FROM invoices GROUP BY billing_country ORDER BY AVG(total) DESC LIMIT 10;",
      "query_toks": [
        "SELECT",
        "billing_country",
        ",",
        "AVG",
        "(",
        "total",
        ")",
        "FROM",
        "invoices",
        "GROUP",
        "BY",
        "billing_country",
        "ORDER",
        "BY",
        "AVG",
        "(",
        "total",
        ")",
        "DESC",
        "LIMIT",
        "10",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "billing_country",
        ",",
        "avg",
        "(",
        "total",
        ")",
        "from",
        "invoices",
        "group",
        "by",
        "billing_country",
        "order",
        "by",
        "avg",
        "(",
        "total",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "A list of the top 10 countries by average invoice size. List country name and average invoice size.",
      "question_toks": [
        "A",
        "list",
        "of",
        "the",
        "top",
        "10",
        "countries",
        "by",
        "average",
        "invoice",
        "size",
        ".",
        "List",
        "country",
        "name",
        "and",
        "average",
        "invoice",
        "size",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              6
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  44,
                  false
                ],
                null
              ]
            ],
            [
              5,
              [
                0,
                [
                  0,
                  46,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            44,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                5,
                46,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 10,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "Chile",
          6.659999999999999
        ],
        [
          "Ireland",
          6.517142857142857
        ],
        [
          "Hungary",
          6.517142857142857
        ],
        [
          "Czech Republic",
          6.445714285714287
        ],
        [
          "Austria",
          6.088571428571428
        ],
        [
          "Finland",
          5.945714285714287
        ],
        [
          "Netherlands",
          5.8028571428571425
        ],
        [
          "India",
          5.789230769230769
        ],
        [
          "USA",
          5.747912087912091
        ],
        [
          "Norway",
          5.659999999999999
        ]
      ]
    },
    "generated_programs": [
      "t1 = invoices.groupby('billing_country').sum()['total'].rename('total')\nt2 = invoices.groupby('billing_country').size().rename('count')\nt3 = pd.concat([t1, t2], axis = 1)\nt3['avg'] = t3['total'] / t3['count']\nt4 = t3['avg'].sort_values(ascending = False).head(10).to_frame().reset_index()\nanswer = t4[['billing_country', 'avg']]",
      "t1 = invoices.groupby('billing_country').sum()['total'].rename('total')\nanswer = t1.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, left_on='customer_id', right_on='id')\nt2 = t1.groupby('billing_country').agg({'total':'mean'})\nanswer = t2.sort_values('total', ascending=False).head(10).reset_index()",
      "t1 = invoices.groupby('billing_country').agg({'total': 'mean'}).rename(columns={'total': 'avg'})\nanswer = t1.sort_values('avg', ascending=False).head(10).reset_index()",
      "t1 = invoices.groupby('billing_country').mean()['total'].rename('average_invoice_size').reset_index()\nanswer = t1.sort_values('average_invoice_size', ascending=False).head(10)",
      "t1 = invoices.groupby('billing_country')['total'].agg('mean').rename('avg')\nanswer = t1[t1 > 0].sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = invoices.groupby('billing_country').mean().rename(columns={'total': 'avg'})\nanswer = t1.sort_values('avg', ascending=False).head(10).reset_index()[['billing_country', 'avg']]",
      "temp_a = pd.merge(invoices, customers, on='customer_id')\ntemp_b = temp_a.groupby('billing_country').mean().sort_values('total', ascending=False).head(10).reset_index()\nanswer = temp_b[['billing_country', 'total']]",
      "t1 = invoices[['billing_country', 'total']].groupby('billing_country').mean().rename('avg_total')\nanswer = t1.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = invoices.groupby('billing_country').aggregate({'total': 'mean'})\nanswer = t1.nlargest(10, 'total').reset_index()",
      "df_country_avg = invoices.groupby('billing_country').mean().reset_index()\nanswer = df_country_avg.sort_values('total', ascending = False).head(10)[['billing_country', 'total']]",
      "t1 = invoices.groupby('billing_country')['total'].agg(['mean', 'count']).rename(columns={\"mean\": 'avg', 'count': 'count'})\nanswer = t1.sort_values('avg', ascending=False).head(10).reset_index()",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby('billing_country').mean()['total'].rename('avg_total_by_country').to_frame()\nanswer = t2.sort_values('avg_total_by_country', ascending=False).head(10).reset_index()",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = invoices.groupby('billing_country').sum().rename(columns={'total':'sum'})\nt3 = t1.to_frame().join(t2)\nt4 = t3['sum'] / t3['count']\nanswer = t4.to_frame().rename(columns={0:'average'}).reset_index().sort_values('average', ascending=False).head(10)",
      "t1 = invoices.groupby('billing_country').agg({'total': 'mean'})\nanswer = t1.rename(columns={'total':'avg_total'}).sort_values('avg_total', ascending = False).head(10)",
      "t1 = invoices.groupby('billing_country').mean().rename(columns={'total':'avg_invoice'})\nt2 = t1.sort_values('avg_invoice', ascending=False).head(10)\nanswer = t2.reset_index()[['billing_country', 'avg_invoice']]",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby('billing_country').mean().sort_values('total', ascending=False).head(10).reset_index()\nanswer = t2[['billing_country', 'total']]",
      "t1 = invoices[['billing_country', 'total']]\nt2 = t1.groupby('billing_country').mean().rename('average')\nanswer = t2.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby('billing_country').mean()['total'].rename('avg')\nanswer = t2.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby(['billing_country'])['total'].mean().rename('avg_invoices').to_frame().reset_index()\nanswer = t2.sort_values('avg_invoices', ascending=False).head(10)"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "insurance_and_eClaims",
      "query": "SELECT DISTINCT t2.customer_details FROM policies AS t1 JOIN customers AS t2 ON t1.customer_id  =  t2.customer_id WHERE t1.policy_type_code  =  \"Deputy\"",
      "query_toks": [
        "SELECT",
        "DISTINCT",
        "t2.customer_details",
        "FROM",
        "policies",
        "AS",
        "t1",
        "JOIN",
        "customers",
        "AS",
        "t2",
        "ON",
        "t1.customer_id",
        "=",
        "t2.customer_id",
        "WHERE",
        "t1.policy_type_code",
        "=",
        "``",
        "Deputy",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "distinct",
        "t2",
        ".",
        "customer_details",
        "from",
        "policies",
        "as",
        "t1",
        "join",
        "customers",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "customer_id",
        "=",
        "t2",
        ".",
        "customer_id",
        "where",
        "t1",
        ".",
        "policy_type_code",
        "=",
        "value"
      ],
      "question": "Which customers have an insurance policy with the type code \"Deputy\"? Give me the customer details.",
      "question_toks": [
        "Which",
        "customers",
        "have",
        "an",
        "insurance",
        "policy",
        "with",
        "the",
        "type",
        "code",
        "``",
        "Deputy",
        "''",
        "?",
        "Give",
        "me",
        "the",
        "customer",
        "details",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          true,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                7,
                false
              ],
              null
            ],
            "\"Deputy\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Customers": [
          "Customer_ID",
          "Customer_Details"
        ],
        "Staff": [
          "Staff_ID",
          "Staff_Details"
        ],
        "Policies": [
          "Policy_ID",
          "Customer_ID",
          "Policy_Type_Code",
          "Start_Date",
          "End_Date"
        ],
        "Claim_Headers": [
          "Claim_Header_ID",
          "Claim_Status_Code",
          "Claim_Type_Code",
          "Policy_ID",
          "Date_of_Claim",
          "Date_of_Settlement",
          "Amount_Claimed",
          "Amount_Piad"
        ],
        "Claims_Documents": [
          "Claim_ID",
          "Document_Type_Code",
          "Created_by_Staff_ID",
          "Created_Date"
        ],
        "Claims_Processing_Stages": [
          "Claim_Stage_ID",
          "Next_Claim_Stage_ID",
          "Claim_Status_Name",
          "Claim_Status_Description"
        ],
        "Claims_Processing": [
          "Claim_Processing_ID",
          "Claim_ID",
          "Claim_Outcome_Code",
          "Claim_Stage_ID",
          "Staff_ID"
        ]
      },
      "answer": [
        [
          "Buddy Marquardt"
        ],
        [
          "Selena Gerhold"
        ],
        [
          "Dr. Diana Rath"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].drop_duplicates()",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].drop_duplicates()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')[['policy_type_code', 'customer_details']]\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].drop_duplicates()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2[['customer_details']].drop_duplicates()",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy'].drop_duplicates('customer_details')\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy'][['customer_details']]\nt2.drop_duplicates(inplace=True)\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].unique()",
      "answer = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')[['customer_details']]",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['policy_type_code'] == 'Deputy']\nanswer = t2['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details'].unique()",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1[t1['policy_type_code'] == 'Deputy']['customer_details'].unique()"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT count(*) FROM customers WHERE city = \"Prague\";",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "customers",
        "WHERE",
        "city",
        "=",
        "``",
        "Prague",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "customers",
        "where",
        "city",
        "=",
        "value"
      ],
      "question": "How many customers live in Prague city?",
      "question_toks": [
        "How",
        "many",
        "customers",
        "live",
        "in",
        "Prague",
        "city",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                28,
                false
              ],
              null
            ],
            "\"Prague\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          2
        ]
      ],
      "pandas_converted": "pd.Series(customers[customers['city'] == 'Prague'].shape[0])"
    },
    "generated_programs": [
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = customers[customers['city'] == 'Prague'].shape[0]",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = customers[customers['city'] == 'Prague'].shape[0]",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = customers[customers['city'] == 'Prague'].shape[0]",
      "answer = pd.Series(customers[customers['city'] == 'Prague'].shape[0])",
      "answer = customers[customers[\"city\"] == \"Prague\"].count()[0]"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "browser_web",
      "query": "SELECT Operating_system ,  count(*) FROM web_client_accelerator GROUP BY Operating_system",
      "query_toks": [
        "SELECT",
        "Operating_system",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "web_client_accelerator",
        "GROUP",
        "BY",
        "Operating_system"
      ],
      "query_toks_no_value": [
        "select",
        "operating_system",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "web_client_accelerator",
        "group",
        "by",
        "operating_system"
      ],
      "question": "Find the number of web accelerators used for each Operating system.",
      "question_toks": [
        "Find",
        "the",
        "number",
        "of",
        "web",
        "accelerators",
        "used",
        "for",
        "each",
        "Operating",
        "system",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            3,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Web_client_accelerator": [
          "id",
          "name",
          "Operating_system",
          "Client",
          "Connection"
        ],
        "browser": [
          "id",
          "name",
          "market_share"
        ],
        "accelerator_compatible_browser": [
          "accelerator_id",
          "browser_id",
          "compatible_since_year"
        ]
      },
      "answer": [
        [
          "Android, Linux, Mac and Windows devices",
          1
        ],
        [
          "Any",
          1
        ],
        [
          "Any system with Java 1.6 VM available",
          1
        ],
        [
          "Appliance (Linux)",
          1
        ],
        [
          "Unix (Linux, *BSD, Mac OS X, others)",
          1
        ],
        [
          "Unix (Linux, *BSD, Mac OS X, others), Windows",
          2
        ],
        [
          "Windows",
          3
        ],
        [
          "Windows (2000 onwards)",
          1
        ],
        [
          "Windows, Linux, Mac OS, Symbian, WindowsMobile",
          1
        ],
        [
          "Windows, Mac",
          3
        ],
        [
          "Windows, Mac and Mobile devices",
          1
        ],
        [
          "Windows, Mac, Linux and Mobile devices",
          1
        ],
        [
          "Windows, Mac, Mobile devices",
          1
        ],
        [
          "Windows, except NT and 95",
          1
        ]
      ]
    },
    "generated_programs": [
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count').to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count').to_frame()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count')",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count').to_frame()",
      "t1 = Web_client_accelerator.groupby('operating_system').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Web_client_accelerator.groupby('operating_system').size()\nanswer = pd.DataFrame(t1).rename(columns = {0:'count'}).reset_index()",
      "answer = Web_client_accelerator.groupby('operating_system').size()",
      "answer = Web_client_accelerator.groupby('operating_system').size()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count').to_frame().reset_index()",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count')",
      "answer = Web_client_accelerator.groupby('operating_system').size().rename('count').reset_index()"
    ],
    "acc@20": 14,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "hospital_1",
      "query": "SELECT DISTINCT name FROM medication ORDER BY name",
      "query_toks": [
        "SELECT",
        "DISTINCT",
        "name",
        "FROM",
        "medication",
        "ORDER",
        "BY",
        "name"
      ],
      "query_toks_no_value": [
        "select",
        "distinct",
        "name",
        "from",
        "medication",
        "order",
        "by",
        "name"
      ],
      "question": "What is the alphabetically ordered list of all distinct medications?",
      "question_toks": [
        "What",
        "is",
        "the",
        "alphabetically",
        "ordered",
        "list",
        "of",
        "all",
        "distinct",
        "medications",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              8
            ]
          ],
          "conds": []
        },
        "select": [
          true,
          [
            [
              0,
              [
                0,
                [
                  0,
                  37,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                37,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Physician": [
          "EmployeeID",
          "Name",
          "Position",
          "SSN"
        ],
        "Department": [
          "DepartmentID",
          "Name",
          "Head"
        ],
        "Affiliated_With": [
          "Physician",
          "Department",
          "PrimaryAffiliation"
        ],
        "Procedures": [
          "Code",
          "Name",
          "Cost"
        ],
        "Trained_In": [
          "Physician",
          "Treatment",
          "CertificationDate",
          "CertificationExpires"
        ],
        "Patient": [
          "SSN",
          "Name",
          "Address",
          "Phone",
          "InsuranceID",
          "PCP"
        ],
        "Nurse": [
          "EmployeeID",
          "Name",
          "Position",
          "Registered",
          "SSN"
        ],
        "Appointment": [
          "AppointmentID",
          "Patient",
          "PrepNurse",
          "Physician",
          "Start",
          "End",
          "ExaminationRoom"
        ],
        "Medication": [
          "Code",
          "Name",
          "Brand",
          "Description"
        ],
        "Prescribes": [
          "Physician",
          "Patient",
          "Medication",
          "Date",
          "Appointment",
          "Dose"
        ],
        "Block": [
          "BlockFloor",
          "BlockCode"
        ],
        "Room": [
          "RoomNumber",
          "RoomType",
          "BlockFloor",
          "BlockCode",
          "Unavailable"
        ],
        "On_Call": [
          "Nurse",
          "BlockFloor",
          "BlockCode",
          "OnCallStart",
          "OnCallEnd"
        ],
        "Stay": [
          "StayID",
          "Patient",
          "Room",
          "StayStart",
          "StayEnd"
        ],
        "Undergoes": [
          "Patient",
          "Procedures",
          "Stay",
          "DateUndergoes",
          "Physician",
          "AssistingNurse"
        ]
      },
      "answer": [
        [
          "Awakin"
        ],
        [
          "Crescavitin"
        ],
        [
          "Melioraurin"
        ],
        [
          "Procrastin-X"
        ],
        [
          "Thesisin"
        ]
      ]
    },
    "generated_programs": [
      "answer = Medication[['name']].drop_duplicates();\nanswer.sort_values(['name'], inplace=True, ascending=True)",
      "answer = Medication['name'].unique()",
      "answer = Medication.sort_values('name')['name'].unique()",
      "answer = Medication[['name']].sort_values('name', ascending = False).drop_duplicates()",
      "answer = Medication[['name']].drop_duplicates().sort_values('name')",
      "answer = Medication['name'].unique()",
      "answer = pd.Series(Medication['name'].unique()).sort_values()",
      "answer = Medication['name'].unique()",
      "answer = pd.Series(sorted(Medication['name'].drop_duplicates()))",
      "answer = Medication['name'].drop_duplicates().sort_values().to_frame().reset_index(drop=True)",
      "answer = pd.Series(Medication['name'].unique()).sort_values()",
      "answer = Medication['name'].drop_duplicates().sort_values()",
      "answer = pd.Series(Medication['name'].sort_values().drop_duplicates())",
      "answer = Medication['name'].sort_values().unique()",
      "answer = pd.Series(Medication['name'].drop_duplicates().sort_values())",
      "answer = pd.Series(Medication['name'].drop_duplicates()).sort_values().reset_index(drop=True)",
      "answer = Medication['name'].unique()",
      "answer = Medication['name'].drop_duplicates().sort_values()",
      "answer = Medication['name'].unique()",
      "answer = Medication['name'].drop_duplicates().sort_values()"
    ],
    "acc@20": 14,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "wine_1",
      "query": "SELECT Grape ,  Winery ,  YEAR FROM WINE WHERE Price  >   100 ORDER BY YEAR",
      "query_toks": [
        "SELECT",
        "Grape",
        ",",
        "Winery",
        ",",
        "YEAR",
        "FROM",
        "WINE",
        "WHERE",
        "Price",
        ">",
        "100",
        "ORDER",
        "BY",
        "YEAR"
      ],
      "query_toks_no_value": [
        "select",
        "grape",
        ",",
        "winery",
        ",",
        "year",
        "from",
        "wine",
        "where",
        "price",
        ">",
        "value",
        "order",
        "by",
        "year"
      ],
      "question": "List the grape, winery and year of the wines whose price is bigger than 100 ordered by year.",
      "question_toks": [
        "List",
        "the",
        "grape",
        ",",
        "winery",
        "and",
        "year",
        "of",
        "the",
        "wines",
        "whose",
        "price",
        "is",
        "bigger",
        "than",
        "100",
        "ordered",
        "by",
        "year",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  11,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  12,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  16,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                17,
                false
              ],
              null
            ],
            100.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                16,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "grapes": [
          "ID",
          "Grape",
          "Color"
        ],
        "appellations": [
          "No",
          "Appelation",
          "County",
          "State",
          "Area",
          "isAVA"
        ],
        "wine": [
          "No",
          "Grape",
          "Winery",
          "Appelation",
          "State",
          "Name",
          "Year",
          "Price",
          "Score",
          "Cases",
          "Drink"
        ]
      },
      "answer": [
        [
          "Grenache",
          "Sine Qua Non",
          2006
        ],
        [
          "Syrah",
          "Sine Qua Non",
          2006
        ],
        [
          "Cabernet Sauvingnon",
          "Hourglass",
          2006
        ],
        [
          "Cabernet Sauvingnon",
          "Lewis",
          2006
        ],
        [
          "Cabernet Sauvingnon",
          "Bucella",
          2006
        ],
        [
          "Cabernet Sauvingnon",
          "Casa Piena",
          2006
        ],
        [
          "Cabernet Sauvingnon",
          "Chappellet",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Lewis",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Carter",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Carter",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Janzen",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Morlet",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Darioush",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Chimeney Rock",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Paul Hobbs",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Dos Lagos",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "David Arthur",
          2007
        ],
        [
          "Grenache",
          "Sine Qua Non",
          2007
        ],
        [
          "Syrah",
          "Sine Qua Non",
          2007
        ],
        [
          "Cabernet Sauvingnon",
          "Lewis",
          2008
        ],
        [
          "Cabernet Sauvingnon",
          "Caymus",
          2008
        ]
      ]
    },
    "generated_programs": [
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100].sort_values('year')[['grape', 'winery', 'year']]",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year')",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending = True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending=True)",
      "answer = wine[wine['price'] > 100][['grape', 'winery', 'year']].sort_values('year', ascending=True)"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "customer_complaints",
      "query": "SELECT email_address ,  phone_number FROM customers ORDER BY email_address ,  phone_number",
      "query_toks": [
        "SELECT",
        "email_address",
        ",",
        "phone_number",
        "FROM",
        "customers",
        "ORDER",
        "BY",
        "email_address",
        ",",
        "phone_number"
      ],
      "query_toks_no_value": [
        "select",
        "email_address",
        ",",
        "phone_number",
        "from",
        "customers",
        "order",
        "by",
        "email_address",
        ",",
        "phone_number"
      ],
      "question": "What are the emails and phone numbers of all customers, sorted by email address and phone number?",
      "question_toks": [
        "What",
        "are",
        "the",
        "emails",
        "and",
        "phone",
        "numbers",
        "of",
        "all",
        "customers",
        ",",
        "sorted",
        "by",
        "email",
        "address",
        "and",
        "phone",
        "number",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  13,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                13,
                false
              ],
              null
            ],
            [
              0,
              [
                0,
                14,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Staff": [
          "staff_id",
          "gender",
          "first_name",
          "last_name",
          "email_address",
          "phone_number"
        ],
        "Customers": [
          "customer_id",
          "customer_type_code",
          "address_line_1",
          "address_line_2",
          "town_city",
          "state",
          "email_address",
          "phone_number"
        ],
        "Products": [
          "product_id",
          "parent_product_id",
          "product_category_code",
          "date_product_first_available",
          "date_product_discontinued",
          "product_name",
          "product_description",
          "product_price"
        ],
        "Complaints": [
          "complaint_id",
          "product_id",
          "customer_id",
          "complaint_outcome_code",
          "complaint_status_code",
          "complaint_type_code",
          "date_complaint_raised",
          "date_complaint_closed",
          "staff_id"
        ]
      },
      "answer": [
        [
          "cayla.satterfield@example.net",
          "470-803-0244"
        ],
        [
          "hsteuber@example.org",
          "06963347450"
        ],
        [
          "lavonne.frami@example.com",
          "+38(3)9011433816"
        ],
        [
          "paige.hyatt@example.com",
          "1-369-302-7623x576"
        ],
        [
          "rzulauf@example.org",
          "578.019.7943x328"
        ],
        [
          "ubeier@example.org",
          "044-468-4549"
        ],
        [
          "vbogisich@example.org",
          "548.373.3603x59134"
        ],
        [
          "vida86@example.com",
          "997.698.4779x882"
        ]
      ]
    },
    "generated_programs": [
      "answer = Customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers.sort_values(['email_address', 'phone_number'])[['email_address', 'phone_number']]",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(by = ['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'], ascending=True)",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])",
      "answer = Customers.sort_values(['email_address', 'phone_number'])[['email_address', 'phone_number']]",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])",
      "answer = Customers[['email_address', 'phone_number']].sort_values(['email_address', 'phone_number'])"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "baseball_1",
      "query": "SELECT T2.name FROM home_game AS T1 JOIN team AS T2 ON T1.team_id = T2.team_id_br WHERE T1.year = 1980 ORDER BY T1.attendance ASC LIMIT 1;",
      "query_toks": [
        "SELECT",
        "T2.name",
        "FROM",
        "home_game",
        "AS",
        "T1",
        "JOIN",
        "team",
        "AS",
        "T2",
        "ON",
        "T1.team_id",
        "=",
        "T2.team_id_br",
        "WHERE",
        "T1.year",
        "=",
        "1980",
        "ORDER",
        "BY",
        "T1.attendance",
        "ASC",
        "LIMIT",
        "1",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "name",
        "from",
        "home_game",
        "as",
        "t1",
        "join",
        "team",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "team_id",
        "=",
        "t2",
        ".",
        "team_id_br",
        "where",
        "t1",
        ".",
        "year",
        "=",
        "value",
        "order",
        "by",
        "t1",
        ".",
        "attendance",
        "asc",
        "limit",
        "value"
      ],
      "question": "Which team had the least number of attendances in home games in 1980?",
      "question_toks": [
        "Which",
        "team",
        "had",
        "the",
        "least",
        "number",
        "of",
        "attendances",
        "in",
        "home",
        "games",
        "in",
        "1980",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              13
            ],
            [
              "table_unit",
              23
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  155,
                  false
                ],
                null
              ],
              [
                0,
                336,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  331,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                153,
                false
              ],
              null
            ],
            1980.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                161,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "all_star": [
          "player_id",
          "year",
          "game_num",
          "game_id",
          "team_id",
          "league_id",
          "gp",
          "starting_pos"
        ],
        "appearances": [
          "year",
          "team_id",
          "league_id",
          "player_id",
          "g_all",
          "gs",
          "g_batting",
          "g_defense",
          "g_p",
          "g_c",
          "g_1b",
          "g_2b",
          "g_3b",
          "g_ss",
          "g_lf",
          "g_cf",
          "g_rf",
          "g_of",
          "g_dh",
          "g_ph",
          "g_pr"
        ],
        "manager_award": [
          "player_id",
          "award_id",
          "year",
          "league_id",
          "tie",
          "notes"
        ],
        "player_award": [
          "player_id",
          "award_id",
          "year",
          "league_id",
          "tie",
          "notes"
        ],
        "manager_award_vote": [
          "award_id",
          "year",
          "league_id",
          "player_id",
          "points_won",
          "points_max",
          "votes_first"
        ],
        "player_award_vote": [
          "award_id",
          "year",
          "league_id",
          "player_id",
          "points_won",
          "points_max",
          "votes_first"
        ],
        "batting": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "g",
          "ab",
          "r",
          "h",
          "double",
          "triple",
          "hr",
          "rbi",
          "sb",
          "cs",
          "bb",
          "so",
          "ibb",
          "hbp",
          "sh",
          "sf",
          "g_idp"
        ],
        "batting_postseason": [
          "year",
          "round",
          "player_id",
          "team_id",
          "league_id",
          "g",
          "ab",
          "r",
          "h",
          "double",
          "triple",
          "hr",
          "rbi",
          "sb",
          "cs",
          "bb",
          "so",
          "ibb",
          "hbp",
          "sh",
          "sf",
          "g_idp"
        ],
        "player_college": [
          "player_id",
          "college_id",
          "year"
        ],
        "fielding": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "pos",
          "g",
          "gs",
          "inn_outs",
          "po",
          "a",
          "e",
          "dp",
          "pb",
          "wp",
          "sb",
          "cs",
          "zr"
        ],
        "fielding_outfield": [
          "player_id",
          "year",
          "stint",
          "glf",
          "gcf",
          "grf"
        ],
        "fielding_postseason": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "round",
          "pos",
          "g",
          "gs",
          "inn_outs",
          "po",
          "a",
          "e",
          "dp",
          "tp",
          "pb",
          "sb",
          "cs"
        ],
        "hall_of_fame": [
          "player_id",
          "yearid",
          "votedby",
          "ballots",
          "needed",
          "votes",
          "inducted",
          "category",
          "needed_note"
        ],
        "home_game": [
          "year",
          "league_id",
          "team_id",
          "park_id",
          "span_first",
          "span_last",
          "games",
          "openings",
          "attendance"
        ],
        "manager": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "inseason",
          "g",
          "w",
          "l",
          "rank",
          "plyr_mgr"
        ],
        "manager_half": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "inseason",
          "half",
          "g",
          "w",
          "l",
          "rank"
        ],
        "player": [
          "player_id",
          "birth_year",
          "birth_month",
          "birth_day",
          "birth_country",
          "birth_state",
          "birth_city",
          "death_year",
          "death_month",
          "death_day",
          "death_country",
          "death_state",
          "death_city",
          "name_first",
          "name_last",
          "name_given",
          "weight",
          "height",
          "bats",
          "throws",
          "debut",
          "final_game",
          "retro_id",
          "bbref_id"
        ],
        "park": [
          "park_id",
          "park_name",
          "park_alias",
          "city",
          "state",
          "country"
        ],
        "pitching": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "w",
          "l",
          "g",
          "gs",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "h",
          "er",
          "hr",
          "bb",
          "so",
          "baopp",
          "era",
          "ibb",
          "wp",
          "hbp",
          "bk",
          "bfp",
          "gf",
          "r",
          "sh",
          "sf",
          "g_idp"
        ],
        "pitching_postseason": [
          "player_id",
          "year",
          "round",
          "team_id",
          "league_id",
          "w",
          "l",
          "g",
          "gs",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "h",
          "er",
          "hr",
          "bb",
          "so",
          "baopp",
          "era",
          "ibb",
          "wp",
          "hbp",
          "bk",
          "bfp",
          "gf",
          "r",
          "sh",
          "sf",
          "g_idp"
        ],
        "salary": [
          "year",
          "team_id",
          "league_id",
          "player_id",
          "salary"
        ],
        "college": [
          "college_id",
          "name_full",
          "city",
          "state",
          "country"
        ],
        "postseason": [
          "year",
          "round",
          "team_id_winner",
          "league_id_winner",
          "team_id_loser",
          "league_id_loser",
          "wins",
          "losses",
          "ties"
        ],
        "team": [
          "year",
          "league_id",
          "team_id",
          "franchise_id",
          "div_id",
          "rank",
          "g",
          "ghome",
          "w",
          "l",
          "div_win",
          "wc_win",
          "lg_win",
          "ws_win",
          "r",
          "ab",
          "h",
          "double",
          "triple",
          "hr",
          "bb",
          "so",
          "sb",
          "cs",
          "hbp",
          "sf",
          "ra",
          "er",
          "era",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "ha",
          "hra",
          "bba",
          "soa",
          "e",
          "dp",
          "fp",
          "name",
          "park",
          "attendance",
          "bpf",
          "ppf",
          "team_id_br",
          "team_id_lahman45",
          "team_id_retro"
        ],
        "team_franchise": [
          "franchise_id",
          "franchise_name",
          "active",
          "na_assoc"
        ],
        "team_half": [
          "year",
          "league_id",
          "team_id",
          "half",
          "div_id",
          "div_win",
          "rank",
          "g",
          "w",
          "l"
        ]
      },
      "answer": [
        [
          "Minnesota Twins"
        ]
      ]
    },
    "generated_programs": [
      "t1 = home_game[home_game['year'] == 1980]['attendance'].sort_values().head(1).to_frame().reset_index()\nt2 = pd.merge(t1, team, left_on='attendance', right_on='attendance')\nanswer = t2['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year']==1980].sort_values('attendance')\nanswer = t2.head(1)['name']",
      "t1 = pd.merge(home_game, team[['team_id_br','name']], on='team_id', how='left')\nt2 = t1[t1['year'] == 1980]\nt3 = t2.sort_values('attendance').head(1)\nanswer = t3['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980]\nt3 = t2.sort_values('attendance', ascending=True).head(1)\nanswer = t3['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980]\nt3 = t2.sort_values('attendance')\nanswer = t3.iloc[0]['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nanswer = t1[t1['year'] == 1980][['name']].sort_values('attendance').head(1)",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980].groupby('name').sum()\nt3 = t2.sort_values('attendance')\nanswer = t3.iloc[0].to_frame().reset_index()['name']",
      "t1 = home_game[home_game['year'] == 1980]\nt2 = t1.sort_values('attendance').head(1).reset_index()\nt3 = pd.merge(t2, team, on='team_id_br')\nanswer = t3['name'].head(1)",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980].sort_values('attendance', ascending=True)\nanswer = t2.head(1)['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980]\nanswer = t2[['name']].sort_values('attendance', ascending=True).head(1)",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nanswer = t1[t1['year'] == 1980].sort_values('attendance').head(1)['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980].sort_values('attendance').head(1)\nanswer = t2['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nanswer = t1[t1['year'] == 1980].sort_values('attendance').head(1)['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nanswer = t1[t1['year'] == 1980].sort_values('attendance')[['name']]",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nanswer = t1[t1['year'] == 1980].sort_values('attendance', ascending = True).head(1)['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year']==1980]\nanswer = pd.Series(t2.sort_values('attendance').head(1)['name'].iloc[0])",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980].sort_values(['attendance'], ascending = True)\nanswer = t2[['name']].head(1)",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980].sort_values('attendance', ascending=True).head(1)\nanswer = t2['name']",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980]\nanswer = t2[['name']].sort_values('attendance').head(1)",
      "t1 = pd.merge(home_game, team, left_on='team_id', right_on='team_id_br')\nt2 = t1[t1['year'] == 1980]\nanswer = t2[['name']].sort_values('attendance', ascending=True).head(1)"
    ],
    "acc@20": 1,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "e_learning",
      "query": "SELECT COUNT(*) FROM Students WHERE personal_name LIKE \"%son%\"",
      "query_toks": [
        "SELECT",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "Students",
        "WHERE",
        "personal_name",
        "LIKE",
        "``",
        "%",
        "son",
        "%",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "students",
        "where",
        "personal_name",
        "like",
        "value"
      ],
      "question": "Find the number of students who have the word \"son\" in their personal names.",
      "question_toks": [
        "Find",
        "the",
        "number",
        "of",
        "students",
        "who",
        "have",
        "the",
        "word",
        "``",
        "son",
        "''",
        "in",
        "their",
        "personal",
        "names",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            9,
            [
              0,
              [
                0,
                15,
                false
              ],
              null
            ],
            "\"%son%\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Course_Authors_and_Tutors": [
          "author_id",
          "author_tutor_ATB",
          "login_name",
          "password",
          "personal_name",
          "middle_name",
          "family_name",
          "gender_mf",
          "address_line_1"
        ],
        "Students": [
          "student_id",
          "date_of_registration",
          "date_of_latest_logon",
          "login_name",
          "password",
          "personal_name",
          "middle_name",
          "family_name"
        ],
        "Subjects": [
          "subject_id",
          "subject_name"
        ],
        "Courses": [
          "course_id",
          "author_id",
          "subject_id",
          "course_name",
          "course_description"
        ],
        "Student_Course_Enrolment": [
          "registration_id",
          "student_id",
          "course_id",
          "date_of_enrolment",
          "date_of_completion"
        ],
        "Student_Tests_Taken": [
          "registration_id",
          "date_test_taken",
          "test_result"
        ]
      },
      "answer": [
        [
          2
        ]
      ]
    },
    "generated_programs": [
      "t1 = Students[Students['personal_name'].str.contains('son')].size\nanswer = pd.Series(t1)",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son', case=False)].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "t1 = Students['personal_name'].str.contains('son')\nanswer = pd.Series(t1.sum())",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].size)",
      "answer = pd.Series((Students['personal_name'].str.contains('son')).sum())",
      "t1 = Students[Students['personal_name'].str.contains('son')].shape[0]\nanswer = pd.Series(t1)",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = Students[Students['personal_name'].str.contains('son')].shape[0]",
      "t1 = Students[Students['personal_name'].str.contains('son', case=False)]\nanswer = pd.Series(t1.shape[0])",
      "answer = Students[Students['personal_name'].str.contains('son')].shape[0]",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = pd.Series(Students[Students['personal_name'].str.contains('son')].shape[0])",
      "answer = Students[Students['personal_name'].str.contains('son')].shape[0]",
      "answer = pd.Series(Students[Students['personal_name'].str.contains(\"son\")].shape[0])"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "loan_1",
      "query": "SELECT sum(acc_bal) ,  state FROM customer WHERE credit_score  >  100 GROUP BY state",
      "query_toks": [
        "SELECT",
        "sum",
        "(",
        "acc_bal",
        ")",
        ",",
        "state",
        "FROM",
        "customer",
        "WHERE",
        "credit_score",
        ">",
        "100",
        "GROUP",
        "BY",
        "state"
      ],
      "query_toks_no_value": [
        "select",
        "sum",
        "(",
        "acc_bal",
        ")",
        ",",
        "state",
        "from",
        "customer",
        "where",
        "credit_score",
        ">",
        "value",
        "group",
        "by",
        "state"
      ],
      "question": "What is the total account balance for customers with a credit score of above 100 for the different states?",
      "question_toks": [
        "What",
        "is",
        "the",
        "total",
        "account",
        "balance",
        "for",
        "customers",
        "with",
        "a",
        "credit",
        "score",
        "of",
        "above",
        "100",
        "for",
        "the",
        "different",
        "states",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              4,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  13,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                11,
                false
              ],
              null
            ],
            100.0,
            null
          ]
        ],
        "groupBy": [
          [
            0,
            13,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "bank": [
          "branch_ID",
          "bname",
          "no_of_customers",
          "city",
          "state"
        ],
        "customer": [
          "cust_ID",
          "cust_name",
          "acc_type",
          "acc_bal",
          "no_of_loans",
          "credit_score",
          "branch_ID",
          "state"
        ],
        "loan": [
          "loan_ID",
          "loan_type",
          "cust_ID",
          "branch_ID",
          "amount"
        ]
      },
      "answer": [
        [
          800000,
          "New York"
        ]
      ]
    },
    "generated_programs": [
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum()",
      "answer = customer.groupby('state')[['acc_bal']][customer['credit_score'] > 100].sum()",
      "t1 = customer[customer['credit_score'] > 100]\nt2 = t1.groupby('state').acc_bal.sum().rename('total_account_balance')\nanswer = t2.to_frame()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum()",
      "answer = customer[customer['credit_score'] > 100].groupby('state').agg({'acc_bal': 'sum'})",
      "t1 = customer[customer['credit_score'] > 100]\nt2 = t1.groupby('state').agg({'acc_bal' : 'sum'}).reset_index()\nanswer = t2[['state', 'acc_bal']]",
      "t1 = customer[['acc_bal', 'state']].groupby('state').sum()\nanswer = t1",
      "answer = customer[customer['credit_score'] > 100].groupby('state').sum()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum().rename('sum')",
      "answer = customer[customer['credit_score'] > 100].groupby(['state'])['acc_bal'].sum().rename('sum_acc_bal').to_frame()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum().to_frame().reset_index()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum().to_frame()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum().to_frame()",
      "answer = customer[customer['credit_score'] > 100].groupby('state').sum()['acc_bal'].to_frame().reset_index()",
      "t1 = customer[customer['credit_score'] > 100]\nt2 = t1.groupby('state')['acc_bal'].sum().rename('sum')\nanswer = t2.to_frame().reset_index()",
      "t1 = customer[customer['credit_score'] > 100]\nt2 = t1.groupby('state')['acc_bal'].sum()\nanswer = t2.to_frame().reset_index()",
      "answer = customer[customer['credit_score'] > 100].groupby('state')['acc_bal'].sum()",
      "answer = customer[customer['credit_score'] > 100].groupby('state').sum()['acc_bal'].to_frame().rename(columns={'acc_bal': 'sum(acc_bal)'})"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "college_2",
      "query": "SELECT min(salary) ,  dept_name FROM instructor GROUP BY dept_name HAVING avg(salary)  >  (SELECT avg(salary) FROM instructor)",
      "query_toks": [
        "SELECT",
        "min",
        "(",
        "salary",
        ")",
        ",",
        "dept_name",
        "FROM",
        "instructor",
        "GROUP",
        "BY",
        "dept_name",
        "HAVING",
        "avg",
        "(",
        "salary",
        ")",
        ">",
        "(",
        "SELECT",
        "avg",
        "(",
        "salary",
        ")",
        "FROM",
        "instructor",
        ")"
      ],
      "query_toks_no_value": [
        "select",
        "min",
        "(",
        "salary",
        ")",
        ",",
        "dept_name",
        "from",
        "instructor",
        "group",
        "by",
        "dept_name",
        "having",
        "avg",
        "(",
        "salary",
        ")",
        ">",
        "(",
        "select",
        "avg",
        "(",
        "salary",
        ")",
        "from",
        "instructor",
        ")"
      ],
      "question": "What is the lowest salary in departments with average salary greater than the overall average.",
      "question_toks": [
        "What",
        "is",
        "the",
        "lowest",
        "salary",
        "in",
        "departments",
        "with",
        "average",
        "salary",
        "greater",
        "than",
        "the",
        "overall",
        "average",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              2,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  13,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            13,
            false
          ]
        ],
        "having": [
          [
            false,
            3,
            [
              0,
              [
                5,
                14,
                false
              ],
              null
            ],
            {
              "from": {
                "table_units": [
                  [
                    "table_unit",
                    3
                  ]
                ],
                "conds": []
              },
              "select": [
                false,
                [
                  [
                    5,
                    [
                      0,
                      [
                        0,
                        14,
                        false
                      ],
                      null
                    ]
                  ]
                ]
              ],
              "where": [],
              "groupBy": [],
              "having": [],
              "orderBy": [],
              "limit": null,
              "intersect": null,
              "union": null,
              "except": null
            },
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "classroom": [
          "building",
          "room_number",
          "capacity"
        ],
        "department": [
          "dept_name",
          "building",
          "budget"
        ],
        "course": [
          "course_id",
          "title",
          "dept_name",
          "credits"
        ],
        "instructor": [
          "ID",
          "name",
          "dept_name",
          "salary"
        ],
        "section": [
          "course_id",
          "sec_id",
          "semester",
          "year",
          "building",
          "room_number",
          "time_slot_id"
        ],
        "teaches": [
          "ID",
          "course_id",
          "sec_id",
          "semester",
          "year"
        ],
        "student": [
          "ID",
          "name",
          "dept_name",
          "tot_cred"
        ],
        "takes": [
          "ID",
          "course_id",
          "sec_id",
          "semester",
          "year",
          "grade"
        ],
        "advisor": [
          "s_ID",
          "i_ID"
        ],
        "time_slot": [
          "time_slot_id",
          "day",
          "start_hr",
          "start_min",
          "end_hr",
          "end_min"
        ],
        "prereq": [
          "course_id",
          "prereq_id"
        ]
      },
      "answer": [
        [
          79070.08,
          "Astronomy"
        ],
        [
          80797.83,
          "Comp. Sci."
        ],
        [
          79866.95,
          "Cybernetics"
        ],
        [
          105311.38,
          "Finance"
        ],
        [
          99382.59,
          "Geology"
        ],
        [
          43770.36,
          "Marketing"
        ],
        [
          51647.57,
          "Mech. Eng."
        ],
        [
          108011.81,
          "Physics"
        ],
        [
          87549.8,
          "Pol. Sci."
        ]
      ]
    },
    "generated_programs": [
      "t1 = instructor.groupby('dept_name').size().rename('count')\nt2 = pd.merge(instructor, t1.to_frame().reset_index(), on='dept_name')\nt3 = t2.groupby('dept_name')['salary'].agg([np.mean, np.min]).rename(columns={'mean':'avg_salary'})\nt4 = t3[t3['avg_salary'] > t2['salary'].mean()]\nanswer = t4[['avg_salary', 'amin']]",
      "t1 = instructor.groupby('dept_name')['salary'].mean().rename('avg').to_frame().reset_index()\nt2 = t1[t1['avg'] > instructor['salary'].mean()]\nanswer = instructor[instructor['dept_name'].isin(t2['dept_name'])].groupby('dept_name')['salary'].min().rename('min').to_frame().reset_index()",
      "t1 = instructor.groupby('dept_name')['salary'].mean().to_frame().reset_index().rename(columns={'salary':'avg'})\nt2 = pd.merge(t1, instructor, on='dept_name')\nt3 = t2[t2['avg'] > t2['avg'].mean()]\nanswer = t3.groupby('dept_name')['salary'].min().to_frame().reset_index()",
      "t1 = instructor.groupby('dept_name').agg({'salary': 'avg'})\nt2 = t1[t1['salary'] > t1['salary'].mean()]\nt3 = t2.reset_index()\nt4 = pd.merge(instructor, t3, on='dept_name')\nt5 = t4.groupby('dept_name').agg({'salary': 'min'})\nanswer = t5.reset_index()",
      "t1 = instructor.groupby('dept_name').mean().rename(columns={'salary': 'average_salary'})\nt2 = instructor.groupby('dept_name').min().rename(columns={'salary': 'min_salary'})\nt3 = t1.merge(t2, left_index=True, right_index=True)\nt4 = t3[t3['average_salary'] > t1['average_salary'].mean()]\nanswer = t4['min_salary']",
      "t1= instructor.groupby(['dept_name'])['salary'].mean()\nt2 = instructor.groupby(['dept_name'])['salary'].min()\nt3 = pd.merge(t1, t2, left_index=True, right_index=True)\nt4 = t3[t3['salary_x'] > t3['salary_x'].mean()]\nanswer = t4['salary_y']",
      "t1 = instructor.groupby('dept_name').mean()\nt2 = t1[t1['salary'] > instructor['salary'].mean()]\nanswer = t2['salary'].min()",
      "t1 = instructor.groupby(['dept_name'])['salary'].mean().rename('avg_salary')\nt2 = t1[t1 > t1.mean()].to_frame().reset_index()\nt3 = pd.merge(instructor, t2, on='dept_name')\nanswer = t3.groupby('dept_name')['salary'].min().rename('min')",
      "t1 = instructor.groupby('dept_name').apply(np.mean).rename('avg_salary')\nt2 = t1[t1['avg_salary'] > t1.loc['Overall_Average'].iloc[0]].reset_index()\nt3 = instructor.groupby('dept_name').min().reset_index()\nt4 = pd.merge(t2, t3, on='dept_name')\nanswer = t4['salary']",
      "t1 = instructor.groupby('dept_name').agg({'salary': 'mean'})\nt2 = instructor.groupby('dept_name').agg({'salary': 'min'})\nt3 = t1[t1['salary'] > t1['salary'].mean()]\nanswer = t2.loc[t3.index]",
      "t1 = instructor.groupby('dept_name').agg({'salary': np.mean}).rename(columns={'salary': 'avg_salary'}).reset_index()\nt2 = t1[t1['avg_salary'] > instructor['salary'].mean()]\nt3 = pd.merge(t2, instructor, on='dept_name')\nanswer = t3.groupby('dept_name').agg({'salary': np.min}).rename(columns={'salary': 'min_salary'}).reset_index()",
      "t1 = instructor.groupby('dept_name').agg({'salary': 'mean'}).rename(columns={'salary': 'average_salary'})\nt2 = t1[t1['average_salary'] > t1['average_salary'].mean()]\nt3 = t2.reset_index()\nt4 = pd.merge(instructor, t3, on='dept_name')\nt5 = t4.groupby('dept_name').agg({'salary': 'min'}).reset_index()\nanswer = t5",
      "t1 = instructor.groupby('dept_name').agg({'salary': ['min', 'mean']}).reset_index()\nt1.columns = ['dept_name', 'min_salary', 'avg_salary']\nt2 = pd.Series(instructor['salary'].mean())\nt2.index = ['avg_salary']\nt1 = pd.concat([t1, t2], axis=1)\nt3 = t1[t1['avg_salary'] > t1['avg_salary'].loc['avg_salary']]\nanswer = t3[['dept_name', 'min_salary']]",
      "department_average = instructor.groupby('dept_name').apply(lambda x: np.sum(x['salary']) / x.shape[0])\noverall_average = instructor['salary'].mean()\nprint(department_average)\nprint(overall_average)",
      "t1 = instructor.groupby('dept_name')['salary'].mean().rename('avg').to_frame()\nt2 = instructor.groupby('dept_name')['salary'].min().rename('min').to_frame()\nt3 = pd.merge(t1, t2, on='dept_name', how='inner')\nt4 = instructor['salary'].mean().round(2)\nt5 = t3[t3['avg'] > t4]['min']\nanswer = t5.to_frame().reset_index()",
      "t1 = instructor.groupby('dept_name').mean().rename({'salary':'avg_salary'}, axis=1)\nt2 = t1[t1['avg_salary'] > t1['avg_salary'].mean()].reset_index()\nt3 = instructor.groupby('dept_name').min().reset_index()\nanswer = pd.merge(t2, t3, on='dept_name')['salary']",
      "t1 = pd.merge(instructor, department, left_on='dept_name', right_on='dept_name')\nt2 = t1.groupby('dept_name').agg({'salary': [np.mean, np.min]})\ngreater = t2[t2['salary', 'mean'] > t2['salary']['mean'].mean()]\nanswer = greater['salary', 'min']",
      "t1 = instructor\nt2 = t1.groupby('dept_name').agg({'salary':[min]})\nt3 = t2['salary']['min'][t2['salary']['min'] > t1['salary'].mean()]\nanswer = t3.to_frame().reset_index()",
      "t1 = instructor.groupby('dept_name').agg({'salary': 'mean'})\nt2 = t1[t1['salary'] > instructor['salary'].mean()].reset_index()\nt3 = t2.rename(columns={'salary': 'avg_salary'})\nt4 = pd.merge(instructor, t3, on='dept_name')\nt5 = t4.groupby('dept_name').agg({'salary': 'min'})\nanswer = t5.reset_index()",
      "t1 = instructor.groupby('dept_name').agg({'salary': [min, np.mean]})\nt2 = t1[t1['salary']['mean'] > instructor['salary'].mean()]\nanswer = t2['salary']['min']"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "sakila_1",
      "query": "SELECT title FROM film WHERE special_features LIKE '%Deleted Scenes%'",
      "query_toks": [
        "SELECT",
        "title",
        "FROM",
        "film",
        "WHERE",
        "special_features",
        "LIKE",
        "'",
        "%",
        "Deleted",
        "Scenes",
        "%",
        "'"
      ],
      "query_toks_no_value": [
        "select",
        "title",
        "from",
        "film",
        "where",
        "special_features",
        "like",
        "value"
      ],
      "question": "Return the titles of films that include 'Deleted Scenes' in their special feature section.",
      "question_toks": [
        "Return",
        "the",
        "titles",
        "of",
        "films",
        "that",
        "include",
        "'Deleted",
        "Scenes",
        "'",
        "in",
        "their",
        "special",
        "feature",
        "section",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              6
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  33,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            9,
            [
              0,
              [
                0,
                43,
                false
              ],
              null
            ],
            "\"%Deleted Scenes%\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "actor": [
          "actor_id",
          "first_name",
          "last_name",
          "last_update"
        ],
        "address": [
          "address_id",
          "address",
          "address2",
          "district",
          "city_id",
          "postal_code",
          "phone",
          "last_update"
        ],
        "category": [
          "category_id",
          "name",
          "last_update"
        ],
        "city": [
          "city_id",
          "city",
          "country_id",
          "last_update"
        ],
        "country": [
          "country_id",
          "country",
          "last_update"
        ],
        "customer": [
          "customer_id",
          "store_id",
          "first_name",
          "last_name",
          "email",
          "address_id",
          "active",
          "create_date",
          "last_update"
        ],
        "film": [
          "film_id",
          "title",
          "description",
          "release_year",
          "language_id",
          "original_language_id",
          "rental_duration",
          "rental_rate",
          "length",
          "replacement_cost",
          "rating",
          "special_features",
          "last_update"
        ],
        "film_actor": [
          "actor_id",
          "film_id",
          "last_update"
        ],
        "film_category": [
          "film_id",
          "category_id",
          "last_update"
        ],
        "film_text": [
          "film_id",
          "title",
          "description"
        ],
        "inventory": [
          "inventory_id",
          "film_id",
          "store_id",
          "last_update"
        ],
        "language": [
          "language_id",
          "name",
          "last_update"
        ],
        "payment": [
          "payment_id",
          "customer_id",
          "staff_id",
          "rental_id",
          "amount",
          "payment_date",
          "last_update"
        ],
        "rental": [
          "rental_id",
          "rental_date",
          "inventory_id",
          "customer_id",
          "return_date",
          "staff_id",
          "last_update"
        ],
        "staff": [
          "staff_id",
          "first_name",
          "last_name",
          "address_id",
          "picture",
          "email",
          "store_id",
          "active",
          "username",
          "password",
          "last_update"
        ],
        "store": [
          "store_id",
          "manager_staff_id",
          "address_id",
          "last_update"
        ]
      },
      "answer": [
        [
          "ACADEMY DINOSAUR"
        ],
        [
          "ACE GOLDFINGER"
        ],
        [
          "ADAPTATION HOLES"
        ],
        [
          "AFRICAN EGG"
        ],
        [
          "AGENT TRUMAN"
        ],
        [
          "AIRPLANE SIERRA"
        ],
        [
          "ALABAMA DEVIL"
        ],
        [
          "ALADDIN CALENDAR"
        ],
        [
          "ALASKA PHANTOM"
        ],
        [
          "ALI FOREVER"
        ],
        [
          "ALICE FANTASIA"
        ],
        [
          "AMADEUS HOLY"
        ],
        [
          "AMELIE HELLFIGHTERS"
        ],
        [
          "ANACONDA CONFESSIONS"
        ],
        [
          "ANNIE IDENTITY"
        ],
        [
          "ANONYMOUS HUMAN"
        ],
        [
          "ANTHEM LUKE"
        ],
        [
          "ANTITRUST TOMATOES"
        ],
        [
          "ANYTHING SAVANNAH"
        ],
        [
          "APACHE DIVINE"
        ],
        [
          "APOLLO TEEN"
        ],
        [
          "ARABIA DOGMA"
        ],
        [
          "ARACHNOPHOBIA ROLLERCOASTER"
        ],
        [
          "ARIZONA BANG"
        ],
        [
          "ARK RIDGEMONT"
        ],
        [
          "ARSENIC INDEPENDENCE"
        ],
        [
          "AUTUMN CROW"
        ],
        [
          "BALLOON HOMEWARD"
        ],
        [
          "BALLROOM MOCKINGBIRD"
        ],
        [
          "BANG KWAI"
        ],
        [
          "BANGER PINOCCHIO"
        ],
        [
          "BASIC EASY"
        ],
        [
          "BEACH HEARTBREAKERS"
        ],
        [
          "BEAR GRACELAND"
        ],
        [
          "BEAST HUNCHBACK"
        ],
        [
          "BED HIGHBALL"
        ],
        [
          "BEDAZZLED MARRIED"
        ],
        [
          "BEHAVIOR RUNAWAY"
        ],
        [
          "BENEATH RUSH"
        ],
        [
          "BERETS AGENT"
        ],
        [
          "BETRAYED REAR"
        ],
        [
          "BIKINI BORROWERS"
        ],
        [
          "BILKO ANONYMOUS"
        ],
        [
          "BIRCH ANTITRUST"
        ],
        [
          "BIRDCAGE CASPER"
        ],
        [
          "BLACKOUT PRIVATE"
        ],
        [
          "BLUES INSTINCT"
        ],
        [
          "BONNIE HOLOCAUST"
        ],
        [
          "BORN SPINAL"
        ],
        [
          "BORROWERS BEDAZZLED"
        ],
        [
          "BOWFINGER GABLES"
        ],
        [
          "BRAVEHEART HUMAN"
        ],
        [
          "BREAKFAST GOLDFINGER"
        ],
        [
          "BUBBLE GROSSE"
        ],
        [
          "BUCKET BROTHERHOOD"
        ],
        [
          "BULL SHAWSHANK"
        ],
        [
          "BUTCH PANTHER"
        ],
        [
          "CABIN FLASH"
        ],
        [
          "CADDYSHACK JEDI"
        ],
        [
          "CALIFORNIA BIRDS"
        ],
        [
          "CAMELOT VACATION"
        ],
        [
          "CANDIDATE PERDITION"
        ],
        [
          "CANDLES GRAPES"
        ],
        [
          "CANYON STOCK"
        ],
        [
          "CAPER MOTIONS"
        ],
        [
          "CARIBBEAN LIBERTY"
        ],
        [
          "CASABLANCA SUPER"
        ],
        [
          "CAT CONEHEADS"
        ],
        [
          "CAUSE DATE"
        ],
        [
          "CELEBRITY HORN"
        ],
        [
          "CENTER DINOSAUR"
        ],
        [
          "CHAINSAW UPTOWN"
        ],
        [
          "CHANCE RESURRECTION"
        ],
        [
          "CHARADE DUFFEL"
        ],
        [
          "CHARIOTS CONSPIRACY"
        ],
        [
          "CHICAGO NORTH"
        ],
        [
          "CHICKEN HELLFIGHTERS"
        ],
        [
          "CHILL LUCK"
        ],
        [
          "CHINATOWN GLADIATOR"
        ],
        [
          "CINCINATTI WHISPERER"
        ],
        [
          "CIRCUS YOUTH"
        ],
        [
          "CITIZEN SHREK"
        ],
        [
          "CLASH FREDDY"
        ],
        [
          "CLEOPATRA DEVIL"
        ],
        [
          "CLOCKWORK PARADISE"
        ],
        [
          "CLUB GRAFFITI"
        ],
        [
          "CLUELESS BUCKET"
        ],
        [
          "CLYDE THEORY"
        ],
        [
          "COAST RAINBOW"
        ],
        [
          "COLDBLOODED DARLING"
        ],
        [
          "COMMANDMENTS EXPRESS"
        ],
        [
          "CONEHEADS SMOOCHY"
        ],
        [
          "CONFUSED CANDLES"
        ],
        [
          "CONNECTICUT TRAMP"
        ],
        [
          "CONNECTION MICROCOSMOS"
        ],
        [
          "CONQUERER NUTS"
        ],
        [
          "CORE SUIT"
        ],
        [
          "COWBOY DOOM"
        ],
        [
          "CRAFT OUTFIELD"
        ],
        [
          "CRAZY HOME"
        ],
        [
          "CREATURES SHAKESPEARE"
        ],
        [
          "CROOKED FROGMEN"
        ],
        [
          "CROSSING DIVORCE"
        ],
        [
          "CRUELTY UNFORGIVEN"
        ],
        [
          "CURTAIN VIDEOTAPE"
        ],
        [
          "CYCLONE FAMILY"
        ],
        [
          "DADDY PITTSBURGH"
        ],
        [
          "DALMATIONS SWEDEN"
        ],
        [
          "DANCES NONE"
        ],
        [
          "DARKNESS WAR"
        ],
        [
          "DARKO DORADO"
        ],
        [
          "DARN FORRESTER"
        ],
        [
          "DAWN POND"
        ],
        [
          "DAY UNFAITHFUL"
        ],
        [
          "DAZED PUNK"
        ],
        [
          "DECEIVER BETRAYED"
        ],
        [
          "DEER VIRGINIAN"
        ],
        [
          "DELIVERANCE MULHOLLAND"
        ],
        [
          "DESIRE ALIEN"
        ],
        [
          "DESPERATE TRAINSPOTTING"
        ],
        [
          "DETAILS PACKER"
        ],
        [
          "DIRTY ACE"
        ],
        [
          "DISCIPLE MOTHER"
        ],
        [
          "DIVORCE SHINING"
        ],
        [
          "DOLLS RAGE"
        ],
        [
          "DOORS PRESIDENT"
        ],
        [
          "DOUBLE WRATH"
        ],
        [
          "DOUBTFIRE LABYRINTH"
        ],
        [
          "DOWNHILL ENOUGH"
        ],
        [
          "DOZEN LION"
        ],
        [
          "DRAGON SQUAD"
        ],
        [
          "DRIVER ANNIE"
        ],
        [
          "DRIVING POLISH"
        ],
        [
          "DRUMLINE CYCLONE"
        ],
        [
          "DUDE BLINDNESS"
        ],
        [
          "DWARFS ALTER"
        ],
        [
          "DYNAMITE TARZAN"
        ],
        [
          "EARTH VISION"
        ],
        [
          "EDGE KISSING"
        ],
        [
          "EGYPT TENENBAUMS"
        ],
        [
          "ELIZABETH SHANE"
        ],
        [
          "EMPIRE MALKOVICH"
        ],
        [
          "ENGLISH BULWORTH"
        ],
        [
          "ENTRAPMENT SATISFACTION"
        ],
        [
          "EVE RESURRECTION"
        ],
        [
          "EXORCIST STING"
        ],
        [
          "EXPECATIONS NATURAL"
        ],
        [
          "EXTRAORDINARY CONQUERER"
        ],
        [
          "FACTORY DRAGON"
        ],
        [
          "FARGO GANDHI"
        ],
        [
          "FEATHERS METAL"
        ],
        [
          "FELLOWSHIP AUTUMN"
        ],
        [
          "FERRIS MOTHER"
        ],
        [
          "FEUD FROGMEN"
        ],
        [
          "FEVER EMPIRE"
        ],
        [
          "FICTION CHRISTMAS"
        ],
        [
          "FIDDLER LOST"
        ],
        [
          "FIDELITY DEVIL"
        ],
        [
          "FIGHT JAWBREAKER"
        ],
        [
          "FIREHOUSE VIETNAM"
        ],
        [
          "FISH OPUS"
        ],
        [
          "FLATLINERS KILLER"
        ],
        [
          "FLINTSTONES HAPPINESS"
        ],
        [
          "FOREVER CANDIDATE"
        ],
        [
          "FRANKENSTEIN STRANGER"
        ],
        [
          "FRIDA SLIPPER"
        ],
        [
          "FRISCO FORREST"
        ],
        [
          "FROGMEN BREAKING"
        ],
        [
          "FRONTIER CABIN"
        ],
        [
          "FROST HEAD"
        ],
        [
          "FUGITIVE MAGUIRE"
        ],
        [
          "FULL FLATLINERS"
        ],
        [
          "FURY MURDER"
        ],
        [
          "GALAXY SWEETHEARTS"
        ],
        [
          "GASLIGHT CRUSADE"
        ],
        [
          "GENTLEMEN STAGE"
        ],
        [
          "GHOST GROUNDHOG"
        ],
        [
          "GHOSTBUSTERS ELF"
        ],
        [
          "GLADIATOR WESTWARD"
        ],
        [
          "GOLD RIVER"
        ],
        [
          "GONE TROUBLE"
        ],
        [
          "GOODFELLAS SALUTE"
        ],
        [
          "GORGEOUS BINGO"
        ],
        [
          "GRAFFITI LOVE"
        ],
        [
          "GRAIL FRANKENSTEIN"
        ],
        [
          "GREASE YOUTH"
        ],
        [
          "GREEDY ROOTS"
        ],
        [
          "GREEK EVERYONE"
        ],
        [
          "GRIT CLOCKWORK"
        ],
        [
          "GROUNDHOG UNCUT"
        ],
        [
          "GUMP DATE"
        ],
        [
          "GUNFIGHT MOON"
        ],
        [
          "HALF OUTFIELD"
        ],
        [
          "HALLOWEEN NUTS"
        ],
        [
          "HAMLET WISDOM"
        ],
        [
          "HANDICAP BOONDOCK"
        ],
        [
          "HANGING DEEP"
        ],
        [
          "HANKY OCTOBER"
        ],
        [
          "HANOVER GALAXY"
        ],
        [
          "HAPPINESS UNITED"
        ],
        [
          "HAROLD FRENCH"
        ],
        [
          "HARRY IDAHO"
        ],
        [
          "HAUNTED ANTITRUST"
        ],
        [
          "HEARTBREAKERS BRIGHT"
        ],
        [
          "HEAVYWEIGHTS BEAST"
        ],
        [
          "HELLFIGHTERS SIERRA"
        ],
        [
          "HIGHBALL POTTER"
        ],
        [
          "HILLS NEIGHBORS"
        ],
        [
          "HOCUS FRIDA"
        ],
        [
          "HOLOCAUST HIGHBALL"
        ],
        [
          "HONEY TIES"
        ],
        [
          "HOOSIERS BIRDCAGE"
        ],
        [
          "HOPE TOOTSIE"
        ],
        [
          "HORROR REIGN"
        ],
        [
          "HOURS RAGE"
        ],
        [
          "HOUSE DYNAMITE"
        ],
        [
          "HUNCHBACK IMPOSSIBLE"
        ],
        [
          "HUNGER ROOF"
        ],
        [
          "HUNTER ALTER"
        ],
        [
          "HUNTING MUSKETEERS"
        ],
        [
          "HYDE DOCTOR"
        ],
        [
          "HYSTERICAL GRAIL"
        ],
        [
          "ICE CROSSING"
        ],
        [
          "IDAHO LOVE"
        ],
        [
          "IDENTITY LOVER"
        ],
        [
          "IMAGE PRINCESS"
        ],
        [
          "IMPACT ALADDIN"
        ],
        [
          "IMPOSSIBLE PREJUDICE"
        ],
        [
          "INCH JET"
        ],
        [
          "INDIAN LOVE"
        ],
        [
          "INNOCENT USUAL"
        ],
        [
          "INSTINCT AIRPORT"
        ],
        [
          "INTRIGUE WORST"
        ],
        [
          "INVASION CYCLONE"
        ],
        [
          "ISHTAR ROCKETEER"
        ],
        [
          "ITALIAN AFRICAN"
        ],
        [
          "JACKET FRISCO"
        ],
        [
          "JAPANESE RUN"
        ],
        [
          "JASON TRAP"
        ],
        [
          "JAWS HARRY"
        ],
        [
          "JEDI BENEATH"
        ],
        [
          "JEEPERS WEDDING"
        ],
        [
          "JEKYLL FROGMEN"
        ],
        [
          "JERK PAYCHECK"
        ],
        [
          "JERSEY SASSY"
        ],
        [
          "JUNGLE CLOSER"
        ],
        [
          "KENTUCKIAN GIANT"
        ],
        [
          "KICK SAVANNAH"
        ],
        [
          "KILLER INNOCENT"
        ],
        [
          "KING EVOLUTION"
        ],
        [
          "LADY STAGE"
        ],
        [
          "LADYBUGS ARMAGEDDON"
        ],
        [
          "LANGUAGE COWBOY"
        ],
        [
          "LAWLESS VISION"
        ],
        [
          "LAWRENCE LOVE"
        ],
        [
          "LEBOWSKI SOLDIERS"
        ],
        [
          "LEGEND JEDI"
        ],
        [
          "LESSON CLEOPATRA"
        ],
        [
          "LIBERTY MAGNIFICENT"
        ],
        [
          "LICENSE WEEKEND"
        ],
        [
          "LIES TREATMENT"
        ],
        [
          "LIFE TWISTED"
        ],
        [
          "LION UNCUT"
        ],
        [
          "LOATHING LEGALLY"
        ],
        [
          "LOLITA WORLD"
        ],
        [
          "LONELY ELEPHANT"
        ],
        [
          "LOSER HUSTLER"
        ],
        [
          "LOST BIRD"
        ],
        [
          "MADIGAN DORADO"
        ],
        [
          "MADISON TRAP"
        ],
        [
          "MADRE GABLES"
        ],
        [
          "MAGNIFICENT CHITTY"
        ],
        [
          "MAGNOLIA FORRESTER"
        ],
        [
          "MAKER GABLES"
        ],
        [
          "MALLRATS UNITED"
        ],
        [
          "MANNEQUIN WORST"
        ],
        [
          "MARS ROMAN"
        ],
        [
          "MASK PEACH"
        ],
        [
          "MATRIX SNOWMAN"
        ],
        [
          "MENAGERIE RUSHMORE"
        ],
        [
          "METAL ARMAGEDDON"
        ],
        [
          "MIDNIGHT WESTWARD"
        ],
        [
          "MIDSUMMER GROUNDHOG"
        ],
        [
          "MILE MULAN"
        ],
        [
          "MILLION ACE"
        ],
        [
          "MINDS TRUMAN"
        ],
        [
          "MINE TITANS"
        ],
        [
          "MIRACLE VIRTUAL"
        ],
        [
          "MODERN DORADO"
        ],
        [
          "MOON BUNCH"
        ],
        [
          "MOONWALKER FOOL"
        ],
        [
          "MOURNING PURPLE"
        ],
        [
          "MOVIE SHAKESPEARE"
        ],
        [
          "MULHOLLAND BEAST"
        ],
        [
          "MUPPET MILE"
        ],
        [
          "MURDER ANTITRUST"
        ],
        [
          "MUSCLE BRIGHT"
        ],
        [
          "MUSKETEERS WAIT"
        ],
        [
          "MUSSOLINI SPOILERS"
        ],
        [
          "NATURAL STOCK"
        ],
        [
          "NEIGHBORS CHARADE"
        ],
        [
          "NETWORK PEAK"
        ],
        [
          "NEWSIES STORY"
        ],
        [
          "NEWTON LABYRINTH"
        ],
        [
          "NIGHTMARE CHILL"
        ],
        [
          "NORTH TEQUILA"
        ],
        [
          "NOTORIOUS REUNION"
        ],
        [
          "NOVOCAINE FLIGHT"
        ],
        [
          "OLEANDER CLUE"
        ],
        [
          "OPERATION OPERATION"
        ],
        [
          "OPPOSITE NECKLACE"
        ],
        [
          "OPUS ICE"
        ],
        [
          "ORDER BETRAYED"
        ],
        [
          "ORIENT CLOSER"
        ],
        [
          "OTHERS SOUP"
        ],
        [
          "OUTBREAK DIVINE"
        ],
        [
          "OUTFIELD MASSACRE"
        ],
        [
          "OZ LIAISONS"
        ],
        [
          "PACIFIC AMISTAD"
        ],
        [
          "PAJAMA JAWBREAKER"
        ],
        [
          "PANIC CLUB"
        ],
        [
          "PANKY SUBMARINE"
        ],
        [
          "PANTHER REDS"
        ],
        [
          "PAPI NECKLACE"
        ],
        [
          "PARADISE SABRINA"
        ],
        [
          "PARIS WEEKEND"
        ],
        [
          "PARK CITIZEN"
        ],
        [
          "PAST SUICIDES"
        ],
        [
          "PATRIOT ROMAN"
        ],
        [
          "PAYCHECK WAIT"
        ],
        [
          "PEAK FOREVER"
        ],
        [
          "PELICAN COMFORTS"
        ],
        [
          "PERFECT GROOVE"
        ],
        [
          "PERSONAL LADYBUGS"
        ],
        [
          "PHILADELPHIA WIFE"
        ],
        [
          "PIANIST OUTFIELD"
        ],
        [
          "PICKUP DRIVING"
        ],
        [
          "PILOT HOOSIERS"
        ],
        [
          "PIRATES ROXANNE"
        ],
        [
          "PITTSBURGH HUNCHBACK"
        ],
        [
          "POCUS PULP"
        ],
        [
          "POLISH BROOKLYN"
        ],
        [
          "PREJUDICE OLEANDER"
        ],
        [
          "PRIDE ALAMO"
        ],
        [
          "PRIMARY GLASS"
        ],
        [
          "PRINCESS GIANT"
        ],
        [
          "PRIX UNDEFEATED"
        ],
        [
          "PUNK DIVORCE"
        ],
        [
          "PURE RUNNER"
        ],
        [
          "PURPLE MOVIE"
        ],
        [
          "QUEEN LUKE"
        ],
        [
          "RACER EGG"
        ],
        [
          "RAGING AIRPLANE"
        ],
        [
          "RAIDERS ANTITRUST"
        ],
        [
          "RAINBOW SHOCK"
        ],
        [
          "RANGE MOONWALKER"
        ],
        [
          "REAR TRADING"
        ],
        [
          "REDEMPTION COMFORTS"
        ],
        [
          "REIGN GENTLEMEN"
        ],
        [
          "RESURRECTION SILVERADO"
        ],
        [
          "RIDGEMONT SUBMARINE"
        ],
        [
          "RIGHT CRANES"
        ],
        [
          "ROCK INSTINCT"
        ],
        [
          "ROCKETEER MOTHER"
        ],
        [
          "ROLLERCOASTER BRINGING"
        ],
        [
          "ROOF CHAMPION"
        ],
        [
          "ROOM ROMAN"
        ],
        [
          "ROOTS REMEMBER"
        ],
        [
          "ROSES TREASURE"
        ],
        [
          "ROUGE SQUAD"
        ],
        [
          "ROXANNE REBEL"
        ],
        [
          "RUGRATS SHAKESPEARE"
        ],
        [
          "RULES HUMAN"
        ],
        [
          "RUN PACIFIC"
        ],
        [
          "RUNNER MADIGAN"
        ],
        [
          "RUSH GOODFELLAS"
        ],
        [
          "RUSHMORE MERMAID"
        ],
        [
          "SADDLE ANTITRUST"
        ],
        [
          "SAINTS BRIDE"
        ],
        [
          "SALUTE APOLLO"
        ],
        [
          "SASSY PACKER"
        ],
        [
          "SATISFACTION CONFIDENTIAL"
        ],
        [
          "SATURDAY LAMBS"
        ],
        [
          "SATURN NAME"
        ],
        [
          "SAVANNAH TOWN"
        ],
        [
          "SCARFACE BANG"
        ],
        [
          "SCISSORHANDS SLUMS"
        ],
        [
          "SCORPION APOLLO"
        ],
        [
          "SEA VIRGIN"
        ],
        [
          "SEABISCUIT PUNK"
        ],
        [
          "SEARCHERS WAIT"
        ],
        [
          "SECRET GROUNDHOG"
        ],
        [
          "SENSE GREEK"
        ],
        [
          "SEVEN SWARM"
        ],
        [
          "SHANE DARKNESS"
        ],
        [
          "SHANGHAI TYCOON"
        ],
        [
          "SHAWSHANK BUBBLE"
        ],
        [
          "SHEPHERD MIDSUMMER"
        ],
        [
          "SHINING ROSES"
        ],
        [
          "SHOW LORD"
        ],
        [
          "SHRUNK DIVINE"
        ],
        [
          "SIDE ARK"
        ],
        [
          "SIEGE MADRE"
        ],
        [
          "SIERRA DIVIDE"
        ],
        [
          "SILENCE KANE"
        ],
        [
          "SINNERS ATLANTIS"
        ],
        [
          "SKY MIRACLE"
        ],
        [
          "SLEEPLESS MONSOON"
        ],
        [
          "SLEEPY JAPANESE"
        ],
        [
          "SLEUTH ORIENT"
        ],
        [
          "SLIPPER FIDELITY"
        ],
        [
          "SLUMS DUCK"
        ],
        [
          "SOLDIERS EVOLUTION"
        ],
        [
          "SONG HEDWIG"
        ],
        [
          "SORORITY QUEEN"
        ],
        [
          "SPARTACUS CHEAPER"
        ],
        [
          "SPEAKEASY DATE"
        ],
        [
          "SPICE SORORITY"
        ],
        [
          "SPIKING ELEMENT"
        ],
        [
          "SPINAL ROCKY"
        ],
        [
          "SPIRIT FLINTSTONES"
        ],
        [
          "SPLASH GUMP"
        ],
        [
          "SPLENDOR PATTON"
        ],
        [
          "SPOILERS HELLFIGHTERS"
        ],
        [
          "SPY MILE"
        ],
        [
          "SQUAD FISH"
        ],
        [
          "STAGECOACH ARMAGEDDON"
        ],
        [
          "STALLION SUNDANCE"
        ],
        [
          "STAMPEDE DISTURBING"
        ],
        [
          "STATE WASTELAND"
        ],
        [
          "STEEL SANTA"
        ],
        [
          "STEERS ARMAGEDDON"
        ],
        [
          "STEPMOM DREAM"
        ],
        [
          "STING PERSONAL"
        ],
        [
          "STRANGELOVE DESIRE"
        ],
        [
          "STRANGER STRANGERS"
        ],
        [
          "STRICTLY SCARFACE"
        ],
        [
          "SUICIDES SILENCE"
        ],
        [
          "SUMMER SCARFACE"
        ],
        [
          "SWEDEN SHINING"
        ],
        [
          "SWEET BROTHERHOOD"
        ],
        [
          "SWEETHEARTS SUSPECTS"
        ],
        [
          "TALENTED HOMICIDE"
        ],
        [
          "TAXI KICK"
        ],
        [
          "TEEN APOLLO"
        ],
        [
          "TELEMARK HEARTBREAKERS"
        ],
        [
          "TEMPLE ATTRACTION"
        ],
        [
          "TERMINATOR CLUB"
        ],
        [
          "THEORY MERMAID"
        ],
        [
          "THIEF PELICAN"
        ],
        [
          "TIES HUNGER"
        ],
        [
          "TITANIC BOONDOCK"
        ],
        [
          "TOOTSIE PILOT"
        ],
        [
          "TOURIST PELICAN"
        ],
        [
          "TRADING PINOCCHIO"
        ],
        [
          "TRAIN BUNCH"
        ],
        [
          "TRAMP OTHERS"
        ],
        [
          "TREASURE COMMAND"
        ],
        [
          "TREATMENT JEKYLL"
        ],
        [
          "TRIP NEWTON"
        ],
        [
          "TROJAN TOMORROW"
        ],
        [
          "TROOPERS METAL"
        ],
        [
          "TUXEDO MILE"
        ],
        [
          "TWISTED PIRATES"
        ],
        [
          "TYCOON GATHERING"
        ],
        [
          "UNBREAKABLE KARATE"
        ],
        [
          "UNFAITHFUL KILL"
        ],
        [
          "UNITED PILOT"
        ],
        [
          "UNTOUCHABLES SUNRISE"
        ],
        [
          "VALLEY PACKER"
        ],
        [
          "VANILLA DAY"
        ],
        [
          "VANISHED GARDEN"
        ],
        [
          "VARSITY TRIP"
        ],
        [
          "VIDEOTAPE ARSENIC"
        ],
        [
          "VIETNAM SMOOCHY"
        ],
        [
          "VIRGINIAN PLUTO"
        ],
        [
          "VIRTUAL SPOILERS"
        ],
        [
          "VISION TORQUE"
        ],
        [
          "VOLCANO TEXAS"
        ],
        [
          "WAGON JAWS"
        ],
        [
          "WAKE JAWS"
        ],
        [
          "WANDA CHAMBER"
        ],
        [
          "WAR NOTTING"
        ],
        [
          "WASTELAND DIVINE"
        ],
        [
          "WATCH TRACY"
        ],
        [
          "WEEKEND PERSONAL"
        ],
        [
          "WESTWARD SEABISCUIT"
        ],
        [
          "WHALE BIKINI"
        ],
        [
          "WHISPERER GIANT"
        ],
        [
          "WIFE TURN"
        ],
        [
          "WILD APOLLO"
        ],
        [
          "WIND PHANTOM"
        ],
        [
          "WINDOW SIDE"
        ],
        [
          "WISDOM WORKER"
        ],
        [
          "WIZARD COLDBLOODED"
        ],
        [
          "WOMEN DORADO"
        ],
        [
          "WORDS HUNTER"
        ],
        [
          "WORKING MICROCOSMOS"
        ],
        [
          "WORST BANGER"
        ],
        [
          "WYOMING STORM"
        ],
        [
          "YENTL IDAHO"
        ],
        [
          "ZHIVAGO CORE"
        ],
        [
          "ZOOLANDER FICTION"
        ]
      ],
      "pandas_converted": "film[film['special_features'].str.contains('Deleted Scenes')]['title']"
    },
    "generated_programs": [
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')][['title']]",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "t1 = film[film['special_features'].notnull()]\nanswer = t1[t1['special_features'].str.contains('deleted scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes', case=False)]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "t1 = film[film['special_features'].str.contains('Deleted Scenes')]\nanswer = t1['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes')]['title']",
      "answer = film[film['special_features'].str.contains('Deleted Scenes', na=False)]['title']",
      "t1 = film[film['special_features'].str.contains('Deleted Scenes')]\nanswer = t1['title']"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "driving_school",
      "query": "SELECT customer_status_code , count(*) FROM Customers GROUP BY customer_status_code;",
      "query_toks": [
        "SELECT",
        "customer_status_code",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Customers",
        "GROUP",
        "BY",
        "customer_status_code",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "customer_status_code",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "customers",
        "group",
        "by",
        "customer_status_code"
      ],
      "question": "For each customer status code, how many customers are classified that way?",
      "question_toks": [
        "For",
        "each",
        "customer",
        "status",
        "code",
        ",",
        "how",
        "many",
        "customers",
        "are",
        "classified",
        "that",
        "way",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  20,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            20,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "line_1_number_building",
          "city",
          "zip_postcode",
          "state_province_county",
          "country"
        ],
        "Staff": [
          "staff_id",
          "staff_address_id",
          "nickname",
          "first_name",
          "middle_name",
          "last_name",
          "date_of_birth",
          "date_joined_staff",
          "date_left_staff"
        ],
        "Vehicles": [
          "vehicle_id",
          "vehicle_details"
        ],
        "Customers": [
          "customer_id",
          "customer_address_id",
          "customer_status_code",
          "date_became_customer",
          "date_of_birth",
          "first_name",
          "last_name",
          "amount_outstanding",
          "email_address",
          "phone_number",
          "cell_mobile_phone_number"
        ],
        "Customer_Payments": [
          "customer_id",
          "datetime_payment",
          "payment_method_code",
          "amount_payment"
        ],
        "Lessons": [
          "lesson_id",
          "customer_id",
          "lesson_status_code",
          "staff_id",
          "vehicle_id",
          "lesson_date",
          "lesson_time",
          "price"
        ]
      },
      "answer": [
        [
          "Bad Customer",
          9
        ],
        [
          "Good Customer",
          6
        ]
      ]
    },
    "generated_programs": [
      "answer = Customers.groupby('customer_status_code')[['customer_id']].count()",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Customers.groupby('customer_status_code').size().rename('count')",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Customers.groupby('customer_status_code').size().to_frame().reset_index().rename(columns={0: 'count'})",
      "answer = Customers.groupby('customer_status_code').size().reset_index(name='count')",
      "answer = Customers.groupby(['customer_status_code']).size().rename('count')",
      "answer = Customers.groupby('customer_status_code').size().rename('count').to_frame().reset_index()",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Customers.groupby('customer_status_code').size().rename('count').to_frame().reset_index()",
      "answer = Customers.groupby('customer_status_code').size().rename('count').to_frame()",
      "answer = Customers.groupby('customer_status_code').count()[['staff_id']]",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Customers.groupby('customer_status_code').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Customers.groupby(['customer_status_code']).size().to_frame()\nt1 = t1.reset_index()\nanswer = t1.rename(columns={0: 'count'})",
      "answer = Customers.groupby('customer_status_code')['customer_id'].count()",
      "answer = Customers.groupby('customer_status_code').size().to_frame(name='count')",
      "t1 = Customers.groupby('customer_status_code')['customer_status_code'].size()\nanswer = t1.reset_index(name='count')",
      "answer = Customers.groupby('customer_status_code').size().rename('count').to_frame().reset_index()"
    ],
    "acc@20": 13,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "film_rank",
      "query": "SELECT TYPE FROM film_market_estimation WHERE YEAR  =  1995",
      "query_toks": [
        "SELECT",
        "TYPE",
        "FROM",
        "film_market_estimation",
        "WHERE",
        "YEAR",
        "=",
        "1995"
      ],
      "query_toks_no_value": [
        "select",
        "type",
        "from",
        "film_market_estimation",
        "where",
        "year",
        "=",
        "value"
      ],
      "question": "Return the types of film market estimations in 1995.",
      "question_toks": [
        "Return",
        "the",
        "types",
        "of",
        "film",
        "market",
        "estimations",
        "in",
        "1995",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  13,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                15,
                false
              ],
              null
            ],
            1995.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "film": [
          "Film_ID",
          "Title",
          "Studio",
          "Director",
          "Gross_in_dollar"
        ],
        "market": [
          "Market_ID",
          "Country",
          "Number_cities"
        ],
        "film_market_estimation": [
          "Estimation_ID",
          "Low_Estimate",
          "High_Estimate",
          "Film_ID",
          "Type",
          "Market_ID",
          "Year"
        ]
      },
      "answer": [
        [
          "Mass suicide"
        ]
      ]
    },
    "generated_programs": [
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "t1 = film_market_estimation[film_market_estimation['year'] == 1995]\nanswer = t1['type'].unique()",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type'].unique()",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type'].unique()",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "t1 = film_market_estimation[film_market_estimation['year'] == 1995]\nanswer = t1['type'].unique()",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "t1 = film_market_estimation[film_market_estimation['year'] == 1995]\nanswer = t1['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type'].unique()",
      "t1 = film_market_estimation[film_market_estimation['year'] == 1995]\nanswer = t1['type'].unique()",
      "answer = film_market_estimation['type'][film_market_estimation['year'] == 1995]",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type'].unique()",
      "answer = film_market_estimation[film_market_estimation['year'] == 1995]['type']"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "train_station",
      "query": "SELECT T2.name ,  T3.name FROM train_station AS T1 JOIN station AS T2 ON T1.station_id  =  T2.station_id JOIN train AS T3 ON T3.train_id  =  T1.train_id",
      "query_toks": [
        "SELECT",
        "T2.name",
        ",",
        "T3.name",
        "FROM",
        "train_station",
        "AS",
        "T1",
        "JOIN",
        "station",
        "AS",
        "T2",
        "ON",
        "T1.station_id",
        "=",
        "T2.station_id",
        "JOIN",
        "train",
        "AS",
        "T3",
        "ON",
        "T3.train_id",
        "=",
        "T1.train_id"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "name",
        ",",
        "t3",
        ".",
        "name",
        "from",
        "train_station",
        "as",
        "t1",
        "join",
        "station",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "station_id",
        "=",
        "t2",
        ".",
        "station_id",
        "join",
        "train",
        "as",
        "t3",
        "on",
        "t3",
        ".",
        "train_id",
        "=",
        "t1",
        ".",
        "train_id"
      ],
      "question": "show the train name and station name for each train.",
      "question_toks": [
        "show",
        "the",
        "train",
        "name",
        "and",
        "station",
        "name",
        "for",
        "each",
        "train",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ],
            "and",
            [
              false,
              2,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ],
              [
                0,
                13,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  10,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "station": [
          "Station_ID",
          "Name",
          "Annual_entry_exit",
          "Annual_interchanges",
          "Total_Passengers",
          "Location",
          "Main_Services",
          "Number_of_Platforms"
        ],
        "train": [
          "Train_ID",
          "Name",
          "Time",
          "Service"
        ],
        "train_station": [
          "Train_ID",
          "Station_ID"
        ]
      },
      "answer": [
        [
          "London Waterloo",
          "Ananthapuri Express"
        ],
        [
          "London Waterloo",
          "Guruvayur Express"
        ],
        [
          "London Waterloo",
          "Guruvayur Express"
        ],
        [
          "London Victoria",
          "Ananthapuri Express"
        ],
        [
          "London Bridge",
          "Jayanthi Janatha Express"
        ],
        [
          "London Euston",
          "Island Express"
        ],
        [
          "London King's Cross",
          "Madurai Fast Passenger"
        ],
        [
          "Glasgow Central",
          "Quilon Fast Passenger"
        ],
        [
          "Glasgow Central",
          "Island Express"
        ],
        [
          "East Croydon",
          "Jayanthi Janatha Express"
        ],
        [
          "East Croydon",
          "Parasuram Express"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['train_id', 'name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nanswer = pd.merge(t1, train, on='train_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, left_on='station_id', right_on='station_id')\nt2 = pd.merge(t1, train, left_on='train_id', right_on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nanswer = pd.merge(t1, train, on='train_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, train, left_on='train_id', right_on='train_id')\nt2 = pd.merge(t1, station, left_on='station_id', right_on='station_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id', how = 'left')\nt2 = pd.merge(t1, train, on = 'train_id', how = 'left')\nanswer = t2[['train_id', 'name_y', 'name_x']]",
      "t1 = pd.merge(train_station, station, left_on='station_id', right_on='station_id')\nanswer = pd.merge(train, t1, on='train_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, left_on='station_id', right_on='station_id')\nanswer = pd.merge(t1, train, left_on='train_id', right_on='train_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, left_on='station_id', right_on='station_id')\nt2 = pd.merge(t1, train, left_on='train_id', right_on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]",
      "t1 = pd.merge(train_station, station, on='station_id')\nt2 = pd.merge(t1, train, on='train_id')\nanswer = t2[['name_x', 'name_y']]"
    ],
    "acc@20": 16,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "sports_competition",
      "query": "SELECT Competition_type ,  Country FROM competition",
      "query_toks": [
        "SELECT",
        "Competition_type",
        ",",
        "Country",
        "FROM",
        "competition"
      ],
      "query_toks_no_value": [
        "select",
        "competition_type",
        ",",
        "country",
        "from",
        "competition"
      ],
      "question": "What are the types and countries of competitions?",
      "question_toks": [
        "What",
        "are",
        "the",
        "types",
        "and",
        "countries",
        "of",
        "competitions",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  21,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  22,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "club": [
          "Club_ID",
          "name",
          "Region",
          "Start_year"
        ],
        "club_rank": [
          "Rank",
          "Club_ID",
          "Gold",
          "Silver",
          "Bronze",
          "Total"
        ],
        "player": [
          "Player_ID",
          "name",
          "Position",
          "Club_ID",
          "Apps",
          "Tries",
          "Goals",
          "Points"
        ],
        "competition": [
          "Competition_ID",
          "Year",
          "Competition_type",
          "Country"
        ],
        "competition_result": [
          "Competition_ID",
          "Club_ID_1",
          "Club_ID_2",
          "Score"
        ]
      },
      "answer": [
        [
          "Friendly",
          "Italy"
        ],
        [
          "Friendly",
          "Spain"
        ],
        [
          "Friendly",
          "Australia"
        ],
        [
          "Friendly",
          "Russia"
        ],
        [
          "Friendly",
          "Russia"
        ],
        [
          "Friendly",
          "Australia"
        ],
        [
          "Tournament",
          "Russia"
        ],
        [
          "Tournament",
          "Slovenia"
        ],
        [
          "Tournament",
          "Slovenia"
        ],
        [
          "Friendly",
          "Italy"
        ],
        [
          "Friendly",
          "Ireland"
        ]
      ],
      "pandas_converted": "competition[['competition_type', 'country']]"
    },
    "generated_programs": [
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type','country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "t1 = competition[['competition_type', 'country']]\nt1.columns = ['type', 'country']\nanswer = t1",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "t1 = competition[['competition_type', 'country']]\nanswer = t1.drop_duplicates()",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]",
      "answer = competition[['competition_type', 'country']]"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "theme_gallery",
      "query": "SELECT name ,  age ,  country FROM artist ORDER BY Year_Join",
      "query_toks": [
        "SELECT",
        "name",
        ",",
        "age",
        ",",
        "country",
        "FROM",
        "artist",
        "ORDER",
        "BY",
        "Year_Join"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        ",",
        "age",
        ",",
        "country",
        "from",
        "artist",
        "order",
        "by",
        "year_join"
      ],
      "question": "What are the names, ages, and countries of artists, sorted by the year they joined?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        ",",
        "ages",
        ",",
        "and",
        "countries",
        "of",
        "artists",
        ",",
        "sorted",
        "by",
        "the",
        "year",
        "they",
        "joined",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                4,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artist": [
          "Artist_ID",
          "Name",
          "Country",
          "Year_Join",
          "Age"
        ],
        "exhibition": [
          "Exhibition_ID",
          "Year",
          "Theme",
          "Artist_ID",
          "Ticket_Price"
        ],
        "exhibition_record": [
          "Exhibition_ID",
          "Date",
          "Attendance"
        ]
      },
      "answer": [
        [
          "Larry Nelson",
          50,
          "United States"
        ],
        [
          "Jeff Sluman",
          57,
          "United States"
        ],
        [
          "John Daly",
          46,
          "United States"
        ],
        [
          "Paul Azinger",
          47,
          "United States"
        ],
        [
          "Nick Price",
          48,
          "Zimbabwe"
        ],
        [
          "Mark Brooks",
          48,
          "United States"
        ],
        [
          "Vijay Singh",
          45,
          "Fiji"
        ]
      ]
    },
    "generated_programs": [
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist.sort_values('year_join').loc[:, ['name', 'age', 'country']]",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join')",
      "answer = artist[['name', 'age', 'country']].sort_values('year_join', ascending = True)"
    ],
    "acc@20": 1,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "cre_Drama_Workshop_Groups",
      "query": "SELECT payment_method_code FROM INVOICES GROUP BY payment_method_code ORDER BY count(*) DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "payment_method_code",
        "FROM",
        "INVOICES",
        "GROUP",
        "BY",
        "payment_method_code",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "payment_method_code",
        "from",
        "invoices",
        "group",
        "by",
        "payment_method_code",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "What is the payment method code used by the most orders?",
      "question_toks": [
        "What",
        "is",
        "the",
        "payment",
        "method",
        "code",
        "used",
        "by",
        "the",
        "most",
        "orders",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              14
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  79,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            79,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Payment_Methods": [
          "payment_method_code",
          "payment_method_description"
        ],
        "Ref_Service_Types": [
          "Service_Type_Code",
          "Parent_Service_Type_Code",
          "Service_Type_Description"
        ],
        "Addresses": [
          "Address_ID",
          "Line_1",
          "Line_2",
          "City_Town",
          "State_County",
          "Other_Details"
        ],
        "Products": [
          "Product_ID",
          "Product_Name",
          "Product_Price",
          "Product_Description",
          "Other_Product_Service_Details"
        ],
        "Marketing_Regions": [
          "Marketing_Region_Code",
          "Marketing_Region_Name",
          "Marketing_Region_Descriptrion",
          "Other_Details"
        ],
        "Clients": [
          "Client_ID",
          "Address_ID",
          "Customer_Email_Address",
          "Customer_Name",
          "Customer_Phone",
          "Other_Details"
        ],
        "Drama_Workshop_Groups": [
          "Workshop_Group_ID",
          "Address_ID",
          "Currency_Code",
          "Marketing_Region_Code",
          "Store_Name",
          "Store_Phone",
          "Store_Email_Address",
          "Other_Details"
        ],
        "Performers": [
          "Performer_ID",
          "Address_ID",
          "Customer_Name",
          "Customer_Phone",
          "Customer_Email_Address",
          "Other_Details"
        ],
        "Customers": [
          "Customer_ID",
          "Address_ID",
          "Customer_Name",
          "Customer_Phone",
          "Customer_Email_Address",
          "Other_Details"
        ],
        "Stores": [
          "Store_ID",
          "Address_ID",
          "Marketing_Region_Code",
          "Store_Name",
          "Store_Phone",
          "Store_Email_Address",
          "Other_Details"
        ],
        "Bookings": [
          "Booking_ID",
          "Customer_ID",
          "Workshop_Group_ID",
          "Status_Code",
          "Store_ID",
          "Order_Date",
          "Planned_Delivery_Date",
          "Actual_Delivery_Date",
          "Other_Order_Details"
        ],
        "Performers_in_Bookings": [
          "Order_ID",
          "Performer_ID"
        ],
        "Customer_Orders": [
          "Order_ID",
          "Customer_ID",
          "Store_ID",
          "Order_Date",
          "Planned_Delivery_Date",
          "Actual_Delivery_Date",
          "Other_Order_Details"
        ],
        "Order_Items": [
          "Order_Item_ID",
          "Order_ID",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details"
        ],
        "Invoices": [
          "Invoice_ID",
          "Order_ID",
          "payment_method_code",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details",
          "Order_Item_ID"
        ],
        "Services": [
          "Service_ID",
          "Service_Type_Code",
          "Workshop_Group_ID",
          "Product_Description",
          "Product_Name",
          "Product_Price",
          "Other_Product_Service_Details"
        ],
        "Bookings_Services": [
          "Order_ID",
          "Product_ID"
        ],
        "Invoice_Items": [
          "Invoice_Item_ID",
          "Invoice_ID",
          "Order_ID",
          "Order_Item_ID",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details"
        ]
      },
      "answer": [
        [
          "MasterCard"
        ]
      ]
    },
    "generated_programs": [
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2= t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.to_frame().sort_values('count', ascending=False)\nanswer = t2['payment_method_code'].head(1)",
      "t1=Invoices['payment_method_code'].value_counts().index[0]\nanswer =  pd.Series(t1)",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2= t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending = False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count').sort_values(ascending=False)\nanswer = t1.head(1).reset_index()['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2= t1.sort_values(ascending=False).head(1).to_frame()\nanswer = t2.index.values",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices[['payment_method_code']].groupby('payment_method_code').size().rename('count')\nt2 = pd.DataFrame(t1.to_frame().reset_index())\nt3 = t2.sort_values('count', ascending=False).reset_index()\nanswer = t3['payment_method_code'].head(1)",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2= t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']",
      "t1 = Invoices.groupby('payment_method_code').size()\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['payment_method_code']"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "dorm_1",
      "query": "SELECT fname FROM student WHERE city_code  =  'PHL' AND age BETWEEN 20 AND 25",
      "query_toks": [
        "SELECT",
        "fname",
        "FROM",
        "student",
        "WHERE",
        "city_code",
        "=",
        "'PHL",
        "'",
        "AND",
        "age",
        "BETWEEN",
        "20",
        "AND",
        "25"
      ],
      "query_toks_no_value": [
        "select",
        "fname",
        "from",
        "student",
        "where",
        "city_code",
        "=",
        "value",
        "and",
        "age",
        "between",
        "value",
        "and",
        "value"
      ],
      "question": "Find the first name of students living in city PHL whose age is between 20 and 25.",
      "question_toks": [
        "Find",
        "the",
        "first",
        "name",
        "of",
        "students",
        "living",
        "in",
        "city",
        "PHL",
        "whose",
        "age",
        "is",
        "between",
        "20",
        "and",
        "25",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                8,
                false
              ],
              null
            ],
            "\"PHL\"",
            null
          ],
          "and",
          [
            false,
            1,
            [
              0,
              [
                0,
                4,
                false
              ],
              null
            ],
            20.0,
            25.0
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ],
        "Dorm": [
          "dormid",
          "dorm_name",
          "student_capacity",
          "gender"
        ],
        "Dorm_amenity": [
          "amenid",
          "amenity_name"
        ],
        "Has_amenity": [
          "dormid",
          "amenid"
        ],
        "Lives_in": [
          "stuid",
          "dormid",
          "room_number"
        ]
      },
      "answer": [
        [
          "David"
        ],
        [
          "Sarah"
        ]
      ]
    },
    "generated_programs": [
      "t1 = Student[Student['city_code'] == 'phl']\nanswer = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nanswer = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]['fname']",
      "t1 = pd.merge(Student, Lives_in, on='stuid')\nt2 = t1[(t1['age'] > 20) & (t1['age'] < 25) & (t1['city_code'] == 'PHL')]\nanswer = t2['fname']",
      "t1 = Student[Student['city_code'] == 'phl']\nt2 = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]\nanswer = t2['fname']",
      "t1 = Student[(Student['city_code'] == 'PHL') & (Student['age'] >= 20) & (Student['age'] <= 25)]\nanswer = t1['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nt2 = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]\nanswer = t2['fname']",
      "t1 = pd.merge(Student, Lives_in, left_on='stuid', right_on='stuid')\nt2 = pd.merge(t1, Dorm, on='dormid')\nt3 = t2[(t2['age'] >= 20) & (t2['age'] <= 25)]\nanswer = t3['fname']",
      "t1 = Student[Student['age'].between(20, 25)]\nt2 = t1[t1['city_code'] == 'PHL']\nanswer = t2['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nanswer = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]['fname']",
      "t1 = Student[Student['city_code'] == 'phl']\nanswer = t1[t1['age'].between(20, 25, inclusive=True)]['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nt2 = t1[(t1['age'] > 20) & (t1['age'] < 25)]\nanswer = t2['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nt2 = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]\nanswer = t2['fname']",
      "answer = Student[Student['city_code'] == 'PHL'].loc[(Student['age'] >= 20) & (Student['age'] <= 25)]['fname']",
      "t1 = Student[['fname', 'city_code', 'age']]\nt2 = t1[t1['city_code'] == 'PHL']\nt3 = t2[(t2['age'] >= 20) & (t2['age'] <= 25)]\nanswer = t3['fname']",
      "t1 = pd.merge(Student, Lives_in, on='stuid')\nanswer = t1[(t1['age'] >= 20) & (t1['age'] <= 25) & (t1['city_code'] == 'PHL')]['fname']",
      "t1 = pd.merge(Student, Lives_in, on='stuid')\nt2 = t1[t1['city_code'] == 'PHL']\nt3 = t2[(t2['age'] >= 20) & (t2['age'] <= 25)]\nanswer = t3['fname']",
      "t1 = Student[Student['city_code'] == 'PHL']\nanswer = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]['fname']",
      "t1 = pd.merge(Student, Lives_in, on='stuid')",
      "t1 = pd.merge(Student, Lives_in, left_on='stuid', right_on='stuid')\nt2 = pd.merge(t1, Dorm, left_on='dormid', right_on='dormid')\nt3 = t2[(t2['age'] >= 20) & (t2['age'] <= 25) & (t2['city_code'] == 'phl')]\nanswer = t3['fname']",
      "t1 = pd.merge(Student, Lives_in, on='stuid')\nt2 = t1[(t1['age'] >= 20) & (t1['age'] <= 25)]\nanswer = t2[t2['city_code'] == 'PHL']['fname']"
    ],
    "acc@20": 12,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT T1.first_name ,  T1.last_name ,  SUM(T2.total) FROM customers AS T1 JOIN invoices AS T2 ON T2.customer_id  =  T1.id GROUP BY T1.id ORDER BY SUM(T2.total) DESC LIMIT 10;",
      "query_toks": [
        "SELECT",
        "T1.first_name",
        ",",
        "T1.last_name",
        ",",
        "SUM",
        "(",
        "T2.total",
        ")",
        "FROM",
        "customers",
        "AS",
        "T1",
        "JOIN",
        "invoices",
        "AS",
        "T2",
        "ON",
        "T2.customer_id",
        "=",
        "T1.id",
        "GROUP",
        "BY",
        "T1.id",
        "ORDER",
        "BY",
        "SUM",
        "(",
        "T2.total",
        ")",
        "DESC",
        "LIMIT",
        "10",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "first_name",
        ",",
        "t1",
        ".",
        "last_name",
        ",",
        "sum",
        "(",
        "t2",
        ".",
        "total",
        ")",
        "from",
        "customers",
        "as",
        "t1",
        "join",
        "invoices",
        "as",
        "t2",
        "on",
        "t2",
        ".",
        "customer_id",
        "=",
        "t1",
        ".",
        "id",
        "group",
        "by",
        "t1",
        ".",
        "id",
        "order",
        "by",
        "sum",
        "(",
        "t2",
        ".",
        "total",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "What are the top 10 customers' first and last names with the highest gross sales, and also what are the sales?",
      "question_toks": [
        "What",
        "are",
        "the",
        "top",
        "10",
        "customers",
        "'",
        "first",
        "and",
        "last",
        "names",
        "with",
        "the",
        "highest",
        "gross",
        "sales",
        ",",
        "and",
        "also",
        "what",
        "are",
        "the",
        "sales",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ],
            [
              "table_unit",
              6
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  39,
                  false
                ],
                null
              ],
              [
                0,
                23,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  24,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  25,
                  false
                ],
                null
              ]
            ],
            [
              4,
              [
                0,
                [
                  0,
                  46,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            23,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                4,
                46,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 10,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "Helena",
          "Hol\u00fd",
          49.620000000000005
        ],
        [
          "Richard",
          "Cunningham",
          47.620000000000005
        ],
        [
          "Luis",
          "Rojas",
          46.62
        ],
        [
          "Ladislav",
          "Kov\u00e1cs",
          45.62
        ],
        [
          "Hugh",
          "O'Reilly",
          45.62
        ],
        [
          "Julia",
          "Barnett",
          43.620000000000005
        ],
        [
          "Frank",
          "Ralston",
          43.62
        ],
        [
          "Fynn",
          "Zimmermann",
          43.62
        ],
        [
          "Astrid",
          "Gruber",
          42.62
        ],
        [
          "Victor",
          "Stevens",
          42.62
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(customers, invoices, on='id')\nt2 = t1.groupby(['id', 'first_name', 'last_name']).agg({'total': 'sum'}).rename(columns={'total': 'gross_sales'})\nanswer = t2.sort_values('gross_sales', ascending=False).head(10)",
      "t1 = pd.merge(customers, invoices, left_on='id', right_on='customer_id')\nt2 = t1.groupby('customer_id').sum()['total'].rename('sum')\nt3 = pd.merge(customers, t2.to_frame(), left_on='id', right_on='customer_id')\nanswer = t3[['first_name', 'last_name', 'sum']].sort_values('sum', ascending=False).head(10)",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby('id')['total'].sum().rename('total_sales')\nt3 = pd.DataFrame({'first_name': customers['first_name'], 'last_name': customers['last_name']})\nt4 = pd.concat([t2, t3], axis=1)\nanswer = t4.sort_values('total_sales', ascending=False)[['first_name', 'last_name', 'total_sales']].head(10)",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby('id').agg({'first_name': 'max', 'last_name': 'max', 'total': 'sum'})\nanswer = t2[['first_name', 'last_name', 'total']].sort_values('total', ascending=False).head(10)",
      "t1 = pd.merge(customers, invoices, left_on='id', right_on='customer_id')\nt2 = t1.groupby(['first_name', 'last_name'])['total'].sum()\nanswer = t2.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(customers, invoices, on='id')\nt2 = t1.groupby(['id', 'first_name', 'last_name'])['total'].aggregate(np.sum).rename('gross_sales')\nanswer = t2.sort_values(ascending = False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby('id')['total'].sum().rename('gross_sales')\nt3 = pd.merge(customers, t2.to_frame(), left_on='id', right_index=True)\nanswer = t3[['first_name', 'last_name', 'gross_sales']].sort_values('gross_sales', ascending = False).head(10)",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby('id_x').sum().reset_index().sort_values('total', ascending=False).head(10)\n# Keep required columns only\nanswer = t2[['id_x', 'first_name', 'last_name', 'total']]",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby('id').sum().sort_values('total', ascending=False).head(10).reset_index()\nt3 = pd.merge(t2, customers, on='id')\nanswer = t3[['first_name', 'last_name', 'total']]",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby(['first_name', 'last_name']).sum()\nanswer = t2[['total']].sort_values('total', ascending=False).head(10).reset_index()",
      "t1 = customers.rename({'id': 'customer_id'}, axis = 1)\nt2 = pd.merge(t1, invoices, on='customer_id')\nt3 = t2.groupby('customer_id').agg({'first_name': 'first', 'last_name': 'first', 'total': 'sum'})\nt4 = t3.sort_values('total', ascending = False).head(10)\nanswer = t4",
      "t1 = pd.merge(customers, invoices, left_on='id', right_on='customer_id')\nt2 = t1.groupby('id')['total'].sum().sort_values(ascending=False).head(10).to_frame().reset_index()\nt3 = pd.merge(t2, customers, on='id')\nanswer = t3[['first_name', 'last_name', 'total']]",
      "t1 = customers.set_index('id').add_prefix('customer_')\nt2 = invoices.set_index('customer_id')\nt1 = pd.merge(t1, t2, how='inner', left_index=True, right_index=True)\nt3 = t1[['first_name', 'last_name', 'total']].groupby(['first_name', 'last_name']).sum()\nt4 = t3.sort_values('total', ascending=False).head(10).reset_index()\nanswer = t4[['first_name', 'last_name', 'total']]",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby('id').sum()\nanswer = t2.sort_values('total', ascending=False).head(10).reset_index()[['last_name', 'first_name', 'total']]",
      "t1 = customers.set_index('id')\nt2 = invoices.set_index('customer_id').drop('id', axis=1)\nt3 = pd.merge(t1, t2, left_index=True, right_index=True)\nt4 = t3.groupby(level=0).sum()\nt5 = t4.sort_values('total', ascending=False).head(10)\nt6 = t5.reset_index()\nt7 = t6.set_index('id')\nt8 = t7.join(customers.set_index('id'), how='left')\nanswer = t8[['first_name', 'last_name', 'total']]",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby(['first_name', 'last_name']).sum()['total']\nanswer = t2.sort_values(ascending=False).head(10).to_frame().reset_index()",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby(['first_name', 'last_name']).sum().nlargest(10, 'total').reset_index()\nanswer = t2[['first_name', 'last_name', 'total']]",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nanswer = t1.groupby(['first_name', 'last_name'])['total'].sum().to_frame().sort_values('total', ascending=False).head(10).reset_index()",
      "t1 = pd.merge(customers, invoices, on='customer_id')\nt2 = t1.groupby(['first_name', 'last_name'])['total'].sum().rename('total').sort_values(ascending=False)\nanswer = t2.head(10).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, left_on='customer_id', right_on='id', suffixes=('_invoices', '_customers'))\nanswer = (t1.groupby(['first_name', 'last_name'])['total'].sum().\n          sort_values(ascending=False).head(10).to_frame().reset_index())"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "inn_1",
      "query": "SELECT bedType ,  avg(basePrice) FROM Rooms GROUP BY bedType;",
      "query_toks": [
        "SELECT",
        "bedType",
        ",",
        "avg",
        "(",
        "basePrice",
        ")",
        "FROM",
        "Rooms",
        "GROUP",
        "BY",
        "bedType",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "bedtype",
        ",",
        "avg",
        "(",
        "baseprice",
        ")",
        "from",
        "rooms",
        "group",
        "by",
        "bedtype"
      ],
      "question": "For each bed type, find the average room price.",
      "question_toks": [
        "For",
        "each",
        "bed",
        "type",
        ",",
        "find",
        "the",
        "average",
        "room",
        "price",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ],
            [
              5,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            4,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Rooms": [
          "RoomId",
          "roomName",
          "beds",
          "bedType",
          "maxOccupancy",
          "basePrice",
          "decor"
        ],
        "Reservations": [
          "Code",
          "Room",
          "CheckIn",
          "CheckOut",
          "Rate",
          "LastName",
          "FirstName",
          "Adults",
          "Kids"
        ]
      },
      "answer": [
        [
          "Double",
          100.0
        ],
        [
          "King",
          181.25
        ],
        [
          "Queen",
          150.0
        ]
      ]
    },
    "generated_programs": [
      "answer = Rooms.groupby('bedtype').aggregate({'baseprice' : np.mean}).rename(index=str, columns={'baseprice': 'avg_baseprice'})",
      "t1 = Rooms.groupby('bedtype').mean()\nanswer = t1['baseprice'].to_frame().reset_index()",
      "t1 = Rooms.groupby(['bedtype']).mean().drop(['maxoccupancy'], axis=1).reset_index()\nanswer = t1[['bedtype', 'baseprice']]",
      "answer = Rooms.groupby('bedtype').agg({'baseprice': np.mean})",
      "t1 = Rooms.groupby('bedtype').size()\nanswer = Rooms.groupby('bedtype')['baseprice'].mean()",
      "t = Rooms.groupby('bedtype').mean()\nanswer = t['baseprice'].to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().to_frame().reset_index().rename(columns={'baseprice': 'price'})",
      "t1 = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg')\nanswer = t1.to_frame().reset_index()",
      "t1 = Rooms.groupby(['bedtype']).agg({'baseprice':np.mean}).reset_index()\nanswer = pd.DataFrame(t1, columns = ['bedtype', 'avg(baseprice)'])",
      "answer = Rooms.groupby('bedtype').agg({'baseprice': 'mean'})",
      "answer = Rooms.groupby('bedtype').agg({'baseprice': 'mean'}).rename(columns = {'baseprice': 'avg(baseprice)'})",
      "answer = Rooms.groupby('bedtype').mean()['baseprice']",
      "t1 = Rooms.groupby('bedtype')['baseprice'].mean()\nanswer = t1.to_frame()",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = Rooms.groupby('bedtype').mean()['baseprice']",
      "answer = Rooms.groupby('bedtype').mean()[['baseprice']]",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype').mean().reset_index()\nanswer = t1[['bedtype', 'baseprice']]",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg_price')",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg_baseprice').to_frame()",
      "t1 = Rooms.groupby('bedtype')[['baseprice']].mean()\nanswer = t1.rename(columns={'baseprice':'avg_baseprice'})"
    ],
    "acc@20": 7,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "storm_record",
      "query": "SELECT T1.name ,  T1.max_speed FROM storm AS T1 JOIN affected_region AS T2 ON T1.storm_id  =  T2.storm_id GROUP BY T1.storm_id ORDER BY count(*) DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "T1.name",
        ",",
        "T1.max_speed",
        "FROM",
        "storm",
        "AS",
        "T1",
        "JOIN",
        "affected_region",
        "AS",
        "T2",
        "ON",
        "T1.storm_id",
        "=",
        "T2.storm_id",
        "GROUP",
        "BY",
        "T1.storm_id",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "name",
        ",",
        "t1",
        ".",
        "max_speed",
        "from",
        "storm",
        "as",
        "t1",
        "join",
        "affected_region",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "storm_id",
        "=",
        "t2",
        ".",
        "storm_id",
        "group",
        "by",
        "t1",
        ".",
        "storm_id",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "What is the storm name and max speed which affected the greatest number of regions?",
      "question_toks": [
        "What",
        "is",
        "the",
        "storm",
        "name",
        "and",
        "max",
        "speed",
        "which",
        "affected",
        "the",
        "greatest",
        "number",
        "of",
        "regions",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              2
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                11,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            1,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "storm": [
          "Storm_ID",
          "Name",
          "Dates_active",
          "Max_speed",
          "Damage_millions_USD",
          "Number_Deaths"
        ],
        "region": [
          "Region_id",
          "Region_code",
          "Region_name"
        ],
        "affected_region": [
          "Region_id",
          "Storm_ID",
          "Number_city_affected"
        ]
      },
      "answer": [
        [
          "Five",
          988
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(storm, affected_region, left_index=True, right_on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = pd.merge(storm, t2.to_frame().reset_index()).sort_values('count', ascending=False).reset_index(drop=True)\nanswer = t3[['name', 'max_speed']].iloc[0]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id')['number_city_affected'].size().rename('count')\nt3 = pd.merge(t2.to_frame().reset_index(), storm, how='left', on='storm_id')\nt4 = t3.sort_values('count', ascending=False).head(1)\nanswer = t4[['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nt4 = pd.merge(t3, storm, on='storm_id')\nanswer = t4.loc[:, ['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, left_on='storm_id', right_on='storm_id')\nt2 = t1.groupby(['storm_id', 'name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index().drop('count', axis=1)",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby(['storm_id', 'name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index()[['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby(['name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index()",
      "t1 = pd.merge(storm, affected_region, left_on='storm_id', right_on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = storm[storm['storm_id'] == t3['storm_id'].values[0]][['name', 'max_speed']]",
      "t1=pd.merge(storm, affected_region, left_on='storm_id', right_on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count').to_frame().reset_index()\nt3 = pd.merge(storm, t2, on='storm_id', how='right')\nanswer = t3[['name', 'max_speed']].sort_values('count', ascending = False).head(1)",
      "t1 = pd.merge(storm, affected_region, left_on='storm_id', right_on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = pd.merge(t2.to_frame().reset_index(), storm, left_on='storm_id', right_on='storm_id')\nanswer = t3[['name', 'max_speed']].sort_values('count', ascending = False).head(1)",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = storm[storm['storm_id'] == t3.iloc[0]['storm_id']][['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending = False).head(1).to_frame()\nt4 = pd.merge(storm, t3.reset_index(), on = 'storm_id')\nanswer = t4[['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby(['storm_id', 'name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index().drop('count', axis = 1)",
      "t1 = storm.merge(affected_region, left_on='storm_id', right_on='storm_id', how='inner')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nt4 = storm.merge(t3, left_on='storm_id', right_on='storm_id', how='inner')\nanswer = t4[['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count').to_frame().reset_index()\nt3 = t2.sort_values(by='count', ascending=False).head(1)\nt4 = pd.merge(t3, storm, on='storm_id')\nanswer = t4[['name', 'max_speed']]",
      "t1 = pd.merge(affected_region, storm, on='storm_id')\nanswer_1 = t1.groupby(['name', 'max_speed']).size().rename('count').sort_values(ascending=False).head(1).index.values[0]\nanswer_2 = t1.groupby(['name', 'max_speed']).size().rename('count').sort_values(ascending=False).head(1).index.values[1]\nanswer = pd.Series([answer_1, answer_2])",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id', as_index=False).size().rename('count')\nt3 = pd.merge(storm, t2, on='storm_id')\nanswer = t3[t3['count'] == t3['count'].max()][['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, left_on='storm_id', right_on='storm_id')\nt2 = t1.groupby(['name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index()",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby(['storm_id', 'name', 'max_speed']).size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index()[['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id')['region_id'].count().to_frame().reset_index()\nt3 = pd.merge(t2, storm, on='storm_id')\nanswer = t3[t3['region_id'] == t3['region_id'].max()][['name', 'max_speed']]",
      "t1 = pd.merge(storm, affected_region, on='storm_id')\nt2 = t1.groupby('storm_id').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nt4 = pd.merge(t3, storm, on='storm_id')\nanswer = t4[['name', 'max_speed']]"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT billing_country ,  COUNT(*) FROM invoices GROUP BY billing_country ORDER BY count(*) DESC LIMIT 5;",
      "query_toks": [
        "SELECT",
        "billing_country",
        ",",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "invoices",
        "GROUP",
        "BY",
        "billing_country",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "DESC",
        "LIMIT",
        "5",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "billing_country",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "invoices",
        "group",
        "by",
        "billing_country",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "A list of the top 5 countries by number of invoices. List country name and number of invoices.",
      "question_toks": [
        "A",
        "list",
        "of",
        "the",
        "top",
        "5",
        "countries",
        "by",
        "number",
        "of",
        "invoices",
        ".",
        "List",
        "country",
        "name",
        "and",
        "number",
        "of",
        "invoices",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              6
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  44,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            44,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 5,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "USA",
          91
        ],
        [
          "Canada",
          56
        ],
        [
          "France",
          35
        ],
        [
          "Brazil",
          35
        ],
        [
          "Germany",
          28
        ]
      ]
    },
    "generated_programs": [
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t2[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t2",
      "t1 = invoices.groupby('billing_country').size().rename('count').sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t1",
      "t1 = invoices.groupby('billing_country').size().rename('count').to_frame()\nanswer = t1.sort_values('count', ascending=False).head(5).reset_index()",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t2[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nanswer = t1.sort_values(ascending=False).head(5).to_frame().reset_index()",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = t1.sort_values(ascending = False).head(5)\nt3 = t2.to_frame().reset_index()\nanswer = t3[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count').to_frame().reset_index()\nt2 = t1.sort_values('count', ascending=False).head(5)\nanswer = t2[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count').to_frame().reset_index()\nanswer = t1.sort_values('count', ascending = False).head(5)",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nanswer = t1.sort_values(ascending=False).head(5).to_frame().reset_index()",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nanswer = t1.sort_values(ascending=False).head(5).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, left_on='customer_id', right_on='id')\nt2 = t1.groupby('billing_country').size().rename('count').sort_values(ascending=False).head(5)\nanswer = t2[t2 > 0].to_frame().reset_index()",
      "t1 = invoices.groupby('billing_country').size().rename('count').reset_index()\nanswer = t1.sort_values(by='count', ascending=False).head(5)",
      "answer = invoices.groupby('billing_country').size().sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer.columns = ['billing_country', 'count']",
      "answer = invoices.groupby('billing_country').size().nlargest(5).to_frame().reset_index()",
      "t1 = pd.merge(invoices, customers, on='customer_id')\nt2 = t1.groupby(['billing_country']).size().rename('count')\nt3 = t2.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t3[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nanswer = t1.sort_values(ascending=False).head(5).to_frame().reset_index()",
      "invoices_country_counts = invoices['billing_country'].value_counts()\nanswer = pd.concat([invoices_country_counts.rename('count').head(5)], axis=1, sort=False)",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t2[['billing_country', 'count']]",
      "t1 = invoices.groupby('billing_country').size().rename('count')\nt2= t1.sort_values(ascending=False).head(5).to_frame().reset_index()\nanswer = t2[['billing_country', 'count']]"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "college_1",
      "query": "SELECT dept_name FROM department ORDER BY dept_name",
      "query_toks": [
        "SELECT",
        "dept_name",
        "FROM",
        "department",
        "ORDER",
        "BY",
        "dept_name"
      ],
      "query_toks_no_value": [
        "select",
        "dept_name",
        "from",
        "department",
        "order",
        "by",
        "dept_name"
      ],
      "question": "What are the names of all departments in alphabetical order?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "all",
        "departments",
        "in",
        "alphabetical",
        "order",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  12,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                12,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "CLASS": [
          "CLASS_CODE",
          "CRS_CODE",
          "CLASS_SECTION",
          "CLASS_TIME",
          "CLASS_ROOM",
          "PROF_NUM"
        ],
        "COURSE": [
          "CRS_CODE",
          "DEPT_CODE",
          "CRS_DESCRIPTION",
          "CRS_CREDIT"
        ],
        "DEPARTMENT": [
          "DEPT_CODE",
          "DEPT_NAME",
          "SCHOOL_CODE",
          "EMP_NUM",
          "DEPT_ADDRESS",
          "DEPT_EXTENSION"
        ],
        "EMPLOYEE": [
          "EMP_NUM",
          "EMP_LNAME",
          "EMP_FNAME",
          "EMP_INITIAL",
          "EMP_JOBCODE",
          "EMP_HIREDATE",
          "EMP_DOB"
        ],
        "ENROLL": [
          "CLASS_CODE",
          "STU_NUM",
          "ENROLL_GRADE"
        ],
        "PROFESSOR": [
          "EMP_NUM",
          "DEPT_CODE",
          "PROF_OFFICE",
          "PROF_EXTENSION",
          "PROF_HIGH_DEGREE"
        ],
        "STUDENT": [
          "STU_NUM",
          "STU_LNAME",
          "STU_FNAME",
          "STU_INIT",
          "STU_DOB",
          "STU_HRS",
          "STU_CLASS",
          "STU_GPA",
          "STU_TRANSFER",
          "DEPT_CODE",
          "STU_PHONE",
          "PROF_NUM"
        ]
      },
      "answer": [
        [
          "Accounting"
        ],
        [
          "Biology"
        ],
        [
          "Computer Info. Systems"
        ],
        [
          "Economics/Finance"
        ],
        [
          "English"
        ],
        [
          "Fine Arts"
        ],
        [
          "History"
        ],
        [
          "Marketing/Management"
        ],
        [
          "Mathematics"
        ],
        [
          "Psychology"
        ],
        [
          "Sociology"
        ]
      ]
    },
    "generated_programs": [
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name')",
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name', ascending = True)",
      "answer = DEPARTMENT['dept_name'].sort_values()",
      "answer = DEPARTMENT['dept_name'].sort_values(ascending=True)",
      "answer = DEPARTMENT['dept_name'].sort_values()",
      "answer = DEPARTMENT['dept_name'].sort_values()",
      "answer = DEPARTMENT.sort_values('dept_name')['dept_name']",
      "answer = DEPARTMENT.sort_values('dept_name')['dept_name']",
      "answer = DEPARTMENT['dept_name'].sort_values(ascending = True)",
      "answer = department.sort_values('dept_name')['dept_name']",
      "answer = DEPARTMENT['dept_name'].sort_values()",
      "answer = DEPARTMENT[['dept_name']].sort_values(by='dept_name')",
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name', ascending = True)",
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name', ascending = True)",
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name')",
      "answer = pd.Series(DEPARTMENT.sort_values('dept_name')['dept_name'])",
      "answer = DEPARTMENT[['dept_name']].sort_values('dept_name', ascending=True)",
      "t1 = DEPARTMENT.sort_values('dept_name')\nanswer = t1['dept_name'].reset_index(drop=True)",
      "answer = DEPARTMENT[['dept_name']].sort_values(by='dept_name')",
      "answer = DEPARTMENT[['dept_name']].sort_values(by='dept_name')"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "wedding",
      "query": "SELECT count(*) FROM Church WHERE Open_Date  <  1850",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Church",
        "WHERE",
        "Open_Date",
        "<",
        "1850"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "church",
        "where",
        "open_date",
        "<",
        "value"
      ],
      "question": "How many churches opened before 1850 are there?",
      "question_toks": [
        "How",
        "many",
        "churches",
        "opened",
        "before",
        "1850",
        "are",
        "there",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            4,
            [
              0,
              [
                0,
                9,
                false
              ],
              null
            ],
            1850.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "people": [
          "People_ID",
          "Name",
          "Country",
          "Is_Male",
          "Age"
        ],
        "church": [
          "Church_ID",
          "Name",
          "Organized_by",
          "Open_Date",
          "Continuation_of"
        ],
        "wedding": [
          "Church_ID",
          "Male_ID",
          "Female_ID",
          "Year"
        ]
      },
      "answer": [
        [
          9
        ]
      ]
    },
    "generated_programs": [
      "answer = church[church['open_date'] < 1850].shape[0]",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = church[church['open_date'] < 1850].shape[0]",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])",
      "answer = pd.Series(church[church['open_date'] < 1850].shape[0])"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_product",
      "query": "SELECT TYPE ,  count(*) FROM store GROUP BY TYPE",
      "query_toks": [
        "SELECT",
        "TYPE",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "store",
        "GROUP",
        "BY",
        "TYPE"
      ],
      "query_toks_no_value": [
        "select",
        "type",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "store",
        "group",
        "by",
        "type"
      ],
      "question": "For each type of store, how many of them are there?",
      "question_toks": [
        "For",
        "each",
        "type",
        "of",
        "store",
        ",",
        "how",
        "many",
        "of",
        "them",
        "are",
        "there",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  10,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            10,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "product": [
          "product_id",
          "product",
          "dimensions",
          "dpi",
          "pages_per_minute_color",
          "max_page_size",
          "interface"
        ],
        "store": [
          "Store_ID",
          "Store_Name",
          "Type",
          "Area_size",
          "Number_of_product_category",
          "Ranking"
        ],
        "district": [
          "District_ID",
          "District_name",
          "Headquartered_City",
          "City_Population",
          "City_Area"
        ],
        "store_product": [
          "Store_ID",
          "Product_ID"
        ],
        "store_district": [
          "Store_ID",
          "District_ID"
        ]
      },
      "answer": [
        [
          "City Mall",
          2
        ],
        [
          "Village Store",
          3
        ]
      ]
    },
    "generated_programs": [
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby(['type']).size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count').to_frame().reset_index()\nanswer = t1",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "t1 = store.groupby('type', as_index=False).size().rename('count')\nanswer = t1",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = df_dict['store'].groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = store.groupby('type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = store.groupby('type').size().rename('count').to_frame().reset_index()"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "loan_1",
      "query": "SELECT state FROM bank GROUP BY state ORDER BY sum(no_of_customers) DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "state",
        "FROM",
        "bank",
        "GROUP",
        "BY",
        "state",
        "ORDER",
        "BY",
        "sum",
        "(",
        "no_of_customers",
        ")",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "state",
        "from",
        "bank",
        "group",
        "by",
        "state",
        "order",
        "by",
        "sum",
        "(",
        "no_of_customers",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "Which state has the greatest total number of bank customers?",
      "question_toks": [
        "Which",
        "state",
        "has",
        "the",
        "greatest",
        "total",
        "number",
        "of",
        "bank",
        "customers",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            5,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                4,
                3,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "bank": [
          "branch_ID",
          "bname",
          "no_of_customers",
          "city",
          "state"
        ],
        "customer": [
          "cust_ID",
          "cust_name",
          "acc_type",
          "acc_bal",
          "no_of_loans",
          "credit_score",
          "branch_ID",
          "state"
        ],
        "loan": [
          "loan_ID",
          "loan_type",
          "cust_ID",
          "branch_ID",
          "amount"
        ]
      },
      "answer": [
        [
          "New York"
        ]
      ]
    },
    "generated_programs": [
      "t1 = bank.groupby('state').sum().rename(columns={'no_of_customers':'sum'})\nt2 = t1.sort_values('sum', ascending=False).head(1).to_frame().reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state')['no_of_customers'].sum().rename('count').to_frame()\nt2 = t1[t1['count'] == t1['count'].max()].reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state').sum().rename(columns={'no_of_customers':'total_no_of_customers'})\nt2 = t1[t1['total_no_of_customers'] == t1.max()[0]]\nanswer = t2.index[0]",
      "t1 = bank.groupby('state').sum().sort_values('no_of_customers', ascending=False).head(1).reset_index()\nanswer = t1['state']",
      "t1 = bank.groupby('state').sum().sort_values('no_of_customers', ascending=False).head(1).reset_index()\nanswer = t1['state']",
      "t1 = bank.groupby('state').sum()\nanswer = t1['no_of_customers'].sort_values(ascending=False).head(1).to_frame().reset_index().iloc[0,0:1]",
      "t1 = bank.groupby('state').sum().rename(columns={'no_of_customers': 'sum_customers'})\nt2 = t1.loc[t1['sum_customers'] == max(t1['sum_customers'])]\nanswer = t2.index",
      "t1 = bank.groupby('state').sum()['no_of_customers'].to_frame().rename(index=str, columns={'no_of_customers': 'sum_no_of_customers'})\nt2 = t1.sort_values('sum_no_of_customers', ascending=False).head(1).reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state').sum()\nt2 = t1.sort_values(by='no_of_customers', ascending=False)\nanswer = t2.index[0]",
      "t1 = bank.groupby('state').agg({'no_of_customers' : 'sum'})\nt2 = t1.sort_values(by='no_of_customers', ascending=False).head(1).reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state')['no_of_customers'].sum().rename('sum_no_of_customers').to_frame()\nt2 = t1.sort_values(by='sum_no_of_customers', ascending=False).reset_index().head(1)\nanswer = t2['state']",
      "t1 = bank[['state']].groupby('state').sum().rename('no_of_customers')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['state']",
      "t1 = bank[['state', 'no_of_customers']].groupby('state').sum()\nt2 = t1.sort_values('no_of_customers', ascending=False).head(1).reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby(['state'])['no_of_customers'].sum().rename('count').to_frame()\nt2 = t1.sort_values(ascending=False).head(1).reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state')['no_of_customers'].sum().rename('total_no_of_customers').to_frame().reset_index()\nanswer = t1[t1['total_no_of_customers'] == t1['total_no_of_customers'].max()]['state']",
      "t1 = bank.groupby('state').sum().sort_values('no_of_customers', ascending = False).head(1).reset_index()\nanswer = pd.Series(t1['state'].iloc[0])",
      "t1 = bank.groupby('state').agg({'no_of_customers': 'sum'}).rename({'no_of_customers':'total_no_of_customers'}, axis=1)\nt2 = t1.sort_values('total_no_of_customers', ascending=False).head(1).to_frame().reset_index()\nanswer = t2['state']",
      "t1 = bank.groupby('state').sum()\nt2 = t1.sort_values('no_of_customers', ascending=False).head(1).reset_index()\nanswer = t2['state']",
      "answer = bank.groupby('state').sum().sort_values('no_of_customers', ascending=False).head(1).index.values[0]",
      "t1 = bank.groupby('state').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['state']"
    ],
    "acc@20": 12,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "hospital_1",
      "query": "SELECT count(T1.SSN) FROM patient AS T1 JOIN prescribes AS T2 ON T1.SSN  =  T2.patient JOIN physician AS T3 ON T2.physician  =  T3.employeeid WHERE T3.name = \"John Dorian\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "T1.SSN",
        ")",
        "FROM",
        "patient",
        "AS",
        "T1",
        "JOIN",
        "prescribes",
        "AS",
        "T2",
        "ON",
        "T1.SSN",
        "=",
        "T2.patient",
        "JOIN",
        "physician",
        "AS",
        "T3",
        "ON",
        "T2.physician",
        "=",
        "T3.employeeid",
        "WHERE",
        "T3.name",
        "=",
        "``",
        "John",
        "Dorian",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "t1",
        ".",
        "ssn",
        ")",
        "from",
        "patient",
        "as",
        "t1",
        "join",
        "prescribes",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "ssn",
        "=",
        "t2",
        ".",
        "patient",
        "join",
        "physician",
        "as",
        "t3",
        "on",
        "t2",
        ".",
        "physician",
        "=",
        "t3",
        ".",
        "employeeid",
        "where",
        "t3",
        ".",
        "name",
        "=",
        "value"
      ],
      "question": "Find the number of patients' prescriptions physician John Dorian made.",
      "question_toks": [
        "Find",
        "the",
        "number",
        "of",
        "patients",
        "'",
        "prescriptions",
        "physician",
        "John",
        "Dorian",
        "made",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ],
            [
              "table_unit",
              9
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  18,
                  false
                ],
                null
              ],
              [
                0,
                41,
                false
              ],
              null
            ],
            "and",
            [
              false,
              2,
              [
                0,
                [
                  0,
                  40,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  18,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"John Dorian\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Physician": [
          "EmployeeID",
          "Name",
          "Position",
          "SSN"
        ],
        "Department": [
          "DepartmentID",
          "Name",
          "Head"
        ],
        "Affiliated_With": [
          "Physician",
          "Department",
          "PrimaryAffiliation"
        ],
        "Procedures": [
          "Code",
          "Name",
          "Cost"
        ],
        "Trained_In": [
          "Physician",
          "Treatment",
          "CertificationDate",
          "CertificationExpires"
        ],
        "Patient": [
          "SSN",
          "Name",
          "Address",
          "Phone",
          "InsuranceID",
          "PCP"
        ],
        "Nurse": [
          "EmployeeID",
          "Name",
          "Position",
          "Registered",
          "SSN"
        ],
        "Appointment": [
          "AppointmentID",
          "Patient",
          "PrepNurse",
          "Physician",
          "Start",
          "End",
          "ExaminationRoom"
        ],
        "Medication": [
          "Code",
          "Name",
          "Brand",
          "Description"
        ],
        "Prescribes": [
          "Physician",
          "Patient",
          "Medication",
          "Date",
          "Appointment",
          "Dose"
        ],
        "Block": [
          "BlockFloor",
          "BlockCode"
        ],
        "Room": [
          "RoomNumber",
          "RoomType",
          "BlockFloor",
          "BlockCode",
          "Unavailable"
        ],
        "On_Call": [
          "Nurse",
          "BlockFloor",
          "BlockCode",
          "OnCallStart",
          "OnCallEnd"
        ],
        "Stay": [
          "StayID",
          "Patient",
          "Room",
          "StayStart",
          "StayEnd"
        ],
        "Undergoes": [
          "Patient",
          "Procedures",
          "Stay",
          "DateUndergoes",
          "Physician",
          "AssistingNurse"
        ]
      },
      "answer": [
        [
          1
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'JOHN DORIAN']\nanswer = pd.Series(t3['ssn'].count())",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'john dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'john dorian']\nanswer = pd.Series(t3['ssn'].unique().size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nanswer = t2[t2['name'] == 'John Dorian'].shape[0]",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3.shape[0])",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].count())",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'john dorian']\nanswer = pd.Series(t3['ssn'].shape[0])",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].count())",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, how='inner', left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, how='inner', left_on='physician', right_on='employeeid')\nt3 = t2.groupby(['ssn'])['ssn'].size().rename('count')\nanswer = t3[t3 > 0].to_frame().reset_index()",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nanswer = pd.Series(t2[t2['name'] == 'John Dorian'].shape[0])",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nanswer = t2[t2['name_y'] == 'John Dorian']['ssn'].count()",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nt3 = t2[t2['name'] == 'John Dorian']\nanswer = pd.Series(t3['ssn'].size)",
      "t1 = pd.merge(Patient, Prescribes, left_on='ssn', right_on='patient')\nt2 = pd.merge(t1, Physician, left_on='physician', right_on='employeeid')\nanswer = pd.Series(t2[t2['name'] == 'John Dorian'][['ssn']].shape[0])",
      "t1 = pd.merge(Patient, Prescribes, left_on='Patient.ssn', right_on='Prescribes.patient')\nt2 = pd.merge(t1, Physician, left_on='Prescribes.physician', right_on='Physician.employeeid')\nt3 = t2[t2['Physician.name'] == 'John Dorian']\nanswer = t3['Patient.ssn'].count()",
      "t1 = pd.merge(Patient, Prescribes, on='ssn')\nt2 = pd.merge(t1, Physician, on='employeeid')\nt3 = t2[t2['name'] == \"john dorian\"]\nanswer = t3['ssn'].unique().size"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT count(*) ,  T1.name FROM genres AS T1 JOIN tracks AS T2 ON T1.id = T2.genre_id GROUP BY T1.name;",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        ",",
        "T1.name",
        "FROM",
        "genres",
        "AS",
        "T1",
        "JOIN",
        "tracks",
        "AS",
        "T2",
        "ON",
        "T1.id",
        "=",
        "T2.genre_id",
        "GROUP",
        "BY",
        "T1.name",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        ",",
        "t1",
        ".",
        "name",
        "from",
        "genres",
        "as",
        "t1",
        "join",
        "tracks",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "genre_id",
        "group",
        "by",
        "t1",
        ".",
        "name"
      ],
      "question": "How many tracks are in each genre?",
      "question_toks": [
        "How",
        "many",
        "tracks",
        "are",
        "in",
        "each",
        "genre",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ],
            [
              "table_unit",
              8
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  36,
                  false
                ],
                null
              ],
              [
                0,
                53,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  37,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            37,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          40,
          "Alternative"
        ],
        [
          332,
          "Alternative & Punk"
        ],
        [
          81,
          "Blues"
        ],
        [
          15,
          "Bossa Nova"
        ],
        [
          74,
          "Classical"
        ],
        [
          17,
          "Comedy"
        ],
        [
          64,
          "Drama"
        ],
        [
          24,
          "Easy Listening"
        ],
        [
          30,
          "Electronica/Dance"
        ],
        [
          28,
          "Heavy Metal"
        ],
        [
          35,
          "Hip Hop/Rap"
        ],
        [
          130,
          "Jazz"
        ],
        [
          579,
          "Latin"
        ],
        [
          374,
          "Metal"
        ],
        [
          1,
          "Opera"
        ],
        [
          48,
          "Pop"
        ],
        [
          61,
          "R&B/Soul"
        ],
        [
          58,
          "Reggae"
        ],
        [
          1297,
          "Rock"
        ],
        [
          12,
          "Rock And Roll"
        ],
        [
          26,
          "Sci Fi & Fantasy"
        ],
        [
          13,
          "Science Fiction"
        ],
        [
          43,
          "Soundtrack"
        ],
        [
          93,
          "TV Shows"
        ],
        [
          28,
          "World"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name')['id_x'].size()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count').to_frame().reset_index()\nanswer = t2",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count').reset_index()\nanswer = t2",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, on='id')\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, on='id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id').groupby('name')['id'].count().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.sort_values(ascending = True).to_frame().reset_index()",
      "t1 = pd.merge(tracks, genres, left_on='genre_id', right_on='id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame()",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nanswer = t1.groupby('name').size().rename('count')"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "cre_Doc_Tracking_DB",
      "query": "SELECT document_type_code FROM Ref_document_types WHERE document_type_name  =  \"Paper\"",
      "query_toks": [
        "SELECT",
        "document_type_code",
        "FROM",
        "Ref_document_types",
        "WHERE",
        "document_type_name",
        "=",
        "``",
        "Paper",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "document_type_code",
        "from",
        "ref_document_types",
        "where",
        "document_type_name",
        "=",
        "value"
      ],
      "question": "Find the code of the document type \"Paper\".",
      "question_toks": [
        "Find",
        "the",
        "code",
        "of",
        "the",
        "document",
        "type",
        "``",
        "Paper",
        "''",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"Paper\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Document_Types": [
          "Document_Type_Code",
          "Document_Type_Name",
          "Document_Type_Description"
        ],
        "Ref_Calendar": [
          "Calendar_Date",
          "Day_Number"
        ],
        "Ref_Locations": [
          "Location_Code",
          "Location_Name",
          "Location_Description"
        ],
        "Roles": [
          "Role_Code",
          "Role_Name",
          "Role_Description"
        ],
        "All_Documents": [
          "Document_ID",
          "Date_Stored",
          "Document_Type_Code",
          "Document_Name",
          "Document_Description",
          "Other_Details"
        ],
        "Employees": [
          "Employee_ID",
          "Role_Code",
          "Employee_Name",
          "Gender_MFU",
          "Date_of_Birth",
          "Other_Details"
        ],
        "Document_Locations": [
          "Document_ID",
          "Location_Code",
          "Date_in_Location_From",
          "Date_in_Locaton_To"
        ],
        "Documents_to_be_Destroyed": [
          "Document_ID",
          "Destruction_Authorised_by_Employee_ID",
          "Destroyed_by_Employee_ID",
          "Planned_Destruction_Date",
          "Actual_Destruction_Date",
          "Other_Details"
        ]
      },
      "answer": [
        [
          "PR"
        ]
      ]
    },
    "generated_programs": [
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name']=='Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name']== 'Paper']['document_type_code']\n# Question: How many types of documents containing the word paper are there?\n# SQL: select count(distinct document_type_code) from ref_document_types where document_type_name like \"paper%\"\nanswer = pd.Series(Ref_Document_Types[Ref_Document_Types['document_type_name'].str.startswith('paper')]['document_type_code'].drop_duplicates().size)",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_name'] == 'Paper']['document_type_code'].unique()"
    ],
    "acc@20": 16,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "hr_1",
      "query": "SELECT T1.department_name ,  T2.city ,  T2.state_province FROM departments AS T1 JOIN locations AS T2 ON T2.location_id  =  T1.location_id",
      "query_toks": [
        "SELECT",
        "T1.department_name",
        ",",
        "T2.city",
        ",",
        "T2.state_province",
        "FROM",
        "departments",
        "AS",
        "T1",
        "JOIN",
        "locations",
        "AS",
        "T2",
        "ON",
        "T2.location_id",
        "=",
        "T1.location_id"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "department_name",
        ",",
        "t2",
        ".",
        "city",
        ",",
        "t2",
        ".",
        "state_province",
        "from",
        "departments",
        "as",
        "t1",
        "join",
        "locations",
        "as",
        "t2",
        "on",
        "t2",
        ".",
        "location_id",
        "=",
        "t1",
        ".",
        "location_id"
      ],
      "question": "What are the department names, cities, and state provinces for each department?",
      "question_toks": [
        "What",
        "are",
        "the",
        "department",
        "names",
        ",",
        "cities",
        ",",
        "and",
        "state",
        "provinces",
        "for",
        "each",
        "department",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              6
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  30,
                  false
                ],
                null
              ],
              [
                0,
                9,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  7,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  33,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  34,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "regions": [
          "REGION_ID",
          "REGION_NAME"
        ],
        "countries": [
          "COUNTRY_ID",
          "COUNTRY_NAME",
          "REGION_ID"
        ],
        "departments": [
          "DEPARTMENT_ID",
          "DEPARTMENT_NAME",
          "MANAGER_ID",
          "LOCATION_ID"
        ],
        "jobs": [
          "JOB_ID",
          "JOB_TITLE",
          "MIN_SALARY",
          "MAX_SALARY"
        ],
        "employees": [
          "EMPLOYEE_ID",
          "FIRST_NAME",
          "LAST_NAME",
          "EMAIL",
          "PHONE_NUMBER",
          "HIRE_DATE",
          "JOB_ID",
          "SALARY",
          "COMMISSION_PCT",
          "MANAGER_ID",
          "DEPARTMENT_ID"
        ],
        "job_history": [
          "EMPLOYEE_ID",
          "START_DATE",
          "END_DATE",
          "JOB_ID",
          "DEPARTMENT_ID"
        ],
        "locations": [
          "LOCATION_ID",
          "STREET_ADDRESS",
          "POSTAL_CODE",
          "CITY",
          "STATE_PROVINCE",
          "COUNTRY_ID"
        ]
      },
      "answer": [
        [
          "Administration",
          "Seattle",
          "Washington"
        ],
        [
          "Marketing",
          "Toronto",
          "Ontario"
        ],
        [
          "Purchasing",
          "Seattle",
          "Washington"
        ],
        [
          "Human Resources",
          "London",
          ""
        ],
        [
          "Shipping",
          "South San Francisco",
          "California"
        ],
        [
          "IT",
          "Southlake",
          "Texas"
        ],
        [
          "Public Relations",
          "Munich",
          "Bavaria"
        ],
        [
          "Sales",
          "OX9 9ZB",
          "Oxford"
        ],
        [
          "Executive",
          "Seattle",
          "Washington"
        ],
        [
          "Finance",
          "Seattle",
          "Washington"
        ],
        [
          "Accounting",
          "Seattle",
          "Washington"
        ],
        [
          "Treasury",
          "Seattle",
          "Washington"
        ],
        [
          "Corporate Tax",
          "Seattle",
          "Washington"
        ],
        [
          "Control And Credit",
          "Seattle",
          "Washington"
        ],
        [
          "Shareholder Services",
          "Seattle",
          "Washington"
        ],
        [
          "Benefits",
          "Seattle",
          "Washington"
        ],
        [
          "Manufacturing",
          "Seattle",
          "Washington"
        ],
        [
          "Construction",
          "Seattle",
          "Washington"
        ],
        [
          "Contracting",
          "Seattle",
          "Washington"
        ],
        [
          "Operations",
          "Seattle",
          "Washington"
        ],
        [
          "IT Support",
          "Seattle",
          "Washington"
        ],
        [
          "NOC",
          "Seattle",
          "Washington"
        ],
        [
          "IT Helpdesk",
          "Seattle",
          "Washington"
        ],
        [
          "Government Sales",
          "Seattle",
          "Washington"
        ],
        [
          "Retail Sales",
          "Seattle",
          "Washington"
        ],
        [
          "Recruiting",
          "Seattle",
          "Washington"
        ],
        [
          "Payroll",
          "Seattle",
          "Washington"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(locations, departments, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, how='left', left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, left_on='location_id', right_on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]",
      "t1 = pd.merge(departments, locations, on='location_id')\nanswer = t1[['department_name', 'city', 'state_province']]"
    ],
    "acc@20": 1,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "csu_1",
      "query": "SELECT campus FROM campuses WHERE YEAR  =  1958",
      "query_toks": [
        "SELECT",
        "campus",
        "FROM",
        "campuses",
        "WHERE",
        "YEAR",
        "=",
        "1958"
      ],
      "query_toks_no_value": [
        "select",
        "campus",
        "from",
        "campuses",
        "where",
        "year",
        "=",
        "value"
      ],
      "question": "What are the campuses that opened in 1958?",
      "question_toks": [
        "What",
        "are",
        "the",
        "campuses",
        "that",
        "opened",
        "in",
        "1958",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                5,
                false
              ],
              null
            ],
            1958.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Campuses": [
          "Id",
          "Campus",
          "Location",
          "County",
          "Year"
        ],
        "csu_fees": [
          "Campus",
          "Year",
          "CampusFee"
        ],
        "degrees": [
          "Year",
          "Campus",
          "Degrees"
        ],
        "discipline_enrollments": [
          "Campus",
          "Discipline",
          "Year",
          "Undergraduate",
          "Graduate"
        ],
        "enrollments": [
          "Campus",
          "Year",
          "TotalEnrollment_AY",
          "FTE_AY"
        ],
        "faculty": [
          "Campus",
          "Year",
          "Faculty"
        ]
      },
      "answer": [
        [
          "California State University-Northridge"
        ]
      ]
    },
    "generated_programs": [
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "t1 = Campuses[Campuses['year'] == 1958]\nanswer = t1['campus']",
      "t1 = Campuses[Campuses['year'] == 1958]\nanswer = t1['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['id']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses['campus'][Campuses['year'] == 1958]",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']",
      "answer = Campuses[Campuses['year'] == 1958]['campus']"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "architecture",
      "query": "SELECT max(T1.length_meters) ,  T2.name FROM bridge AS T1 JOIN architect AS T2 ON T1.architect_id  =  T2.id",
      "query_toks": [
        "SELECT",
        "max",
        "(",
        "T1.length_meters",
        ")",
        ",",
        "T2.name",
        "FROM",
        "bridge",
        "AS",
        "T1",
        "JOIN",
        "architect",
        "AS",
        "T2",
        "ON",
        "T1.architect_id",
        "=",
        "T2.id"
      ],
      "query_toks_no_value": [
        "select",
        "max",
        "(",
        "t1",
        ".",
        "length_meters",
        ")",
        ",",
        "t2",
        ".",
        "name",
        "from",
        "bridge",
        "as",
        "t1",
        "join",
        "architect",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "architect_id",
        "=",
        "t2",
        ".",
        "id"
      ],
      "question": "What is the maximum length in meters for the bridges and what are the architects' names?",
      "question_toks": [
        "What",
        "is",
        "the",
        "maximum",
        "length",
        "in",
        "meters",
        "for",
        "the",
        "bridges",
        "and",
        "what",
        "are",
        "the",
        "architects",
        "'",
        "names",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              1,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "architect": [
          "id",
          "name",
          "nationality",
          "gender"
        ],
        "bridge": [
          "architect_id",
          "id",
          "name",
          "location",
          "length_meters",
          "length_feet"
        ],
        "mill": [
          "architect_id",
          "id",
          "location",
          "name",
          "type",
          "built_year",
          "notes"
        ]
      },
      "answer": [
        [
          121.0,
          "Frank Lloyd Wright"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = t1[['length_meters', 'name']].max()",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nt2 = t1[['length_meters', 'name']]\nanswer = t2[t2['length_meters'] == t2['length_meters'].max()]",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nt2 = t1.groupby('name').max()\nanswer = t1.loc[t1['length_meters'] == t2['length_meters'], ['length_meters', 'name']]",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nanswer = pd.Series(t1['length_meters'].max(), index = ['max_length'])",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nt2 = t1[['length_meters', 'name']].groupby('name').max()\nanswer = t2",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nt2 = t1[['length_meters', 'name']]\nanswer = [t2['length_meters'].max(), t2['name']]",
      "answer = pd.merge(bridge, architect, left_on='architect_id', right_on='id')[['length_meters', 'name']].max()",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nt2 = t1.groupby('name').max()\nanswer = t2[['length_meters']]",
      "t1 = pd.merge(bridge, architect, on='architect_id').sort_values('length_meters', ascending=False)\nanswer = pd.Series([t1['length_meters'].max(), t1['name'].iloc[0]])",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = t1[['name', 'length_meters']].sort_values('length_meters', ascending=False).head(1)",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nanswer = t1[['length_meters', 'name']].groupby('name').max()",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = pd.Series(t1['length_meters'].max())",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = t1[['length_meters', 'name']].max()",
      "t1 = pd.merge(architect, bridge, on='id')\nanswer = pd.Series(t1['length_meters'].max())\nt2 = t1[t1['length_meters'] == t1['length_meters'].max()][['name']]",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = t1[['length_meters', 'name']].sort_values('length_meters', ascending = False).head(1)",
      "t1 = pd.merge(architect, bridge, left_on='id', right_on='architect_id')\nanswer = t1[['length_meters', 'name']].sort_values('length_meters', ascending=False).head(1)",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nt2 = t1[['length_meters', 'name']]\nanswer = pd.DataFrame(index=[0], columns=['length_meters', 'name'])\nanswer.loc[0] = t2.max()",
      "t1 = pd.merge(bridge, architect, left_on='architect_id', right_on='id')\nanswer = pd.Series(t1['length_meters'].max())",
      "t1 = pd.merge(bridge, architect, on='architect_id')\nanswer = t1[['length_meters', 'name']].max()",
      "t1 = pd.merge(architect, bridge, left_on='id', right_on='architect_id')\nanswer = pd.Series(t1['length_meters'].max(), t1['name'].unique())"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "hr_1",
      "query": "SELECT employee_id FROM job_history GROUP BY employee_id HAVING COUNT(*)  >= 2",
      "query_toks": [
        "SELECT",
        "employee_id",
        "FROM",
        "job_history",
        "GROUP",
        "BY",
        "employee_id",
        "HAVING",
        "COUNT",
        "(",
        "*",
        ")",
        ">",
        "=",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "employee_id",
        "from",
        "job_history",
        "group",
        "by",
        "employee_id",
        "having",
        "count",
        "(",
        "*",
        ")",
        ">",
        "=",
        "value"
      ],
      "question": "display the ID for those employees who did two or more jobs in the past.",
      "question_toks": [
        "display",
        "the",
        "ID",
        "for",
        "those",
        "employees",
        "who",
        "did",
        "two",
        "or",
        "more",
        "jobs",
        "in",
        "the",
        "past",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  25,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            25,
            false
          ]
        ],
        "having": [
          [
            false,
            5,
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "regions": [
          "REGION_ID",
          "REGION_NAME"
        ],
        "countries": [
          "COUNTRY_ID",
          "COUNTRY_NAME",
          "REGION_ID"
        ],
        "departments": [
          "DEPARTMENT_ID",
          "DEPARTMENT_NAME",
          "MANAGER_ID",
          "LOCATION_ID"
        ],
        "jobs": [
          "JOB_ID",
          "JOB_TITLE",
          "MIN_SALARY",
          "MAX_SALARY"
        ],
        "employees": [
          "EMPLOYEE_ID",
          "FIRST_NAME",
          "LAST_NAME",
          "EMAIL",
          "PHONE_NUMBER",
          "HIRE_DATE",
          "JOB_ID",
          "SALARY",
          "COMMISSION_PCT",
          "MANAGER_ID",
          "DEPARTMENT_ID"
        ],
        "job_history": [
          "EMPLOYEE_ID",
          "START_DATE",
          "END_DATE",
          "JOB_ID",
          "DEPARTMENT_ID"
        ],
        "locations": [
          "LOCATION_ID",
          "STREET_ADDRESS",
          "POSTAL_CODE",
          "CITY",
          "STATE_PROVINCE",
          "COUNTRY_ID"
        ]
      },
      "answer": [
        [
          101
        ],
        [
          176
        ],
        [
          200
        ]
      ]
    },
    "generated_programs": [
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].reset_index()[['employee_id']]",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nt2 = t1[t1>=2].to_frame().reset_index()\nanswer = t2['employee_id']",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >=2].to_frame().reset_index()['employee_id']",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size()>=2].to_frame().reset_index()['employee_id']",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1>=2].reset_index()['employee_id']",
      "t1 = job_history.groupby('employee_id').size()\nanswer = t1[t1 >= 2].to_frame().reset_index()",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].index",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].to_frame().reset_index()",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1 >= 2].to_frame().reset_index()",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].reset_index()['employee_id']",
      "answer = pd.Series(job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].index)",
      "answer = job_history['employee_id'].value_counts()[job_history['employee_id'].value_counts() >= 2].index",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1 >= 2].to_frame().reset_index()['employee_id']",
      "answer = job_history.groupby('employee_id').size().rename('count')[lambda x: x >= 2].to_frame().reset_index()\\\n        [['employee_id']]",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1>=2].index",
      "answer = job_history.groupby('employee_id').size()[lambda x: x >= 2].to_frame().reset_index()",
      "\nt1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1 >= 2].to_frame().reset_index()",
      "t1 = job_history.groupby('employee_id').size().rename('count')\nanswer = t1[t1 >= 2].to_frame().reset_index()['employee_id']",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2]",
      "answer = job_history.groupby('employee_id').size()[job_history.groupby('employee_id').size() >= 2].to_frame().reset_index()"
    ],
    "acc@20": 10,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "college_3",
      "query": "SELECT Fname FROM STUDENT ORDER BY Age DESC",
      "query_toks": [
        "SELECT",
        "Fname",
        "FROM",
        "STUDENT",
        "ORDER",
        "BY",
        "Age",
        "DESC"
      ],
      "query_toks_no_value": [
        "select",
        "fname",
        "from",
        "student",
        "order",
        "by",
        "age",
        "desc"
      ],
      "question": "Find the first name of students in the descending order of age.",
      "question_toks": [
        "Find",
        "the",
        "first",
        "name",
        "of",
        "students",
        "in",
        "the",
        "descending",
        "order",
        "of",
        "age",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                0,
                4,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ],
        "Faculty": [
          "FacID",
          "Lname",
          "Fname",
          "Rank",
          "Sex",
          "Phone",
          "Room",
          "Building"
        ],
        "Department": [
          "DNO",
          "Division",
          "DName",
          "Room",
          "Building",
          "DPhone"
        ],
        "Member_of": [
          "FacID",
          "DNO",
          "Appt_Type"
        ],
        "Course": [
          "CID",
          "CName",
          "Credits",
          "Instructor",
          "Days",
          "Hours",
          "DNO"
        ],
        "Minor_in": [
          "StuID",
          "DNO"
        ],
        "Enrolled_in": [
          "StuID",
          "CID",
          "Grade"
        ],
        "Gradeconversion": [
          "lettergrade",
          "gradepoint"
        ]
      },
      "answer": [
        [
          "Bruce"
        ],
        [
          "Paul"
        ],
        [
          "Sarah"
        ],
        [
          "David"
        ],
        [
          "Ian"
        ],
        [
          "Shiela"
        ],
        [
          "Lisa"
        ],
        [
          "Dinesh"
        ],
        [
          "Jandy"
        ],
        [
          "Steven"
        ],
        [
          "Michael"
        ],
        [
          "David"
        ],
        [
          "Eric"
        ],
        [
          "Sarah"
        ],
        [
          "Eric"
        ],
        [
          "Tracy"
        ],
        [
          "Eric"
        ],
        [
          "George"
        ],
        [
          "Eric"
        ],
        [
          "Linda"
        ],
        [
          "Andy"
        ],
        [
          "Lisa"
        ],
        [
          "Charles"
        ],
        [
          "Arthur"
        ],
        [
          "Stacy"
        ],
        [
          "Mark"
        ],
        [
          "Paul"
        ],
        [
          "William"
        ],
        [
          "Eric"
        ],
        [
          "Derek"
        ],
        [
          "Mark"
        ],
        [
          "Michael"
        ],
        [
          "Jun"
        ],
        [
          "Susan"
        ]
      ]
    },
    "generated_programs": [
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student.sort_values('age', ascending = False)[['fname']]",
      "answer = Student[['fname']].sort_values('age', ascending = False)",
      "answer = Student.sort_values('age', ascending = False)[['fname']]",
      "answer = Student[['fname']].sort_values('age', ascending = False)",
      "answer = Student.sort_values('age', ascending=False)['fname']",
      "answer = Student[['fname']].sort_values('age', ascending = False)",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student.sort_values('age', ascending=False)[['fname']]",
      "answer = Student.sort_values('age', ascending=False)['fname']",
      "answer = Student[['fname']].sort_values(by='age', ascending=False)",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student[['fname']].sort_values('age', ascending = False)",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student[['fname']].sort_values(by='age', ascending=False)",
      "answer = Student.sort_values('age', ascending = False)['fname']",
      "answer = Student[['fname']].sort_values('age', ascending=False)",
      "answer = Student.sort_values('age', ascending=False)[['fname']]"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "musical",
      "query": "SELECT Name FROM actor ORDER BY Name ASC",
      "query_toks": [
        "SELECT",
        "Name",
        "FROM",
        "actor",
        "ORDER",
        "BY",
        "Name",
        "ASC"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        "from",
        "actor",
        "order",
        "by",
        "name",
        "asc"
      ],
      "question": "List the name of actors in ascending alphabetical order.",
      "question_toks": [
        "List",
        "the",
        "name",
        "of",
        "actors",
        "in",
        "ascending",
        "alphabetical",
        "order",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                9,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "musical": [
          "Musical_ID",
          "Name",
          "Year",
          "Award",
          "Category",
          "Nominee",
          "Result"
        ],
        "actor": [
          "Actor_ID",
          "Name",
          "Musical_ID",
          "Character",
          "Duration",
          "age"
        ]
      },
      "answer": [
        [
          "Alan Fletcher"
        ],
        [
          "Ian Smith"
        ],
        [
          "Jackie Woodburne"
        ],
        [
          "Kate Ritchie"
        ],
        [
          "Lynne McGranger"
        ],
        [
          "Ray Meagher"
        ],
        [
          "Ryan Moloney"
        ],
        [
          "Stefan Dennis"
        ],
        [
          "Tom Oliver"
        ]
      ]
    },
    "generated_programs": [
      "answer = actor.sort_values('name')['name']",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor['name'].sort_values(ascending = True)",
      "answer = actor['name'].sort_values()",
      "answer = actor[['name']].sort_values('name')",
      "answer = actor['name'].sort_values()",
      "answer = actor[['name']].sort_values('name', ascending = True)",
      "answer = actor['name'].sort_values(ascending=True)",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor['name'].sort_values()",
      "answer = actor['name'].sort_values(ascending = True)",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor.sort_values(by='name')",
      "answer = actor[['name']].sort_values('name')",
      "answer = actor.sort_values(by='name', ascending=True).reset_index(drop=True)",
      "answer = actor.sort_values('name', ascending=True)['name']",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor[['name']].sort_values('name', ascending=True)",
      "answer = actor[['name']].sort_values('name', ascending=True)"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "soccer_1",
      "query": "SELECT count(*) FROM Country AS T1 JOIN League AS T2 ON T1.id  =  T2.country_id WHERE T1.name  =  \"England\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Country",
        "AS",
        "T1",
        "JOIN",
        "League",
        "AS",
        "T2",
        "ON",
        "T1.id",
        "=",
        "T2.country_id",
        "WHERE",
        "T1.name",
        "=",
        "``",
        "England",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "country",
        "as",
        "t1",
        "join",
        "league",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "country_id",
        "where",
        "t1",
        ".",
        "name",
        "=",
        "value"
      ],
      "question": "How many leagues are there in England?",
      "question_toks": [
        "How",
        "many",
        "leagues",
        "are",
        "there",
        "in",
        "England",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ],
            [
              "table_unit",
              3
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  55,
                  false
                ],
                null
              ],
              [
                0,
                53,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                56,
                false
              ],
              null
            ],
            "\"England\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Player_Attributes": [
          "id",
          "player_fifa_api_id",
          "player_api_id",
          "date",
          "overall_rating",
          "potential",
          "preferred_foot",
          "attacking_work_rate",
          "defensive_work_rate",
          "crossing",
          "finishing",
          "heading_accuracy",
          "short_passing",
          "volleys",
          "dribbling",
          "curve",
          "free_kick_accuracy",
          "long_passing",
          "ball_control",
          "acceleration",
          "sprint_speed",
          "agility",
          "reactions",
          "balance",
          "shot_power",
          "jumping",
          "stamina",
          "strength",
          "long_shots",
          "aggression",
          "interceptions",
          "positioning",
          "vision",
          "penalties",
          "marking",
          "standing_tackle",
          "sliding_tackle",
          "gk_diving",
          "gk_handling",
          "gk_kicking",
          "gk_positioning",
          "gk_reflexes"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "Player": [
          "id",
          "player_api_id",
          "player_name",
          "player_fifa_api_id",
          "birthday",
          "height",
          "weight"
        ],
        "League": [
          "id",
          "country_id",
          "name"
        ],
        "Country": [
          "id",
          "name"
        ],
        "Team": [
          "id",
          "team_api_id",
          "team_fifa_api_id",
          "team_long_name",
          "team_short_name"
        ],
        "Team_Attributes": [
          "id",
          "team_fifa_api_id",
          "team_api_id",
          "date",
          "buildUpPlaySpeed",
          "buildUpPlaySpeedClass",
          "buildUpPlayDribbling",
          "buildUpPlayDribblingClass",
          "buildUpPlayPassing",
          "buildUpPlayPassingClass",
          "buildUpPlayPositioningClass",
          "chanceCreationPassing",
          "chanceCreationPassingClass",
          "chanceCreationCrossing",
          "chanceCreationCrossingClass",
          "chanceCreationShooting",
          "chanceCreationShootingClass",
          "chanceCreationPositioningClass",
          "defencePressure",
          "defencePressureClass",
          "defenceAggression",
          "defenceAggressionClass",
          "defenceTeamWidth",
          "defenceTeamWidthClass",
          "defenceDefenderLineClass"
        ]
      },
      "answer": [
        [
          1
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Country, League, on='id')\nanswer = pd.Series(t1[t1['name_x'] == 'England'].shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nt2 = t1[t1['name_x'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Country, League, on='id')\nanswer = pd.Series(t1[t1['name'] == 'England'].shape[0])",
      "t1 = pd.merge(League, Country, left_on='country_id', right_on='id')\nt2 = t1[t1['name'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Country[Country['name'] == 'England'], League, on = 'id')\nanswer = pd.Series(t1.shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nanswer = pd.Series(t1[t1['name_x'] == 'England'].shape[0])",
      "t1 = pd.merge(League, Country, left_on='country_id', right_on='id')\nt2 = t1[t1['name_y'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nanswer = pd.Series(t1[t1['name_x'] == 'England'].shape[0])",
      "t1 = pd.merge(country, league, on='id')\nanswer = pd.Series(t1[t1['name'] == 'England'].shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nt2 = t1[t1['name_x'] == 'England']\nanswer = pd.Series(t2['id'].size)",
      "t1 = pd.merge(League, Country, left_on='country_id', right_on='id')\nt2 = t1[t1['name'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nt2 = t1[t1['name_x'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nt2 = t1[t1['name_x'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(League, Country, left_on='country_id', right_on='id')\nanswer = pd.Series(t1[t1['name'] == 'England'].shape[0])",
      "t1 = pd.merge(Country, League, on='id')\nanswer = pd.Series(t1[t1['name_x'] == 'England'].shape[0])",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nt2 = t1[t1['name_x'] == 'England']\nanswer = pd.Series(t2.shape[0])",
      "#       select count(*) from League as t1 join Country as t2 on t1.country_id  =  t2.id where t2.name  =  \"England\"\nt1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nanswer = t1[t1['name_x'] == 'England'].shape[0]",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nanswer = pd.Series(t1[t1['name_x'] == 'England'].shape[0])",
      "t1 = pd.merge(League, Country, left_on='country_id', right_on='id')\nanswer = t1[t1['name_y'] == 'England'].shape[0]",
      "t1 = pd.merge(Country, League, left_on='id', right_on='country_id')\nanswer = pd.Series(t1[t1['name'] == 'England'].shape[0])"
    ],
    "acc@20": 13,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "soccer_2",
      "query": "SELECT cName FROM college ORDER BY enr DESC LIMIT 3",
      "query_toks": [
        "SELECT",
        "cName",
        "FROM",
        "college",
        "ORDER",
        "BY",
        "enr",
        "DESC",
        "LIMIT",
        "3"
      ],
      "query_toks_no_value": [
        "select",
        "cname",
        "from",
        "college",
        "order",
        "by",
        "enr",
        "desc",
        "limit",
        "value"
      ],
      "question": "What are the names of schools with the top 3 largest size?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "schools",
        "with",
        "the",
        "top",
        "3",
        "largest",
        "size",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                0,
                3,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 3,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "College": [
          "cName",
          "state",
          "enr"
        ],
        "Player": [
          "pID",
          "pName",
          "yCard",
          "HS"
        ],
        "Tryout": [
          "pID",
          "cName",
          "pPos",
          "decision"
        ]
      },
      "answer": [
        [
          "OU"
        ],
        [
          "FSU"
        ],
        [
          "LSU"
        ]
      ]
    },
    "generated_programs": [
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']",
      "t1 = College.sort_values('enr', ascending=False)\nanswer = t1.head(3)['cname']",
      "answer = College.sort_values(by='enr', ascending=False).head(3)",
      "t1 = College.sort_values('enr', ascending=False)\nt2 = t1.head(3)\nanswer = t2['cname']",
      "answer = College.sort_values('enr', ascending = False).head(3)['cname']",
      "t1 = College.sort_values('enr', ascending=False).head(3).reset_index()\nanswer = t1['cname']",
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending = False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending = False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']",
      "answer = College.sort_values('enr', ascending = False).head(3).reset_index()[['cname']]",
      "answer = College[['cname']].sort_values('enr', ascending=False).head(3)",
      "t1 = College.sort_values('enr', ascending=False).head(3)\nanswer = t1['cname']",
      "answer = College.sort_values(by='enr', ascending = False)['cname'].head(3)",
      "answer = College.sort_values('enr', ascending=False)['cname'].head(3)",
      "t1 = College.sort_values(by='enr', ascending=False).head(3)\nanswer = t1['cname']",
      "t1 = College.sort_values('enr', ascending=False).head(3).reset_index()\nanswer = t1['cname']",
      "answer = College.sort_values('enr', ascending=False).head(3)['cname']"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "driving_school",
      "query": "SELECT date_joined_staff FROM Staff WHERE first_name = \"Janessa\" AND last_name = \"Sawayn\";",
      "query_toks": [
        "SELECT",
        "date_joined_staff",
        "FROM",
        "Staff",
        "WHERE",
        "first_name",
        "=",
        "``",
        "Janessa",
        "''",
        "AND",
        "last_name",
        "=",
        "``",
        "Sawayn",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "date_joined_staff",
        "from",
        "staff",
        "where",
        "first_name",
        "=",
        "value",
        "and",
        "last_name",
        "=",
        "value"
      ],
      "question": "When did the staff member named Janessa Sawayn join the company?",
      "question_toks": [
        "When",
        "did",
        "the",
        "staff",
        "member",
        "named",
        "Janessa",
        "Sawayn",
        "join",
        "the",
        "company",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                10,
                false
              ],
              null
            ],
            "\"Janessa\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                12,
                false
              ],
              null
            ],
            "\"Sawayn\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "line_1_number_building",
          "city",
          "zip_postcode",
          "state_province_county",
          "country"
        ],
        "Staff": [
          "staff_id",
          "staff_address_id",
          "nickname",
          "first_name",
          "middle_name",
          "last_name",
          "date_of_birth",
          "date_joined_staff",
          "date_left_staff"
        ],
        "Vehicles": [
          "vehicle_id",
          "vehicle_details"
        ],
        "Customers": [
          "customer_id",
          "customer_address_id",
          "customer_status_code",
          "date_became_customer",
          "date_of_birth",
          "first_name",
          "last_name",
          "amount_outstanding",
          "email_address",
          "phone_number",
          "cell_mobile_phone_number"
        ],
        "Customer_Payments": [
          "customer_id",
          "datetime_payment",
          "payment_method_code",
          "amount_payment"
        ],
        "Lessons": [
          "lesson_id",
          "customer_id",
          "lesson_status_code",
          "staff_id",
          "vehicle_id",
          "lesson_date",
          "lesson_time",
          "price"
        ]
      },
      "answer": [
        [
          "2017-04-27 03:21:26"
        ]
      ]
    },
    "generated_programs": [
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "t_staff = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t_staff['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'janessa') & (Staff['last_name'] == 'sawayn')]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == \"janessa\") & (Staff['last_name'] == \"sawayn\")]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[Staff['first_name'] == 'Janessa']\nt2 = t1[t1['last_name'] == 'Sawayn']\nanswer = t2['date_joined_staff']",
      "t1 = Staff[\n    (Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]['date_joined_staff']\nanswer = t1",
      "t1 = Staff[(Staff['first_name'] == 'janessa') & (Staff['last_name'] == 'sawayn')]['date_joined_staff']\nanswer = t1",
      "answer = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]['date_joined_staff']",
      "answer = Staff[Staff['first_name'] == 'Janessa'][Staff['last_name'] == 'Sawayn']['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "answer = Staff[Staff['first_name'] == 'Janessa']['date_joined_staff'].equals(Staff[Staff['last_name'] == 'Sawayn']['date_joined_staff'])",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]\nanswer = t1['date_joined_staff']",
      "answer = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]['date_joined_staff']",
      "answer = Staff[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn')]['date_joined_staff']",
      "answer = Staff.loc[(Staff['first_name'] == 'Janessa') & (Staff['last_name'] == 'Sawayn'), 'date_joined_staff']",
      "t1 = Staff[(Staff['first_name'] == 'janessa') & (Staff['last_name'] == 'sawayn')]\nanswer = t1['date_joined_staff']"
    ],
    "acc@20": 15,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "scientist_1",
      "query": "SELECT name FROM projects ORDER BY hours DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "name",
        "FROM",
        "projects",
        "ORDER",
        "BY",
        "hours",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        "from",
        "projects",
        "order",
        "by",
        "hours",
        "desc",
        "limit",
        "value"
      ],
      "question": "Find the name of project that continues for the longest time.",
      "question_toks": [
        "Find",
        "the",
        "name",
        "of",
        "project",
        "that",
        "continues",
        "for",
        "the",
        "longest",
        "time",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                0,
                5,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Scientists": [
          "SSN",
          "Name"
        ],
        "Projects": [
          "Code",
          "Name",
          "Hours"
        ],
        "AssignedTo": [
          "Scientist",
          "Project"
        ]
      },
      "answer": [
        [
          "A Magnetic Primer Designer"
        ]
      ]
    },
    "generated_programs": [
      "answer = Projects.sort_values('hours', ascending = False).head(1)['name']",
      "answer = Projects[['name']].sort_values('hours', ascending=False).head(1)",
      "answer = pd.Series(Projects.sort_values('hours', ascending=False).iloc[0]['name'])",
      "answer = Projects[Projects['hours'] == Projects['hours'].max()]['name']",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects[['name']].sort_values('hours', ascending=False).head(1)",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects.sort_values('hours', ascending=False)[:1]['name']",
      "answer = Projects[['name', 'hours']].sort_values('hours', ascending = False).head(1)",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects.sort_values('hours', ascending = False).head(1)['name']",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects.sort_values(by='hours', ascending=False).head(1)",
      "answer = Projects.sort_values('hours', ascending=False)[['name']].head(1)",
      "t1 = Projects.sort_values('hours', ascending = False).head(1)\nanswer = t1['name']",
      "answer = Projects.sort_values('hours', ascending=False).head(1)['name']",
      "answer = Projects[['name']].sort_values('hours', ascending=False).head(1)",
      "answer = Projects[['name', 'hours']].sort_values('hours', ascending = False).head(1)",
      "answer = Projects.sort_values('hours', ascending = False).reset_index().loc[0,'name']"
    ],
    "acc@20": 13,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "college_1",
      "query": "SELECT count(*) FROM CLASS AS T1 JOIN enroll AS T2 ON T1.class_code  =  T2.class_code WHERE T1.crs_code  =  'ACCT-211'",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "CLASS",
        "AS",
        "T1",
        "JOIN",
        "enroll",
        "AS",
        "T2",
        "ON",
        "T1.class_code",
        "=",
        "T2.class_code",
        "WHERE",
        "T1.crs_code",
        "=",
        "'ACCT-211",
        "'"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "class",
        "as",
        "t1",
        "join",
        "enroll",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "class_code",
        "=",
        "t2",
        ".",
        "class_code",
        "where",
        "t1",
        ".",
        "crs_code",
        "=",
        "value"
      ],
      "question": "What are the total number of students enrolled in ACCT-211?",
      "question_toks": [
        "What",
        "are",
        "the",
        "total",
        "number",
        "of",
        "students",
        "enrolled",
        "in",
        "ACCT-211",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              4
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                24,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"ACCT-211\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "CLASS": [
          "CLASS_CODE",
          "CRS_CODE",
          "CLASS_SECTION",
          "CLASS_TIME",
          "CLASS_ROOM",
          "PROF_NUM"
        ],
        "COURSE": [
          "CRS_CODE",
          "DEPT_CODE",
          "CRS_DESCRIPTION",
          "CRS_CREDIT"
        ],
        "DEPARTMENT": [
          "DEPT_CODE",
          "DEPT_NAME",
          "SCHOOL_CODE",
          "EMP_NUM",
          "DEPT_ADDRESS",
          "DEPT_EXTENSION"
        ],
        "EMPLOYEE": [
          "EMP_NUM",
          "EMP_LNAME",
          "EMP_FNAME",
          "EMP_INITIAL",
          "EMP_JOBCODE",
          "EMP_HIREDATE",
          "EMP_DOB"
        ],
        "ENROLL": [
          "CLASS_CODE",
          "STU_NUM",
          "ENROLL_GRADE"
        ],
        "PROFESSOR": [
          "EMP_NUM",
          "DEPT_CODE",
          "PROF_OFFICE",
          "PROF_EXTENSION",
          "PROF_HIGH_DEGREE"
        ],
        "STUDENT": [
          "STU_NUM",
          "STU_LNAME",
          "STU_FNAME",
          "STU_INIT",
          "STU_DOB",
          "STU_HRS",
          "STU_CLASS",
          "STU_GPA",
          "STU_TRANSFER",
          "DEPT_CODE",
          "STU_PHONE",
          "PROF_NUM"
        ]
      },
      "answer": [
        [
          2
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'acct-211']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2['class_code'].size)",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = t1[t1['crs_code'] == 'ACCT-211'].shape[0]",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211']['stu_num'].unique().size)",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2['stu_num'].drop_duplicates().size)",
      "t1 = pd.merge(CLASS, ENROLL, left_on='class_code', right_on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = t2.shape[0]",
      "t1 = pd.merge(CLASS, ENROLL, left_on='class_code', right_on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211'].shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211'].shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = t1.loc[t1['crs_code'] == 'ACCT-211'].shape[0]",
      "t1 = pd.merge(CLASS, ENROLL, left_on='class_code', right_on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211']['stu_num'].drop_duplicates().size)",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = t1[t1['crs_code'] == 'acct-211']['stu_num'].count()",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(CLASS,ENROLL, on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211'].shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, left_on='class_code', right_on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211']['stu_num'].unique().size)",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = t1[t1['crs_code'] == 'ACCT-211'][['class_code']].shape[0]",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nanswer = pd.Series(t1[t1['crs_code'] == 'ACCT-211'].shape[0])",
      "t1 = pd.merge(CLASS, ENROLL, on='class_code')\nt2 = t1[t1['crs_code'] == 'ACCT-211']\nanswer = pd.Series(t2.shape[0])"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "county_public_safety",
      "query": "SELECT T1.Name ,  T2.Name FROM city AS T1 JOIN county_public_safety AS T2 ON T1.County_ID  =  T2.County_ID",
      "query_toks": [
        "SELECT",
        "T1.Name",
        ",",
        "T2.Name",
        "FROM",
        "city",
        "AS",
        "T1",
        "JOIN",
        "county_public_safety",
        "AS",
        "T2",
        "ON",
        "T1.County_ID",
        "=",
        "T2.County_ID"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "name",
        ",",
        "t2",
        ".",
        "name",
        "from",
        "city",
        "as",
        "t1",
        "join",
        "county_public_safety",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "county_id",
        "=",
        "t2",
        ".",
        "county_id"
      ],
      "question": "What are the names of cities, as well as the names of the counties they correspond to?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "cities",
        ",",
        "as",
        "well",
        "as",
        "the",
        "names",
        "of",
        "the",
        "counties",
        "they",
        "correspond",
        "to",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  11,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  12,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "county_public_safety": [
          "County_ID",
          "Name",
          "Population",
          "Police_officers",
          "Residents_per_officer",
          "Case_burden",
          "Crime_rate",
          "Police_force",
          "Location"
        ],
        "city": [
          "City_ID",
          "County_ID",
          "Name",
          "White",
          "Black",
          "Amerindian",
          "Asian",
          "Multiracial",
          "Hispanic"
        ]
      },
      "answer": [
        [
          "Adjuntas",
          "Abbotsford"
        ],
        [
          "Aguada",
          "Abbotsford"
        ],
        [
          "Aguadilla",
          "Abbotsford"
        ],
        [
          "Aguas Buenas",
          "Burnaby"
        ],
        [
          "Aibonito",
          "Burnaby"
        ],
        [
          "A\u00f1asco",
          "Campbell River"
        ],
        [
          "Arecibo",
          "Campbell River"
        ],
        [
          "Arroyo",
          "Campbell River"
        ],
        [
          "Barceloneta",
          "Campbell River"
        ],
        [
          "Barranquitas",
          "Campbell River"
        ],
        [
          "Bayam\u00f3n",
          "Campbell River"
        ],
        [
          "Cabo Rojo",
          "Castlegar"
        ],
        [
          "Caguas",
          "Castlegar"
        ],
        [
          "Camuy",
          "Central Saanich"
        ],
        [
          "Can\u00f3vanas",
          "Central Saanich"
        ],
        [
          "Carolina",
          "Chilliwack"
        ],
        [
          "Cata\u00f1o",
          "Chilliwack"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "answer = pd.merge(city, county_public_safety, on='county_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "answer = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']].rename(columns={'name_x': 'city name', 'name_y': 'county name'})",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "answer = pd.merge(city, county_public_safety, on='county_id')[['name_x', 'name_y']]",
      "#answer = city[['name', 'county_id']].join(county_public_safety[['county_id', 'name']].set_index('county_id'), on='county_id')\nt1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, left_on='county_id', right_on='county_id')\nanswer = t1[['name_x', 'name_y']]",
      "t1 = pd.merge(city, county_public_safety, on='county_id')\nanswer = t1[['name_x', 'name_y']]"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "sakila_1",
      "query": "SELECT T2.address ,  T1.email FROM customer AS T1 JOIN address AS T2 ON T2.address_id  =  T1.address_id WHERE T1.first_name  =  'LINDA'",
      "query_toks": [
        "SELECT",
        "T2.address",
        ",",
        "T1.email",
        "FROM",
        "customer",
        "AS",
        "T1",
        "JOIN",
        "address",
        "AS",
        "T2",
        "ON",
        "T2.address_id",
        "=",
        "T1.address_id",
        "WHERE",
        "T1.first_name",
        "=",
        "'LINDA",
        "'"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "address",
        ",",
        "t1",
        ".",
        "email",
        "from",
        "customer",
        "as",
        "t1",
        "join",
        "address",
        "as",
        "t2",
        "on",
        "t2",
        ".",
        "address_id",
        "=",
        "t1",
        ".",
        "address_id",
        "where",
        "t1",
        ".",
        "first_name",
        "=",
        "value"
      ],
      "question": "Return the address and email of the customer with the first name Linda.",
      "question_toks": [
        "Return",
        "the",
        "address",
        "and",
        "email",
        "of",
        "the",
        "customer",
        "with",
        "the",
        "first",
        "name",
        "Linda",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ],
              [
                0,
                28,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  27,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                25,
                false
              ],
              null
            ],
            "\"LINDA\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "actor": [
          "actor_id",
          "first_name",
          "last_name",
          "last_update"
        ],
        "address": [
          "address_id",
          "address",
          "address2",
          "district",
          "city_id",
          "postal_code",
          "phone",
          "last_update"
        ],
        "category": [
          "category_id",
          "name",
          "last_update"
        ],
        "city": [
          "city_id",
          "city",
          "country_id",
          "last_update"
        ],
        "country": [
          "country_id",
          "country",
          "last_update"
        ],
        "customer": [
          "customer_id",
          "store_id",
          "first_name",
          "last_name",
          "email",
          "address_id",
          "active",
          "create_date",
          "last_update"
        ],
        "film": [
          "film_id",
          "title",
          "description",
          "release_year",
          "language_id",
          "original_language_id",
          "rental_duration",
          "rental_rate",
          "length",
          "replacement_cost",
          "rating",
          "special_features",
          "last_update"
        ],
        "film_actor": [
          "actor_id",
          "film_id",
          "last_update"
        ],
        "film_category": [
          "film_id",
          "category_id",
          "last_update"
        ],
        "film_text": [
          "film_id",
          "title",
          "description"
        ],
        "inventory": [
          "inventory_id",
          "film_id",
          "store_id",
          "last_update"
        ],
        "language": [
          "language_id",
          "name",
          "last_update"
        ],
        "payment": [
          "payment_id",
          "customer_id",
          "staff_id",
          "rental_id",
          "amount",
          "payment_date",
          "last_update"
        ],
        "rental": [
          "rental_id",
          "rental_date",
          "inventory_id",
          "customer_id",
          "return_date",
          "staff_id",
          "last_update"
        ],
        "staff": [
          "staff_id",
          "first_name",
          "last_name",
          "address_id",
          "picture",
          "email",
          "store_id",
          "active",
          "username",
          "password",
          "last_update"
        ],
        "store": [
          "store_id",
          "manager_staff_id",
          "address_id",
          "last_update"
        ]
      },
      "answer": [
        [
          "692 Joliet Street",
          "LINDA.WILLIAMS@sakilacustomer.org"
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.merge(customer[customer['first_name'] == 'Linda'], address, on='address_id')[['address', 'email']]",
      "t1 = pd.merge(customer[customer['first_name'] == 'Linda'], address, on='address_id')\nanswer = t1[['address', 'email']]",
      "t1 = pd.merge(customer, address, on = 'address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nt2 = t1[t1['first_name'] == 'Linda']\nanswer = t2[['address', 'email']]",
      "answer = customer[customer['first_name'] == 'Linda'][['email', 'address_id']]\nt1 = pd.merge(answer, address, on='address_id')\nanswer = t1[['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1.loc[(t1['first_name'] == 'Linda'), ['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1.loc[t1['first_name'] == 'Linda', ['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[['address', 'email']][t1['first_name'] == 'Linda']",
      "t1 = pd.merge(customer, address, on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, on='address_id')\nt2 = t1[t1['first_name'] == 'Linda']\nanswer = t2[['address', 'email']]",
      "t1 = customer[customer['first_name'] == 'Linda']\nt2 = pd.merge(t1, address, left_on='address_id', right_on='address_id')\nanswer = t2[['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "answer = pd.merge(customer, address, left_on='address_id', right_on='address_id')[['address', 'email']][customer['first_name'] == 'Linda']",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]",
      "t1 = pd.merge(customer, address, left_on='address_id', right_on='address_id')\nanswer = t1[t1['first_name'] == 'Linda'][['address', 'email']]"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "music_4",
      "query": "SELECT RESULT ,  COUNT(*) FROM music_festival GROUP BY RESULT ORDER BY COUNT(*) DESC",
      "query_toks": [
        "SELECT",
        "RESULT",
        ",",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "music_festival",
        "GROUP",
        "BY",
        "RESULT",
        "ORDER",
        "BY",
        "COUNT",
        "(",
        "*",
        ")",
        "DESC"
      ],
      "query_toks_no_value": [
        "select",
        "result",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "music_festival",
        "group",
        "by",
        "result",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc"
      ],
      "question": "Please show the results of music festivals and the number of music festivals that have had each, ordered by this count.",
      "question_toks": [
        "Please",
        "show",
        "the",
        "results",
        "of",
        "music",
        "festivals",
        "and",
        "the",
        "number",
        "of",
        "music",
        "festivals",
        "that",
        "have",
        "had",
        "each",
        ",",
        "ordered",
        "by",
        "this",
        "count",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  17,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            17,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artist": [
          "Artist_ID",
          "Artist",
          "Age",
          "Famous_Title",
          "Famous_Release_date"
        ],
        "volume": [
          "Volume_ID",
          "Volume_Issue",
          "Issue_Date",
          "Weeks_on_Top",
          "Song",
          "Artist_ID"
        ],
        "music_festival": [
          "ID",
          "Music_Festival",
          "Date_of_ceremony",
          "Category",
          "Volume",
          "Result"
        ]
      },
      "answer": [
        [
          "Nominated",
          6
        ],
        [
          "Awarded",
          3
        ]
      ]
    },
    "generated_programs": [
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby(['result']).size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.to_frame().reset_index().sort_values('count', ascending=False)",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count').to_frame().reset_index()\nanswer = t1[['result', 'count']].sort_values('count', ascending=False)",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.to_frame().sort_values('count', ascending = False).reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count').sort_values(ascending=False).to_frame().reset_index()\nanswer = t1[['result', 'count']]",
      "answer = music_festival.groupby('result').size().rename('count').sort_values(ascending=False).to_frame().reset_index()",
      "answer = music_festival.groupby('result').size().rename('count').sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "answer = music_festival.groupby('result').size().sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "answer = music_festival.groupby('result').size().rename('count').sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby(['result']).size().rename('count')\nanswer = t1.to_frame().reset_index().sort_values('count', ascending = False)",
      "answer = music_festival.groupby('result').size().rename('count').to_frame()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()",
      "answer = music_festival.groupby('result').size().rename('count').sort_values(ascending=False).to_frame().reset_index()",
      "t1 = music_festival.groupby('result').size().rename('count')\nanswer = t1.sort_values(ascending=False).to_frame().reset_index()"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "cre_Drama_Workshop_Groups",
      "query": "SELECT T1.State_County FROM Addresses AS T1 JOIN Stores AS T2 ON T1.Address_ID  =  T2.Address_ID WHERE T2.Marketing_Region_Code  =  \"CA\"",
      "query_toks": [
        "SELECT",
        "T1.State_County",
        "FROM",
        "Addresses",
        "AS",
        "T1",
        "JOIN",
        "Stores",
        "AS",
        "T2",
        "ON",
        "T1.Address_ID",
        "=",
        "T2.Address_ID",
        "WHERE",
        "T2.Marketing_Region_Code",
        "=",
        "``",
        "CA",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "state_county",
        "from",
        "addresses",
        "as",
        "t1",
        "join",
        "stores",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "address_id",
        "=",
        "t2",
        ".",
        "address_id",
        "where",
        "t2",
        ".",
        "marketing_region_code",
        "=",
        "value"
      ],
      "question": "Find the states or counties where the stores with marketing region code \"CA\" are located.",
      "question_toks": [
        "Find",
        "the",
        "states",
        "or",
        "counties",
        "where",
        "the",
        "stores",
        "with",
        "marketing",
        "region",
        "code",
        "``",
        "CA",
        "''",
        "are",
        "located",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              9
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ],
              [
                0,
                48,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  10,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                49,
                false
              ],
              null
            ],
            "\"CA\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Payment_Methods": [
          "payment_method_code",
          "payment_method_description"
        ],
        "Ref_Service_Types": [
          "Service_Type_Code",
          "Parent_Service_Type_Code",
          "Service_Type_Description"
        ],
        "Addresses": [
          "Address_ID",
          "Line_1",
          "Line_2",
          "City_Town",
          "State_County",
          "Other_Details"
        ],
        "Products": [
          "Product_ID",
          "Product_Name",
          "Product_Price",
          "Product_Description",
          "Other_Product_Service_Details"
        ],
        "Marketing_Regions": [
          "Marketing_Region_Code",
          "Marketing_Region_Name",
          "Marketing_Region_Descriptrion",
          "Other_Details"
        ],
        "Clients": [
          "Client_ID",
          "Address_ID",
          "Customer_Email_Address",
          "Customer_Name",
          "Customer_Phone",
          "Other_Details"
        ],
        "Drama_Workshop_Groups": [
          "Workshop_Group_ID",
          "Address_ID",
          "Currency_Code",
          "Marketing_Region_Code",
          "Store_Name",
          "Store_Phone",
          "Store_Email_Address",
          "Other_Details"
        ],
        "Performers": [
          "Performer_ID",
          "Address_ID",
          "Customer_Name",
          "Customer_Phone",
          "Customer_Email_Address",
          "Other_Details"
        ],
        "Customers": [
          "Customer_ID",
          "Address_ID",
          "Customer_Name",
          "Customer_Phone",
          "Customer_Email_Address",
          "Other_Details"
        ],
        "Stores": [
          "Store_ID",
          "Address_ID",
          "Marketing_Region_Code",
          "Store_Name",
          "Store_Phone",
          "Store_Email_Address",
          "Other_Details"
        ],
        "Bookings": [
          "Booking_ID",
          "Customer_ID",
          "Workshop_Group_ID",
          "Status_Code",
          "Store_ID",
          "Order_Date",
          "Planned_Delivery_Date",
          "Actual_Delivery_Date",
          "Other_Order_Details"
        ],
        "Performers_in_Bookings": [
          "Order_ID",
          "Performer_ID"
        ],
        "Customer_Orders": [
          "Order_ID",
          "Customer_ID",
          "Store_ID",
          "Order_Date",
          "Planned_Delivery_Date",
          "Actual_Delivery_Date",
          "Other_Order_Details"
        ],
        "Order_Items": [
          "Order_Item_ID",
          "Order_ID",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details"
        ],
        "Invoices": [
          "Invoice_ID",
          "Order_ID",
          "payment_method_code",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details",
          "Order_Item_ID"
        ],
        "Services": [
          "Service_ID",
          "Service_Type_Code",
          "Workshop_Group_ID",
          "Product_Description",
          "Product_Name",
          "Product_Price",
          "Other_Product_Service_Details"
        ],
        "Bookings_Services": [
          "Order_ID",
          "Product_ID"
        ],
        "Invoice_Items": [
          "Invoice_Item_ID",
          "Invoice_ID",
          "Order_ID",
          "Order_Item_ID",
          "Product_ID",
          "Order_Quantity",
          "Other_Item_Details"
        ]
      },
      "answer": [
        [
          "Alaska"
        ],
        [
          "Delaware"
        ],
        [
          "Alabama"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county'].dropna()",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA'][['state_county']]",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'ca']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id', how='inner')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(address, store, on=\"address_id\")\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']",
      "t1 = pd.merge(Addresses, Stores, left_on='address_id', right_on='address_id')\nanswer = t1[t1['marketing_region_code'] == 'CA']['state_county']",
      "t1 = pd.merge(Addresses, Stores, on='address_id')\nt2 = t1[t1['marketing_region_code'] == 'CA']\nanswer = t2['state_county']"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT title FROM albums;",
      "query_toks": [
        "SELECT",
        "title",
        "FROM",
        "albums",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "title",
        "from",
        "albums"
      ],
      "question": "What are the titles of all the albums?",
      "question_toks": [
        "What",
        "are",
        "the",
        "titles",
        "of",
        "all",
        "the",
        "albums",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "For Those About To Rock We Salute You"
        ],
        [
          "Balls to the Wall"
        ],
        [
          "Restless and Wild"
        ],
        [
          "Let There Be Rock"
        ],
        [
          "Big Ones"
        ],
        [
          "Jagged Little Pill"
        ],
        [
          "Facelift"
        ],
        [
          "Warner 25 Anos"
        ],
        [
          "Plays Metallica By Four Cellos"
        ],
        [
          "Audioslave"
        ],
        [
          "Out Of Exile"
        ],
        [
          "BackBeat Soundtrack"
        ],
        [
          "The Best Of Billy Cobham"
        ],
        [
          "Alcohol Fueled Brewtality Live! [Disc 1]"
        ],
        [
          "Alcohol Fueled Brewtality Live! [Disc 2]"
        ],
        [
          "Black Sabbath"
        ],
        [
          "Black Sabbath Vol. 4 (Remaster)"
        ],
        [
          "Body Count"
        ],
        [
          "Chemical Wedding"
        ],
        [
          "The Best Of Buddy Guy - The Millenium Collection"
        ],
        [
          "Prenda Minha"
        ],
        [
          "Sozinho Remix Ao Vivo"
        ],
        [
          "Minha Historia"
        ],
        [
          "Afrociberdelia"
        ],
        [
          "Da Lama Ao Caos"
        ],
        [
          "Ac\u00fastico MTV live"
        ],
        [
          "Cidade Negra - Hits"
        ],
        [
          "Na Pista"
        ],
        [
          "Ax\u00e9 Bahia 2001"
        ],
        [
          "BBC Sessions [Disc 1] live"
        ],
        [
          "Bongo Fury"
        ],
        [
          "Carnaval 2001"
        ],
        [
          "Chill: Brazil (Disc 1)"
        ],
        [
          "Chill: Brazil (Disc 2)"
        ],
        [
          "Garage Inc. (Disc 1)"
        ],
        [
          "Greatest Hits II"
        ],
        [
          "Greatest Kiss"
        ],
        [
          "Heart of the Night"
        ],
        [
          "International Superhits"
        ],
        [
          "Into The Light"
        ],
        [
          "Meus Momentos"
        ],
        [
          "Minha Hist\u00f3ria"
        ],
        [
          "MK III The Final Concerts [Disc 1]"
        ],
        [
          "Physical Graffiti [Disc 1]"
        ],
        [
          "Sambas De Enredo 2001"
        ],
        [
          "Supernatural"
        ],
        [
          "The Best of Ed Motta"
        ],
        [
          "The Essential Miles Davis [Disc 1]"
        ],
        [
          "The Essential Miles Davis [Disc 2]"
        ],
        [
          "The Final Concerts (Disc 2)"
        ],
        [
          "Up An' Atom"
        ],
        [
          "Vin\u00edcius De Moraes - Sem Limite"
        ],
        [
          "Vozes do MPB"
        ],
        [
          "Chronicle, Vol. 1"
        ],
        [
          "Chronicle, Vol. 2"
        ],
        [
          "C\u00e1ssia Eller - Cole\u00e7\u00e3o Sem Limite [Disc 2]"
        ],
        [
          "C\u00e1ssia Eller - Sem Limite [Disc 1]"
        ],
        [
          "Come Taste The Band"
        ],
        [
          "Deep Purple In Rock"
        ],
        [
          "Fireball"
        ],
        [
          "Knocking at Your Back Door: The Best Of Deep Purple in the 80's"
        ],
        [
          "Machine Head"
        ],
        [
          "Purpendicular"
        ],
        [
          "Slaves And Masters"
        ],
        [
          "Stormbringer"
        ],
        [
          "The Battle Rages On"
        ],
        [
          "Vault: Def Leppard's Greatest Hits"
        ],
        [
          "Outbreak"
        ],
        [
          "Djavan Ao Vivo - Vol. 02"
        ],
        [
          "Djavan Ao Vivo - Vol. 1"
        ],
        [
          "Elis Regina-Minha Hist\u00f3ria"
        ],
        [
          "The Cream Of Clapton"
        ],
        [
          "Unplugged"
        ],
        [
          "Album Of The Year"
        ],
        [
          "Angel Dust"
        ],
        [
          "King For A Day Fool For A Lifetime"
        ],
        [
          "The Real Thing"
        ],
        [
          "Deixa Entrar"
        ],
        [
          "In Your Honor [Disc 1]"
        ],
        [
          "In Your Honor [Disc 2]"
        ],
        [
          "One By One"
        ],
        [
          "The Colour And The Shape"
        ],
        [
          "My Way: The Best Of Frank Sinatra [Disc 1]"
        ],
        [
          "Roda De Funk"
        ],
        [
          "As Can\u00e7\u00f5es de Eu Tu Eles"
        ],
        [
          "Quanta Gente Veio Ver (Live)"
        ],
        [
          "Quanta Gente Veio ver--B\u00f4nus De Carnaval"
        ],
        [
          "Faceless"
        ],
        [
          "American Idiot"
        ],
        [
          "Appetite for Destruction"
        ],
        [
          "Use Your Illusion I"
        ],
        [
          "Use Your Illusion II"
        ],
        [
          "Blue Moods"
        ],
        [
          "A Matter of Life and Death"
        ],
        [
          "A Real Dead One"
        ],
        [
          "A Real Live One"
        ],
        [
          "Brave New World"
        ],
        [
          "Dance Of Death"
        ],
        [
          "Fear Of The Dark"
        ],
        [
          "Iron Maiden"
        ],
        [
          "Killers"
        ],
        [
          "Live After Death"
        ],
        [
          "Live At Donington 1992 (Disc 1)"
        ],
        [
          "Live At Donington 1992 (Disc 2)"
        ],
        [
          "No Prayer For The Dying"
        ],
        [
          "Piece Of Mind"
        ],
        [
          "Powerslave"
        ],
        [
          "Rock In Rio CD1"
        ],
        [
          "Rock In Rio CD2"
        ],
        [
          "Seventh Son of a Seventh Son"
        ],
        [
          "Somewhere in Time"
        ],
        [
          "The Number of The Beast"
        ],
        [
          "The X Factor"
        ],
        [
          "Virtual XI"
        ],
        [
          "Sex Machine"
        ],
        [
          "Emergency On Planet Earth"
        ],
        [
          "Synkronized"
        ],
        [
          "The Return Of The Space Cowboy"
        ],
        [
          "Get Born"
        ],
        [
          "Are You Experienced?"
        ],
        [
          "Surfing with the Alien (Remastered)"
        ],
        [
          "Jorge Ben Jor 25 Anos"
        ],
        [
          "Jota Quest-1995"
        ],
        [
          "Cafezinho"
        ],
        [
          "Living After Midnight"
        ],
        [
          "Unplugged live"
        ],
        [
          "BBC Sessions [Disc 2] live"
        ],
        [
          "Coda"
        ],
        [
          "Houses Of The Holy"
        ],
        [
          "In Through The Out Door"
        ],
        [
          "IV"
        ],
        [
          "Led Zeppelin I"
        ],
        [
          "Led Zeppelin II"
        ],
        [
          "Led Zeppelin III"
        ],
        [
          "Physical Graffiti [Disc 2]"
        ],
        [
          "Presence"
        ],
        [
          "The Song Remains The Same (Disc 1)"
        ],
        [
          "The Song Remains The Same (Disc 2)"
        ],
        [
          "A TempestadeTempestade Ou O Livro Dos Dias"
        ],
        [
          "Mais Do Mesmo"
        ],
        [
          "Greatest Hits"
        ],
        [
          "Lulu Santos - RCA 100 Anos De M\u00fasica - \u00c1lbum 01"
        ],
        [
          "Lulu Santos - RCA 100 Anos De M\u00fasica - \u00c1lbum 02"
        ],
        [
          "Misplaced Childhood"
        ],
        [
          "Barulhinho Bom"
        ],
        [
          "Seek And Shall Find: More Of The Best (1963-1981)"
        ],
        [
          "The Best Of Men At Work"
        ],
        [
          "Black Album"
        ],
        [
          "Garage Inc. (Disc 2)"
        ],
        [
          "Kill 'Em All"
        ],
        [
          "Load"
        ],
        [
          "Master Of Puppets"
        ],
        [
          "ReLoad"
        ],
        [
          "Ride The Lightning"
        ],
        [
          "St. Anger"
        ],
        [
          "...And Justice For All"
        ],
        [
          "Miles Ahead"
        ],
        [
          "Milton Nascimento Ao Vivo"
        ],
        [
          "Minas"
        ],
        [
          "Ace Of Spades"
        ],
        [
          "Demorou..."
        ],
        [
          "Motley Crue Greatest Hits"
        ],
        [
          "From The Muddy Banks Of The Wishkah live"
        ],
        [
          "Nevermind"
        ],
        [
          "Compositores"
        ],
        [
          "Olodum"
        ],
        [
          "Ac\u00fastico MTV"
        ],
        [
          "Arquivo II"
        ],
        [
          "Arquivo Os Paralamas Do Sucesso"
        ],
        [
          "Bark at the Moon (Remastered)"
        ],
        [
          "Blizzard of Ozz"
        ],
        [
          "Diary of a Madman (Remastered)"
        ],
        [
          "No More Tears (Remastered)"
        ],
        [
          "Tribute"
        ],
        [
          "Walking Into Clarksdale"
        ],
        [
          "Original Soundtracks 1"
        ],
        [
          "The Beast Live"
        ],
        [
          "Live On Two Legs live"
        ],
        [
          "Pearl Jam"
        ],
        [
          "Riot Act"
        ],
        [
          "Ten"
        ],
        [
          "Vs."
        ],
        [
          "Dark Side Of The Moon"
        ],
        [
          "Os C\u00e3es Ladram Mas A Caravana N\u00e3o P\u00e1ra"
        ],
        [
          "Greatest Hits I"
        ],
        [
          "News Of The World"
        ],
        [
          "Out Of Time"
        ],
        [
          "Green"
        ],
        [
          "New Adventures In Hi-Fi"
        ],
        [
          "The Best Of R.E.M.: The IRS Years"
        ],
        [
          "Cesta B\u00e1sica"
        ],
        [
          "Raul Seixas"
        ],
        [
          "Blood Sugar Sex Magik"
        ],
        [
          "By The Way"
        ],
        [
          "Californication"
        ],
        [
          "Retrospective I (1974-1980)"
        ],
        [
          "Santana - As Years Go By"
        ],
        [
          "Santana Live"
        ],
        [
          "Maquinarama"
        ],
        [
          "O Samba Pocon\u00e9"
        ],
        [
          "Judas 0: B-Sides and Rarities"
        ],
        [
          "Rotten Apples: Greatest Hits"
        ],
        [
          "A-Sides"
        ],
        [
          "Morning Dance"
        ],
        [
          "In Step"
        ],
        [
          "Core"
        ],
        [
          "Mezmerize"
        ],
        [
          "1997 Black Light Syndrome"
        ],
        [
          "Live [Disc 1]"
        ],
        [
          "Live [Disc 2]"
        ],
        [
          "The Singles"
        ],
        [
          "Beyond Good And Evil"
        ],
        [
          "Pure Cult: The Best Of The Cult (For Rockers, Ravers, Lovers & Sinners) UK"
        ],
        [
          "The Doors"
        ],
        [
          "The Police Greatest Hits"
        ],
        [
          "Hot Rocks, 1964-1971 (Disc 1)"
        ],
        [
          "No Security"
        ],
        [
          "Voodoo Lounge"
        ],
        [
          "Tangents"
        ],
        [
          "Transmission"
        ],
        [
          "My Generation - The Very Best Of The Who"
        ],
        [
          "Serie Sem Limite (Disc 1)"
        ],
        [
          "Serie Sem Limite (Disc 2)"
        ],
        [
          "Ac\u00fastico"
        ],
        [
          "Volume Dois"
        ],
        [
          "Battlestar Galactica: The Story So Far"
        ],
        [
          "Battlestar Galactica, Season 3"
        ],
        [
          "Heroes, Season 1"
        ],
        [
          "Lost, Season 3"
        ],
        [
          "Lost, Season 1"
        ],
        [
          "Lost, Season 2"
        ],
        [
          "Achtung Baby"
        ],
        [
          "All That You Can't Leave Behind"
        ],
        [
          "B-Sides 1980-1990"
        ],
        [
          "How To Dismantle An Atomic Bomb"
        ],
        [
          "Pop"
        ],
        [
          "Rattle And Hum"
        ],
        [
          "The Best Of 1980-1990"
        ],
        [
          "War"
        ],
        [
          "Zooropa"
        ],
        [
          "UB40 The Best Of - Volume Two UK"
        ],
        [
          "Diver Down"
        ],
        [
          "The Best Of Van Halen, Vol. I"
        ],
        [
          "Van Halen"
        ],
        [
          "Van Halen III"
        ],
        [
          "Contraband"
        ],
        [
          "Vinicius De Moraes"
        ],
        [
          "Ao Vivo IMPORT"
        ],
        [
          "The Office, Season 1"
        ],
        [
          "The Office, Season 2"
        ],
        [
          "The Office, Season 3"
        ],
        [
          "Un-Led-Ed"
        ],
        [
          "Battlestar Galactica (Classic), Season 1"
        ],
        [
          "Aquaman"
        ],
        [
          "Instant Karma: The Amnesty International Campaign to Save Darfur"
        ],
        [
          "Speak of the Devil"
        ],
        [
          "20th Century Masters - The Millennium Collection: The Best of Scorpions"
        ],
        [
          "House of Pain"
        ],
        [
          "Radio Brasil (O Som da Jovem Vanguarda) - Seleccao de Henrique Amaro"
        ],
        [
          "Cake: B-Sides and Rarities"
        ],
        [
          "LOST, Season 4"
        ],
        [
          "Quiet Songs"
        ],
        [
          "Muso Ko"
        ],
        [
          "Realize"
        ],
        [
          "Every Kind of Light"
        ],
        [
          "Duos II"
        ],
        [
          "Worlds"
        ],
        [
          "The Best of Beethoven"
        ],
        [
          "Temple of the Dog"
        ],
        [
          "Carry On"
        ],
        [
          "Revelations"
        ],
        [
          "Adorate Deum: Gregorian Chant from the Proper of the Mass"
        ],
        [
          "Allegri: Miserere"
        ],
        [
          "Pachelbel: Canon & Gigue"
        ],
        [
          "Vivaldi: The Four Seasons"
        ],
        [
          "Bach: Violin Concertos"
        ],
        [
          "Bach: Goldberg Variations"
        ],
        [
          "Bach: The Cello Suites"
        ],
        [
          "Handel: The Messiah (Highlights)"
        ],
        [
          "The World of Classical Favourites"
        ],
        [
          "Sir Neville Marriner: A Celebration"
        ],
        [
          "Mozart: Wind Concertos"
        ],
        [
          "Haydn: Symphonies 99 - 104"
        ],
        [
          "Beethoven: Symhonies Nos. 5 & 6"
        ],
        [
          "A Soprano Inspired"
        ],
        [
          "Great Opera Choruses"
        ],
        [
          "Wagner: Favourite Overtures"
        ],
        [
          "Faur\u00e9: Requiem, Ravel: Pavane & Others"
        ],
        [
          "Tchaikovsky: The Nutcracker"
        ],
        [
          "The Last Night of the Proms"
        ],
        [
          "Puccini: Madama Butterfly - Highlights"
        ],
        [
          "Holst: The Planets, Op. 32 & Vaughan Williams: Fantasies"
        ],
        [
          "Pavarotti's Opera Made Easy"
        ],
        [
          "Great Performances - Barber's Adagio and Other Romantic Favorites for Strings"
        ],
        [
          "Carmina Burana"
        ],
        [
          "A Copland Celebration, Vol. I"
        ],
        [
          "Bach: Toccata & Fugue in D Minor"
        ],
        [
          "Prokofiev: Symphony No.1"
        ],
        [
          "Scheherazade"
        ],
        [
          "Bach: The Brandenburg Concertos"
        ],
        [
          "Chopin: Piano Concertos Nos. 1 & 2"
        ],
        [
          "Mascagni: Cavalleria Rusticana"
        ],
        [
          "Sibelius: Finlandia"
        ],
        [
          "Beethoven Piano Sonatas: Moonlight & Pastorale"
        ],
        [
          "Great Recordings of the Century - Mahler: Das Lied von der Erde"
        ],
        [
          "Elgar: Cello Concerto & Vaughan Williams: Fantasias"
        ],
        [
          "Adams, John: The Chairman Dances"
        ],
        [
          "Tchaikovsky: 1812 Festival Overture, Op.49, Capriccio Italien & Beethoven: Wellington's Victory"
        ],
        [
          "Palestrina: Missa Papae Marcelli & Allegri: Miserere"
        ],
        [
          "Prokofiev: Romeo & Juliet"
        ],
        [
          "Strauss: Waltzes"
        ],
        [
          "Berlioz: Symphonie Fantastique"
        ],
        [
          "Bizet: Carmen Highlights"
        ],
        [
          "English Renaissance"
        ],
        [
          "Handel: Music for the Royal Fireworks (Original Version 1749)"
        ],
        [
          "Grieg: Peer Gynt Suites & Sibelius: Pell\u00e9as et M\u00e9lisande"
        ],
        [
          "Mozart Gala: Famous Arias"
        ],
        [
          "SCRIABIN: Vers la flamme"
        ],
        [
          "Armada: Music from the Courts of England and Spain"
        ],
        [
          "Mozart: Symphonies Nos. 40 & 41"
        ],
        [
          "Back to Black"
        ],
        [
          "Frank"
        ],
        [
          "Carried to Dust (Bonus Track Version)"
        ],
        [
          "Beethoven: Symphony No. 6 'Pastoral' Etc."
        ],
        [
          "Bartok: Violin & Viola Concertos"
        ],
        [
          "Mendelssohn: A Midsummer Night's Dream"
        ],
        [
          "Bach: Orchestral Suites Nos. 1 - 4"
        ],
        [
          "Charpentier: Divertissements, Airs & Concerts"
        ],
        [
          "South American Getaway"
        ],
        [
          "G\u00f3recki: Symphony No. 3"
        ],
        [
          "Purcell: The Fairy Queen"
        ],
        [
          "The Ultimate Relexation Album"
        ],
        [
          "Purcell: Music for the Queen Mary"
        ],
        [
          "Weill: The Seven Deadly Sins"
        ],
        [
          "J.S. Bach: Chaconne, Suite in E Minor, Partita in E Major & Prelude, Fugue and Allegro"
        ],
        [
          "Prokofiev: Symphony No.5 & Stravinksy: Le Sacre Du Printemps"
        ],
        [
          "Szymanowski: Piano Works, Vol. 1"
        ],
        [
          "Nielsen: The Six Symphonies"
        ],
        [
          "Great Recordings of the Century: Paganini's 24 Caprices"
        ],
        [
          "Liszt - 12 \u00c9tudes D'Execution Transcendante"
        ],
        [
          "Great Recordings of the Century - Shubert: Schwanengesang, 4 Lieder"
        ],
        [
          "Locatelli: Concertos for Violin, Strings and Continuo, Vol. 3"
        ],
        [
          "Respighi:Pines of Rome"
        ],
        [
          "Schubert: The Late String Quartets & String Quintet (3 CD's)"
        ],
        [
          "Monteverdi: L'Orfeo"
        ],
        [
          "Mozart: Chamber Music"
        ],
        [
          "Koyaanisqatsi (Soundtrack from the Motion Picture)"
        ]
      ],
      "pandas_converted": "albums['title']"
    },
    "generated_programs": [
      "answer = albums.loc[:, 'title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title'].copy()",
      "answer = albums[['title']]",
      "t1 = albums['title']\nt2 = t1.drop_duplicates()\nanswer = t2",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums['title']",
      "answer = albums[['title']]"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "wrestler",
      "query": "SELECT Team FROM Elimination WHERE Eliminated_By  =  \"Orton\" INTERSECT SELECT Team FROM Elimination WHERE Eliminated_By  =  \"Benjamin\"",
      "query_toks": [
        "SELECT",
        "Team",
        "FROM",
        "Elimination",
        "WHERE",
        "Eliminated_By",
        "=",
        "``",
        "Orton",
        "''",
        "INTERSECT",
        "SELECT",
        "Team",
        "FROM",
        "Elimination",
        "WHERE",
        "Eliminated_By",
        "=",
        "``",
        "Benjamin",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "team",
        "from",
        "elimination",
        "where",
        "eliminated_by",
        "=",
        "value",
        "intersect",
        "select",
        "team",
        "from",
        "elimination",
        "where",
        "eliminated_by",
        "=",
        "value"
      ],
      "question": "Show the teams that have both wrestlers eliminated by \"Orton\" and wrestlers eliminated by \"Benjamin\".",
      "question_toks": [
        "Show",
        "the",
        "teams",
        "that",
        "have",
        "both",
        "wrestlers",
        "eliminated",
        "by",
        "``",
        "Orton",
        "''",
        "and",
        "wrestlers",
        "eliminated",
        "by",
        "``",
        "Benjamin",
        "''",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                10,
                false
              ],
              null
            ],
            "\"Orton\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": {
          "from": {
            "table_units": [
              [
                "table_unit",
                1
              ]
            ],
            "conds": []
          },
          "select": [
            false,
            [
              [
                0,
                [
                  0,
                  [
                    0,
                    9,
                    false
                  ],
                  null
                ]
              ]
            ]
          ],
          "where": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  10,
                  false
                ],
                null
              ],
              "\"Benjamin\"",
              null
            ]
          ],
          "groupBy": [],
          "having": [],
          "orderBy": [],
          "limit": null,
          "intersect": null,
          "union": null,
          "except": null
        },
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "wrestler": [
          "Wrestler_ID",
          "Name",
          "Reign",
          "Days_held",
          "Location",
          "Event"
        ],
        "Elimination": [
          "Elimination_ID",
          "Wrestler_ID",
          "Team",
          "Eliminated_By",
          "Elimination_Move",
          "Time"
        ]
      },
      "answer": [
        [
          "Team Batista"
        ]
      ]
    },
    "generated_programs": [
      "t1 = Elimination[Elimination['eliminated_by'] == 'orton']['team']\nt2 = Elimination[Elimination['eliminated_by'] == 'benjamin']['team']\nanswer = t1[t1.isin(t2)]",
      "team_orton = Elimination[Elimination['eliminated_by'] == 'orton']['team']\nteam_benjamin = Elimination[Elimination['eliminated_by'] == 'benjamin']['team']\nanswer = pd.Series(sorted(set(team_orton) & set(team_benjamin)))",
      "orton = Elimination[Elimination['eliminated_by'] == 'Orton']\nbenjamin = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = pd.merge(orton, benjamin, on='team')['team'].unique()",
      "t1 = Elimination[Elimination['eliminated_by'] == 'orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'benjamin']\nanswer = t1[t1['team'].isin(t2['team'])]['team']",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = pd.Series(np.intersect1d(t1['team'], t2['team']))",
      "t2 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt3 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nt4 = t2.merge(t3, on='team', how='inner')\nanswer = t4['team'].unique()",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nt3 = t1['team'].to_frame()\nt4 = t2['team'].to_frame()\nt5 = pd.merge(t3, t4, on='team')\nanswer = t5['team']",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']['team']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']['team']\nanswer = (t1 & t2).to_frame().rename(columns={'team': 'team'})",
      "t1 = Elimination[Elimination['eliminated_by'] == \"Orton\"]['team']\nt2 = Elimination[Elimination['eliminated_by'] == \"Benjamin\"]['team']\nanswer = pd.Series(set(t1).intersection(set(t2)))",
      "team1 = Elimination[Elimination['eliminated_by'] == 'Orton']['team']\nteam2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']['team']\nanswer = pd.Series(sorted(set(team1).intersection(set(team2))))",
      "t1 = Elimination[Elimination['eliminated_by'] == 'orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'benjamin']\nt3 = pd.merge(t1, t2, indicator = True)\nt4 = t3[t3['_merge'] == 'both']\nanswer = t4['team_x'].unique()",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton'][['team']].drop_duplicates()\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin'][['team']].drop_duplicates()\nanswer = pd.merge(t1, t2, on='team').drop_duplicates()",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']['team']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']['team']\nanswer = t1.intersection(t2)",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = list(set(t1['team']).intersection(set(t2['team'])))",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = t1[t1['team'].isin(t2['team'])]['team']",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = t1[t1['team'].isin(t2['team'])]['team']",
      "t1 = Elimination[Elimination['eliminated_by'] == \"Orton\"]\nt2 = Elimination[Elimination['eliminated_by'] == \"Benjamin\"]\nt1 = t1['team'].to_frame().rename(index=str, columns={'team': 'team1'})\nt2 = t2['team'].to_frame().rename(index=str, columns={'team': 'team2'})\nt3 = t1.merge(t2, left_on='team1', right_on='team2')\nanswer = pd.Series(t3['team1'].drop_duplicates())",
      "t1 = Elimination[(Elimination['eliminated_by'] == \"Orton\")]['team']\nt2 = Elimination[(Elimination['eliminated_by'] == \"Benjamin\")]['team']\nanswer = pd.Series(t1.isin(t2.values).sum())",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']\nanswer = t1['team'].merge(t2['team'], on='team')",
      "t1 = Elimination[Elimination['eliminated_by'] == 'Orton']['team']\nt2 = Elimination[Elimination['eliminated_by'] == 'Benjamin']['team']\nanswer = t1[t1.isin(t2)].drop_duplicates()"
    ],
    "acc@20": 10,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "climbing",
      "query": "SELECT Country FROM mountain WHERE Height  >  5600 INTERSECT SELECT Country FROM mountain WHERE Height  <  5200",
      "query_toks": [
        "SELECT",
        "Country",
        "FROM",
        "mountain",
        "WHERE",
        "Height",
        ">",
        "5600",
        "INTERSECT",
        "SELECT",
        "Country",
        "FROM",
        "mountain",
        "WHERE",
        "Height",
        "<",
        "5200"
      ],
      "query_toks_no_value": [
        "select",
        "country",
        "from",
        "mountain",
        "where",
        "height",
        ">",
        "value",
        "intersect",
        "select",
        "country",
        "from",
        "mountain",
        "where",
        "height",
        "<",
        "value"
      ],
      "question": "Show the countries that have mountains with height more than 5600 stories and mountains with height less than 5200.",
      "question_toks": [
        "Show",
        "the",
        "countries",
        "that",
        "have",
        "mountains",
        "with",
        "height",
        "more",
        "than",
        "5600",
        "stories",
        "and",
        "mountains",
        "with",
        "height",
        "less",
        "than",
        "5200",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                3,
                false
              ],
              null
            ],
            5600.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": {
          "from": {
            "table_units": [
              [
                "table_unit",
                0
              ]
            ],
            "conds": []
          },
          "select": [
            false,
            [
              [
                0,
                [
                  0,
                  [
                    0,
                    6,
                    false
                  ],
                  null
                ]
              ]
            ]
          ],
          "where": [
            [
              false,
              4,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ],
              5200.0,
              null
            ]
          ],
          "groupBy": [],
          "having": [],
          "orderBy": [],
          "limit": null,
          "intersect": null,
          "union": null,
          "except": null
        },
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "mountain": [
          "Mountain_ID",
          "Name",
          "Height",
          "Prominence",
          "Range",
          "Country"
        ],
        "climber": [
          "Climber_ID",
          "Name",
          "Country",
          "Time",
          "Points",
          "Mountain_ID"
        ]
      },
      "answer": [
        [
          "Tanzania"
        ]
      ]
    },
    "generated_programs": [
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = t1[t1['country'].isin(t2['country'])]['country']",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = t1.append(t2).drop_duplicates()",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = t1['country'].append(t2['country']).unique()",
      "t1 = mountain[mountain['height'] > 5600]['country'].unique()\nt2 = mountain[mountain['height'] < 5200]['country'].unique()\nanswer = np.intersect1d(t1, t2)",
      "cond_1 = mountain['height'] > 5600\ncond_2 = mountain['height'] < 5200\nt1 = mountain[cond_1]['country']\nt2 = mountain[cond_2]['country']\nanswer = pd.concat([t1, t2]).drop_duplicates()",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = pd.Series(np.intersect1d(t1, t2))",
      "t1 = mountain[(mountain['height'] > 5600)]['country']\nt2 = mountain[(mountain['height'] < 5200)]['country']\nanswer = t2.intersection(t1)",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = pd.concat([t1,t2]).unique()",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = pd.merge(t1, t2, on='country')",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = pd.concat([t1, t2])['country'].unique()",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = t1['country'].append(t2['country']).drop_duplicates()",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = t1[t1.isin(t2)]",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = t1.loc[t1['country'].isin(t2['country']),['country']]",
      "t1 = mountain[mountain['height'] > 5600]['country'].unique()\nt2 = mountain[mountain['height'] < 5200]['country'].unique()\nanswer =  np.intersect1d(t1, t2)",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = t1.intersection(t2)",
      "mountain1 = mountain[mountain['height'] > 5600]\nmountain2 = mountain[mountain['height'] < 5200]\nanswer = np.intersect1d(mountain1['country'], mountain2['country'])",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nanswer = t1[['country']].merge(t2[['country']], how='inner')",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = t1.append(t2).unique()",
      "t1 = mountain[mountain['height'] > 5600]\nt2 = mountain[mountain['height'] < 5200]\nt3 = t1['country'].isin(t2['country'])\nanswer = t3[t3].unique()",
      "t1 = mountain[mountain['height'] > 5600]['country']\nt2 = mountain[mountain['height'] < 5200]['country']\nanswer = t1.intersection(t2)"
    ],
    "acc@20": 4,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "gymnast",
      "query": "SELECT T2.Hometown FROM gymnast AS T1 JOIN people AS T2 ON T1.Gymnast_ID  =  T2.People_ID GROUP BY T2.Hometown HAVING COUNT(*)  >=  2",
      "query_toks": [
        "SELECT",
        "T2.Hometown",
        "FROM",
        "gymnast",
        "AS",
        "T1",
        "JOIN",
        "people",
        "AS",
        "T2",
        "ON",
        "T1.Gymnast_ID",
        "=",
        "T2.People_ID",
        "GROUP",
        "BY",
        "T2.Hometown",
        "HAVING",
        "COUNT",
        "(",
        "*",
        ")",
        ">",
        "=",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "hometown",
        "from",
        "gymnast",
        "as",
        "t1",
        "join",
        "people",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "gymnast_id",
        "=",
        "t2",
        ".",
        "people_id",
        "group",
        "by",
        "t2",
        ".",
        "hometown",
        "having",
        "count",
        "(",
        "*",
        ")",
        ">",
        "=",
        "value"
      ],
      "question": "Give the hometowns from which two or more gymnasts are from.",
      "question_toks": [
        "Give",
        "the",
        "hometowns",
        "from",
        "which",
        "two",
        "or",
        "more",
        "gymnasts",
        "are",
        "from",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                9,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  13,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            13,
            false
          ]
        ],
        "having": [
          [
            false,
            5,
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "gymnast": [
          "Gymnast_ID",
          "Floor_Exercise_Points",
          "Pommel_Horse_Points",
          "Rings_Points",
          "Vault_Points",
          "Parallel_Bars_Points",
          "Horizontal_Bar_Points",
          "Total_Points"
        ],
        "people": [
          "People_ID",
          "Name",
          "Age",
          "Height",
          "Hometown"
        ]
      },
      "answer": [
        [
          "Santo Domingo"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby(['hometown']).size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().to_frame().reset_index()\nanswer = t2[t2.iloc[:, 1] >= 2]['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t1['count'] >= 2].sort_values().to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby(['hometown']).size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby(['hometown']).size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nanswer = t3['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1[['hometown']].groupby('hometown').size().rename('count')\nanswer = list(t2[t2 >= 2].index)",
      "t1 = pd.merge(gymnast, people, on='people_id')\nt2 = t1.groupby('hometown').size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()['hometown']"
    ],
    "acc@20": 10,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "chinook_1",
      "query": "SELECT COUNT(*) FROM ALBUM AS T1 JOIN ARTIST AS T2 ON T1.ArtistId  =  T2.ArtistId WHERE T2.Name  =  \"Metallica\"",
      "query_toks": [
        "SELECT",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "ALBUM",
        "AS",
        "T1",
        "JOIN",
        "ARTIST",
        "AS",
        "T2",
        "ON",
        "T1.ArtistId",
        "=",
        "T2.ArtistId",
        "WHERE",
        "T2.Name",
        "=",
        "``",
        "Metallica",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "album",
        "as",
        "t1",
        "join",
        "artist",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "artistid",
        "=",
        "t2",
        ".",
        "artistid",
        "where",
        "t2",
        ".",
        "name",
        "=",
        "value"
      ],
      "question": "Find the number of albums by the artist \"Metallica\".",
      "question_toks": [
        "Find",
        "the",
        "number",
        "of",
        "albums",
        "by",
        "the",
        "artist",
        "``",
        "Metallica",
        "''",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ],
              [
                0,
                4,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                5,
                false
              ],
              null
            ],
            "\"Metallica\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Album": [
          "AlbumId",
          "Title",
          "ArtistId"
        ],
        "Artist": [
          "ArtistId",
          "Name"
        ],
        "Customer": [
          "CustomerId",
          "FirstName",
          "LastName",
          "Company",
          "Address",
          "City",
          "State",
          "Country",
          "PostalCode",
          "Phone",
          "Fax",
          "Email",
          "SupportRepId"
        ],
        "Employee": [
          "EmployeeId",
          "LastName",
          "FirstName",
          "Title",
          "ReportsTo",
          "BirthDate",
          "HireDate",
          "Address",
          "City",
          "State",
          "Country",
          "PostalCode",
          "Phone",
          "Fax",
          "Email"
        ],
        "Genre": [
          "GenreId",
          "Name"
        ],
        "Invoice": [
          "InvoiceId",
          "CustomerId",
          "InvoiceDate",
          "BillingAddress",
          "BillingCity",
          "BillingState",
          "BillingCountry",
          "BillingPostalCode",
          "Total"
        ],
        "InvoiceLine": [
          "InvoiceLineId",
          "InvoiceId",
          "TrackId",
          "UnitPrice",
          "Quantity"
        ],
        "MediaType": [
          "MediaTypeId",
          "Name"
        ],
        "Playlist": [
          "PlaylistId",
          "Name"
        ],
        "PlaylistTrack": [
          "PlaylistId",
          "TrackId"
        ],
        "Track": [
          "TrackId",
          "Name",
          "AlbumId",
          "MediaTypeId",
          "GenreId",
          "Composer",
          "Milliseconds",
          "Bytes",
          "UnitPrice"
        ]
      },
      "answer": [
        [
          10
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = t1[t1['name'] == 'Metallica'].shape[0]",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica'].shape[0]\nanswer = pd.Series(t2)",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica']['artistid'].size)",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = t1[t1['name'] == 'Metallica']['title'].count()",
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nanswer = pd.Series(t1[t1['name'] == 'Metallica'].shape[0])",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nanswer = t1[t1['name'] == 'Metallica'].shape[0]",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\nt2 = t1[t1['name'] == 'Metallica']\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Album, Artist, on='artistid')\nt2 = t1[t1['name'] == 'Metallica']['albumid']\nanswer = pd.Series(t2.size)",
      "t1 = pd.merge(Album, Artist, left_on='artistid', right_on='artistid')\na = t1[t1['name'] == 'Metallica'].shape[0]\nanswer = pd.Series(a)"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "flight_1",
      "query": "SELECT flno ,  distance FROM Flight ORDER BY price DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "flno",
        ",",
        "distance",
        "FROM",
        "Flight",
        "ORDER",
        "BY",
        "price",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "flno",
        ",",
        "distance",
        "from",
        "flight",
        "order",
        "by",
        "price",
        "desc",
        "limit",
        "value"
      ],
      "question": "Show the flight number and distance of the flight with maximum price.",
      "question_toks": [
        "Show",
        "the",
        "flight",
        "number",
        "and",
        "distance",
        "of",
        "the",
        "flight",
        "with",
        "maximum",
        "price",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                0,
                7,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "flight": [
          "flno",
          "origin",
          "destination",
          "distance",
          "departure_date",
          "arrival_date",
          "price",
          "aid"
        ],
        "aircraft": [
          "aid",
          "name",
          "distance"
        ],
        "employee": [
          "eid",
          "name",
          "salary"
        ],
        "certificate": [
          "eid",
          "aid"
        ]
      },
      "answer": [
        [
          2,
          5478
        ]
      ]
    },
    "generated_programs": [
      "t1 = flight.sort_values('price', ascending=False).head(1).reset_index()\nanswer = t1[['flno', 'distance']]",
      "answer = flight.sort_values('price', ascending=False)[['flno', 'distance']].head(1)",
      "answer = flight[['flno', 'distance']].sort_values('price', ascending = False).head(1)",
      "t1 = flight.sort_values('price', ascending=False).head(1).reset_index()\nanswer = t1[['flno', 'distance']]",
      "t1 = flight.sort_values('price', ascending = False).head(1).reset_index()\nanswer = t1[['flno', 'distance']]",
      "t1 = flight.sort_values('price', ascending=False)\nanswer = t1[['flno', 'distance']].head(1)",
      "t1 = flight.sort_values('price', ascending=False).head(1)\nanswer = t1[['flno', 'distance']]",
      "t1 = flight[['flno', 'distance']]\nanswer = t1.sort_values(['price'], ascending=False).head(1)",
      "t1 = flight.sort_values(by='price', ascending=False)\nanswer = t1.loc[t1['flno'] == t1['flno'].iloc[0]]",
      "answer = flight[['flno', 'distance']].sort_values('price', ascending=False).head(1)",
      "t1 = flight.sort_values('price', ascending=False).head(1).reset_index()\nanswer = t1[['flno', 'distance']]",
      "answer = flight[['flno', 'distance']].sort_values('price', ascending=False).head(1)",
      "t1 = flight.sort_values('price', ascending=False).head(1)\nanswer = t1[['flno', 'distance']]",
      "t1 = flight.sort_values('price', ascending = False).head(1)\nanswer = t1[['flno', 'distance']]",
      "answer = flight.sort_values('price', ascending=False).head(1)[['flno', 'distance']]",
      "t1 = flight.sort_values('price', ascending=False).head(1)[['flno', 'distance']]\nanswer = t1",
      "answer = flight.loc[flight.price.idxmax()][['flno', 'distance']]",
      "t1 = flight.sort_values('price', ascending=False).head(1)\nanswer = t1[['flno', 'distance']]",
      "t = flight.sort_values('price', ascending = False).head(1)\nanswer = t[['flno', 'distance']]",
      "answer = flight[['flno', 'distance']].sort_values('price', ascending=False).head(1)"
    ],
    "acc@20": 14,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "customers_and_products_contacts",
      "query": "SELECT T1.customer_name FROM customers AS T1 JOIN customer_orders AS T2 ON T1.customer_id  =  T2.customer_id WHERE T1.payment_method_code  =  'Credit Card' GROUP BY T1.customer_id HAVING count(*)  >  2",
      "query_toks": [
        "SELECT",
        "T1.customer_name",
        "FROM",
        "customers",
        "AS",
        "T1",
        "JOIN",
        "customer_orders",
        "AS",
        "T2",
        "ON",
        "T1.customer_id",
        "=",
        "T2.customer_id",
        "WHERE",
        "T1.payment_method_code",
        "=",
        "'Credit",
        "Card",
        "'",
        "GROUP",
        "BY",
        "T1.customer_id",
        "HAVING",
        "count",
        "(",
        "*",
        ")",
        ">",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "customer_name",
        "from",
        "customers",
        "as",
        "t1",
        "join",
        "customer_orders",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "customer_id",
        "=",
        "t2",
        ".",
        "customer_id",
        "where",
        "t1",
        ".",
        "payment_method_code",
        "=",
        "value",
        "group",
        "by",
        "t1",
        ".",
        "customer_id",
        "having",
        "count",
        "(",
        "*",
        ")",
        ">",
        "value"
      ],
      "question": "Show the names of customers who use Credit Card payment method and have more than 2 orders.",
      "question_toks": [
        "Show",
        "the",
        "names",
        "of",
        "customers",
        "who",
        "use",
        "Credit",
        "Card",
        "payment",
        "method",
        "and",
        "have",
        "more",
        "than",
        "2",
        "orders",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              5
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  11,
                  false
                ],
                null
              ],
              [
                0,
                29,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                12,
                false
              ],
              null
            ],
            "\"Credit Card\"",
            null
          ]
        ],
        "groupBy": [
          [
            0,
            11,
            false
          ]
        ],
        "having": [
          [
            false,
            3,
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "line_1_number_building",
          "city",
          "zip_postcode",
          "state_province_county",
          "country"
        ],
        "Products": [
          "product_id",
          "product_type_code",
          "product_name",
          "product_price"
        ],
        "Customers": [
          "customer_id",
          "payment_method_code",
          "customer_number",
          "customer_name",
          "customer_address",
          "customer_phone",
          "customer_email"
        ],
        "Contacts": [
          "contact_id",
          "customer_id",
          "gender",
          "first_name",
          "last_name",
          "contact_phone"
        ],
        "Customer_Address_History": [
          "customer_id",
          "address_id",
          "date_from",
          "date_to"
        ],
        "Customer_Orders": [
          "order_id",
          "customer_id",
          "order_date",
          "order_status_code"
        ],
        "Order_Items": [
          "order_item_id",
          "order_id",
          "product_id",
          "order_quantity"
        ]
      },
      "answer": [
        [
          "Sterling"
        ],
        [
          "Cleo"
        ]
      ]
    },
    "generated_programs": [
      "t1 = Customers[Customers['payment_method_code'] == 'credit card']\nt2 = pd.merge(t1, Customer_Orders, on='customer_id')\nt3 = t2.groupby('customer_id').size().rename('count')\nt4 = t3[t3 > 2].to_frame().reset_index()\nt5 = pd.merge(t4, Customers, on='customer_id')\nanswer = t5.rename(columns={'customer_name_x': 'customer_name'})['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card'].groupby('customer_id').size().rename('size')\nt3 = t2.to_frame().reset_index()\nt4 = pd.merge(t3, Customers, on='customer_id')\nanswer = t4[t4['size'] > 2]['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'Credit Card']\nt3 = t2.groupby(['customer_id', 'customer_name']).size().rename('count')\nanswer = t3[t3 > 2].to_frame().reset_index()['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt1 = t1[t1['payment_method_code'] == 'credit card']\nt2 = t1.groupby('customer_id').size().rename('count')\nt2 = t2[t2 > 2]\nt3 = t2.to_frame().reset_index()\nanswer = pd.merge(t3, Customers, on='customer_id')['customer_name']",
      "t1 = Customers[Customers['payment_method_code'] == 'credit card']\nt2 = pd.merge(t1, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt3 = t2.groupby('customer_name').size().rename('count')\nanswer = t3[t3 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'Credit Card']\nt3 = t2.groupby('customer_id').size()\nt4 = t3[t3 > 2].reset_index()\nt5 = pd.merge(t4, Customers, on='customer_id')\nanswer = t5['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card'].groupby('customer_id').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t4['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1.groupby('customer_id').size().rename('count')\nanswer = t1[t1['payment_method_code'] == 'credit card'][['customer_name', 'customer_id']].drop_duplicates().set_index('customer_id').loc[t2[t2 > 2].index].reset_index(drop=True)",
      "t1 = pd.merge(Customers, Customer_Orders, how='inner', on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card'].groupby(['customer_id', 'customer_name']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = pd.DataFrame(t1.groupby('customer_id')['order_id'].count())\nt3 = t1.merge(t2, on='customer_id')\nt4 = t3[t3['order_id_x'] > 2]\nanswer = t4['customer_name'].unique()",
      "t1 = Customers[Customers['payment_method_code'] == 'credit card']\nt2 = pd.merge(t1, Customer_Orders, on='customer_id')\nt3 = t2['customer_id'].value_counts().rename_axis('customer_id').reset_index(name='count')\nt4 = t3[t3['count'] > 2]\nt5 = pd.merge(t4, Customers, on='customer_id')\nanswer = t5['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card']\nt3 = t2.groupby('customer_id').size().rename('count')\nt4 = t3[t3 > 2].to_frame().reset_index()\nt5 = pd.merge(t4, Customer_Orders, on='customer_id')\nanswer = t5['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card']\nt3 = t2.groupby('customer_name').size().rename('count').to_frame()\nanswer = t3[t3['count'] > 2].reset_index()['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1.groupby('customer_id').size()\nt3 = t1[t1['customer_id'].isin(t2[t2 > 2].index)]\nanswer = t3[t3['payment_method_code'] == 'Credit Card']['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1.groupby('customer_id').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Customers, left_on='customer_id', right_on='customer_id')\nt5 = t4[t4['payment_method_code'] == 'Credit Card']\nanswer = t5['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1.groupby('customer_id').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Customers, on='customer_id')\nanswer = t4[t4['payment_method_code'] == 'Credit Card']['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card']\nt3 = t2.groupby('customer_id').size().rename('count').to_frame().reset_index()\nt4 = t3[t3['count'] > 2].reset_index()\nanswer = Customers[Customers['customer_id'].isin(t4['customer_id'])]['customer_name']",
      "t1 = pd.merge(Customers, Customer_Orders, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card']\nt3 = t2.groupby('customer_name').size().rename('count')\nanswer = t3[t3 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'Credit Card'].groupby(['customer_id'])\nanswer = t2.filter(lambda x: len(x) > 2)['customer_name'].unique()",
      "t1 = pd.merge(Customers, Customer_Orders, on='customer_id')\nt2 = t1[t1['payment_method_code'] == 'credit card'].groupby(['customer_id', 'customer_name']).size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nanswer = t3['customer_name']"
    ],
    "acc@20": 5,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "customer_deliveries",
      "query": "SELECT count(DISTINCT payment_method) FROM customers",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "DISTINCT",
        "payment_method",
        ")",
        "FROM",
        "customers"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "distinct",
        "payment_method",
        ")",
        "from",
        "customers"
      ],
      "question": "How many different payment methods are there?",
      "question_toks": [
        "How",
        "many",
        "different",
        "payment",
        "methods",
        "are",
        "there",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  12,
                  true
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Products": [
          "product_id",
          "product_name",
          "product_price",
          "product_description"
        ],
        "Addresses": [
          "address_id",
          "address_details",
          "city",
          "zip_postcode",
          "state_province_county",
          "country"
        ],
        "Customers": [
          "customer_id",
          "payment_method",
          "customer_name",
          "customer_phone",
          "customer_email",
          "date_became_customer"
        ],
        "Regular_Orders": [
          "regular_order_id",
          "distributer_id"
        ],
        "Regular_Order_Products": [
          "regular_order_id",
          "product_id"
        ],
        "Actual_Orders": [
          "actual_order_id",
          "order_status_code",
          "regular_order_id",
          "actual_order_date"
        ],
        "Actual_Order_Products": [
          "actual_order_id",
          "product_id"
        ],
        "Customer_Addresses": [
          "customer_id",
          "address_id",
          "date_from",
          "address_type",
          "date_to"
        ],
        "Delivery_Routes": [
          "route_id",
          "route_name",
          "other_route_details"
        ],
        "Delivery_Route_Locations": [
          "location_code",
          "route_id",
          "location_address_id",
          "location_name"
        ],
        "Trucks": [
          "truck_id",
          "truck_licence_number",
          "truck_details"
        ],
        "Employees": [
          "employee_id",
          "employee_address_id",
          "employee_name",
          "employee_phone"
        ],
        "Order_Deliveries": [
          "location_code",
          "actual_order_id",
          "delivery_status_code",
          "driver_employee_id",
          "truck_id",
          "delivery_date"
        ]
      },
      "answer": [
        [
          4
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().shape[0])",
      "answer = pd.Series(Customers['payment_method'].unique().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "t1 = Customers[['payment_method']]\nt2 = t1.drop_duplicates()\nanswer = pd.Series(t2.shape[0])",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].unique().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().shape[0])",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].drop_duplicates().size)",
      "answer = pd.Series(Customers['payment_method'].unique().size)"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "driving_school",
      "query": "SELECT count(*) FROM Lessons AS T1 JOIN Staff AS T2 ON T1.staff_id = T2.staff_id WHERE T2.first_name LIKE \"%a%\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Lessons",
        "AS",
        "T1",
        "JOIN",
        "Staff",
        "AS",
        "T2",
        "ON",
        "T1.staff_id",
        "=",
        "T2.staff_id",
        "WHERE",
        "T2.first_name",
        "LIKE",
        "``",
        "%",
        "a",
        "%",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "lessons",
        "as",
        "t1",
        "join",
        "staff",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "staff_id",
        "=",
        "t2",
        ".",
        "staff_id",
        "where",
        "t2",
        ".",
        "first_name",
        "like",
        "value"
      ],
      "question": "How many lessons were taught by a staff member whose first name has the letter 'a' in it?",
      "question_toks": [
        "How",
        "many",
        "lessons",
        "were",
        "taught",
        "by",
        "a",
        "staff",
        "member",
        "whose",
        "first",
        "name",
        "has",
        "the",
        "letter",
        "'a",
        "'",
        "in",
        "it",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  36,
                  false
                ],
                null
              ],
              [
                0,
                7,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            9,
            [
              0,
              [
                0,
                10,
                false
              ],
              null
            ],
            "\"%a%\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "line_1_number_building",
          "city",
          "zip_postcode",
          "state_province_county",
          "country"
        ],
        "Staff": [
          "staff_id",
          "staff_address_id",
          "nickname",
          "first_name",
          "middle_name",
          "last_name",
          "date_of_birth",
          "date_joined_staff",
          "date_left_staff"
        ],
        "Vehicles": [
          "vehicle_id",
          "vehicle_details"
        ],
        "Customers": [
          "customer_id",
          "customer_address_id",
          "customer_status_code",
          "date_became_customer",
          "date_of_birth",
          "first_name",
          "last_name",
          "amount_outstanding",
          "email_address",
          "phone_number",
          "cell_mobile_phone_number"
        ],
        "Customer_Payments": [
          "customer_id",
          "datetime_payment",
          "payment_method_code",
          "amount_payment"
        ],
        "Lessons": [
          "lesson_id",
          "customer_id",
          "lesson_status_code",
          "staff_id",
          "vehicle_id",
          "lesson_date",
          "lesson_time",
          "price"
        ]
      },
      "answer": [
        [
          5
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(staff, lesson, on='staff_id')\nt2 = t1[t1.first_name.str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Staff, Lessons, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a', regex=False)].shape[0])",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a', regex=True)]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a', case=False)].shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a')].shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nresult = t1[t1['first_name'].str.contains('a')].shape[0]\nanswer = pd.Series(result)",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a', case=False)]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a', regex=False)].shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = t1[t1['first_name'].str.contains('a')].shape[0]",
      "t1 = pd.merge(Lessons, Staff, left_on='staff_id', right_on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a', regex=False)]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a')].shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nt2 = t1[t1['first_name'].str.contains('a')]\nanswer = pd.Series(t2.shape[0])",
      "t1 = pd.merge(Lessons, Staff, on='staff_id')\nanswer = pd.Series(t1[t1['first_name'].str.contains('a')].shape[0])"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "debate",
      "query": "SELECT T2.Name ,  COUNT(*) FROM debate_people AS T1 JOIN people AS T2 ON T1.Affirmative  =  T2.People_ID GROUP BY T2.Name",
      "query_toks": [
        "SELECT",
        "T2.Name",
        ",",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "debate_people",
        "AS",
        "T1",
        "JOIN",
        "people",
        "AS",
        "T2",
        "ON",
        "T1.Affirmative",
        "=",
        "T2.People_ID",
        "GROUP",
        "BY",
        "T2.Name"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "name",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "debate_people",
        "as",
        "t1",
        "join",
        "people",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "affirmative",
        "=",
        "t2",
        ".",
        "people_id",
        "group",
        "by",
        "t2",
        ".",
        "name"
      ],
      "question": "Show the names of people and the number of times they have been on the affirmative side of debates.",
      "question_toks": [
        "Show",
        "the",
        "names",
        "of",
        "people",
        "and",
        "the",
        "number",
        "of",
        "times",
        "they",
        "have",
        "been",
        "on",
        "the",
        "affirmative",
        "side",
        "of",
        "debates",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  11,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            3,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "people": [
          "People_ID",
          "District",
          "Name",
          "Party",
          "Age"
        ],
        "debate": [
          "Debate_ID",
          "Date",
          "Venue",
          "Num_of_Audience"
        ],
        "debate_people": [
          "Debate_ID",
          "Affirmative",
          "Negative",
          "If_Affirmative_Win"
        ]
      },
      "answer": [
        [
          "James Humphrey",
          1
        ],
        [
          "Luther C. Carter",
          1
        ],
        [
          "Thomas J. Barr",
          1
        ],
        [
          "William B. Maclay",
          2
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(people, debate_people, left_on = 'people_id', right_on='affirmative')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id', suffixes=('_debate_people', '_people'))\nanswer = t1.groupby('name').size().rename('count').to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nanswer = t1.groupby('name').size().rename('count')",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(people, debate_people, left_on='people_id', right_on='affirmative')\nanswer = t1.groupby('name').size().rename('count').to_frame()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count').reset_index()\nanswer = t2",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nanswer = t1.groupby('name').size().to_frame().reset_index().rename(columns={0:'count'})",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count').to_frame().reset_index()\nanswer = t2",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nt2 = t1.groupby('name').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = pd.merge(debate_people, people, left_on='affirmative', right_on='people_id')\nanswer = t1.groupby('name').size().rename('count').to_frame()"
    ],
    "acc@20": 15,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "entertainment_awards",
      "query": "SELECT Name FROM artwork WHERE TYPE != \"Program Talent Show\"",
      "query_toks": [
        "SELECT",
        "Name",
        "FROM",
        "artwork",
        "WHERE",
        "TYPE",
        "!",
        "=",
        "``",
        "Program",
        "Talent",
        "Show",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        "from",
        "artwork",
        "where",
        "type",
        "!",
        "=",
        "value"
      ],
      "question": "List the name of artworks whose type is not \"Program Talent Show\".",
      "question_toks": [
        "List",
        "the",
        "name",
        "of",
        "artworks",
        "whose",
        "type",
        "is",
        "not",
        "``",
        "Program",
        "Talent",
        "Show",
        "''",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            7,
            [
              0,
              [
                0,
                8,
                false
              ],
              null
            ],
            "\"Program Talent Show\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "festival_detail": [
          "Festival_ID",
          "Festival_Name",
          "Chair_Name",
          "Location",
          "Year",
          "Num_of_Audience"
        ],
        "artwork": [
          "Artwork_ID",
          "Type",
          "Name"
        ],
        "nomination": [
          "Artwork_ID",
          "Festival_ID",
          "Result"
        ]
      },
      "answer": [
        [
          "Indonesian Idol"
        ],
        [
          "I Know"
        ],
        [
          "Loving you"
        ],
        [
          "Why"
        ],
        [
          "Boys"
        ],
        [
          "Daniel Mananta"
        ],
        [
          "Back Home"
        ]
      ]
    },
    "generated_programs": [
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'Program Talent Show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "t1 = artwork[artwork['type'] != \"program talent show\"]\nanswer = t1['name']",
      "t1 = artwork[artwork['type'] != 'program talent show']\nanswer = t1['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "t1 = artwork[artwork['type'] != 'program talent show']\nanswer = t1['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']",
      "answer = artwork[artwork['type'] != 'program talent show']['name']"
    ],
    "acc@20": 1,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "allergy_1",
      "query": "SELECT allergy ,  allergytype FROM Allergy_type",
      "query_toks": [
        "SELECT",
        "allergy",
        ",",
        "allergytype",
        "FROM",
        "Allergy_type"
      ],
      "query_toks_no_value": [
        "select",
        "allergy",
        ",",
        "allergytype",
        "from",
        "allergy_type"
      ],
      "question": "What are the allergies and their types?",
      "question_toks": [
        "What",
        "are",
        "the",
        "allergies",
        "and",
        "their",
        "types",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Allergy_Type": [
          "Allergy",
          "AllergyType"
        ],
        "Has_Allergy": [
          "StuID",
          "Allergy"
        ],
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ]
      },
      "answer": [
        [
          "Eggs",
          "food"
        ],
        [
          "Nuts",
          "food"
        ],
        [
          "Milk",
          "food"
        ],
        [
          "Shellfish",
          "food"
        ],
        [
          "Anchovies",
          "food"
        ],
        [
          "Wheat",
          "food"
        ],
        [
          "Soy",
          "food"
        ],
        [
          "Ragweed",
          "environmental"
        ],
        [
          "Tree Pollen",
          "environmental"
        ],
        [
          "Grass Pollen",
          "environmental"
        ],
        [
          "Cat",
          "animal"
        ],
        [
          "Dog",
          "animal"
        ],
        [
          "Rodent",
          "animal"
        ],
        [
          "Bee Stings",
          "animal"
        ]
      ]
    },
    "generated_programs": [
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type",
      "answer = Allergy_Type",
      "answer = Allergy_Type",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type.rename(columns={'allergy':'allergy', 'allergytype':'allergytype'})",
      "answer = Allergy_Type",
      "answer = Allergy_Type",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type[['allergy', 'allergytype']]",
      "answer = Allergy_Type"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "film_rank",
      "query": "SELECT Studio ,  COUNT(*) FROM film GROUP BY Studio",
      "query_toks": [
        "SELECT",
        "Studio",
        ",",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "film",
        "GROUP",
        "BY",
        "Studio"
      ],
      "query_toks_no_value": [
        "select",
        "studio",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "film",
        "group",
        "by",
        "studio"
      ],
      "question": "List the studios of each film and the number of films produced by that studio.",
      "question_toks": [
        "List",
        "the",
        "studios",
        "of",
        "each",
        "film",
        "and",
        "the",
        "number",
        "of",
        "films",
        "produced",
        "by",
        "that",
        "studio",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            3,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "film": [
          "Film_ID",
          "Title",
          "Studio",
          "Director",
          "Gross_in_dollar"
        ],
        "market": [
          "Market_ID",
          "Country",
          "Number_cities"
        ],
        "film_market_estimation": [
          "Estimation_ID",
          "Low_Estimate",
          "High_Estimate",
          "Film_ID",
          "Type",
          "Market_ID",
          "Year"
        ]
      },
      "answer": [
        [
          "20th Century Fox",
          2
        ],
        [
          "Columbia",
          2
        ],
        [
          "Columbia / Rastar",
          1
        ],
        [
          "MGM",
          1
        ],
        [
          "Orion / Carolco",
          1
        ],
        [
          "Paramount",
          2
        ],
        [
          "Paramount / Lorimar",
          1
        ],
        [
          "United Artists",
          1
        ],
        [
          "Universal",
          1
        ],
        [
          "Universal / RKO",
          1
        ]
      ]
    },
    "generated_programs": [
      "answer = film.groupby('studio').size().rename('count')",
      "t1 = film.groupby('studio').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "t1 = film.groupby(['studio']).size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "t1 = film.groupby('studio').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = film.groupby('studio').size().to_frame().rename(columns={0:'count'})",
      "t1 = film.groupby('studio').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "t1 = film.groupby('studio')\nt2 = t1.size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = film.groupby(['studio']).size().rename('count')\nanswer = t1.to_frame()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "t1 = film.groupby('studio').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame()",
      "answer = film.groupby('studio').size().rename('count').to_frame()",
      "answer = film.groupby('studio').size().rename('count').to_frame().reset_index()",
      "answer = film.groupby('studio').size().rename('count').to_frame()\nanswer.index.name = 'studio'"
    ],
    "acc@20": 14,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "insurance_and_eClaims",
      "query": "SELECT t2.customer_details FROM policies AS t1 JOIN customers AS t2 ON t1.customer_id  =  t2.customer_id WHERE t1.start_date  =  (SELECT max(start_date) FROM policies)",
      "query_toks": [
        "SELECT",
        "t2.customer_details",
        "FROM",
        "policies",
        "AS",
        "t1",
        "JOIN",
        "customers",
        "AS",
        "t2",
        "ON",
        "t1.customer_id",
        "=",
        "t2.customer_id",
        "WHERE",
        "t1.start_date",
        "=",
        "(",
        "SELECT",
        "max",
        "(",
        "start_date",
        ")",
        "FROM",
        "policies",
        ")"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "customer_details",
        "from",
        "policies",
        "as",
        "t1",
        "join",
        "customers",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "customer_id",
        "=",
        "t2",
        ".",
        "customer_id",
        "where",
        "t1",
        ".",
        "start_date",
        "=",
        "(",
        "select",
        "max",
        "(",
        "start_date",
        ")",
        "from",
        "policies",
        ")"
      ],
      "question": "Which customer is associated with the latest policy?",
      "question_toks": [
        "Which",
        "customer",
        "is",
        "associated",
        "with",
        "the",
        "latest",
        "policy",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ],
              [
                0,
                1,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                8,
                false
              ],
              null
            ],
            {
              "from": {
                "table_units": [
                  [
                    "table_unit",
                    2
                  ]
                ],
                "conds": []
              },
              "select": [
                false,
                [
                  [
                    1,
                    [
                      0,
                      [
                        0,
                        8,
                        false
                      ],
                      null
                    ]
                  ]
                ]
              ],
              "where": [],
              "groupBy": [],
              "having": [],
              "orderBy": [],
              "limit": null,
              "intersect": null,
              "union": null,
              "except": null
            },
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Customers": [
          "Customer_ID",
          "Customer_Details"
        ],
        "Staff": [
          "Staff_ID",
          "Staff_Details"
        ],
        "Policies": [
          "Policy_ID",
          "Customer_ID",
          "Policy_Type_Code",
          "Start_Date",
          "End_Date"
        ],
        "Claim_Headers": [
          "Claim_Header_ID",
          "Claim_Status_Code",
          "Claim_Type_Code",
          "Policy_ID",
          "Date_of_Claim",
          "Date_of_Settlement",
          "Amount_Claimed",
          "Amount_Piad"
        ],
        "Claims_Documents": [
          "Claim_ID",
          "Document_Type_Code",
          "Created_by_Staff_ID",
          "Created_Date"
        ],
        "Claims_Processing_Stages": [
          "Claim_Stage_ID",
          "Next_Claim_Stage_ID",
          "Claim_Status_Name",
          "Claim_Status_Description"
        ],
        "Claims_Processing": [
          "Claim_Processing_ID",
          "Claim_ID",
          "Claim_Outcome_Code",
          "Claim_Stage_ID",
          "Staff_ID"
        ]
      },
      "answer": [
        [
          "Selena Gerhold"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Customers, Policies, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on= 'customer_id', right_on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1.loc[t1['start_date'].idxmax()]['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nanswer = t1[t1['start_date'] == t1['start_date'].max()]['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nanswer = t1[df_dict['Policies']['start_date'] == df_dict['Policies']['start_date'].max()]['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nanswer = t1[t1['start_date'] == max(t1['start_date'])]['customer_details']",
      "max_date = Policies['start_date'].max()\nt1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == max_date]['customer_details']\nanswer = pd.Series(t2.values[0])",
      "answer = Customers[Customers['customer_id'] == Policies.loc[Policies['start_date'].idxmax(), 'customer_id']]['customer_details']",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['start_date'] == np.max(t1['start_date'])]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1.loc[t1['start_date'] == t1['start_date'].max(), 'customer_details']\nanswer = t2",
      "t1 = pd.merge(Policies, Customers, on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']",
      "t1 = pd.merge(Policies, Customers, left_on='customer_id', right_on='customer_id')\nt2 = t1[t1['start_date'] == t1['start_date'].max()]\nanswer = t2['customer_details']"
    ],
    "acc@20": 16,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "allergy_1",
      "query": "SELECT allergytype ,  count(*) FROM Allergy_type GROUP BY allergytype",
      "query_toks": [
        "SELECT",
        "allergytype",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Allergy_type",
        "GROUP",
        "BY",
        "allergytype"
      ],
      "query_toks_no_value": [
        "select",
        "allergytype",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "allergy_type",
        "group",
        "by",
        "allergytype"
      ],
      "question": "Show all allergy types and the number of allergies in each type.",
      "question_toks": [
        "Show",
        "all",
        "allergy",
        "types",
        "and",
        "the",
        "number",
        "of",
        "allergies",
        "in",
        "each",
        "type",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            2,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Allergy_Type": [
          "Allergy",
          "AllergyType"
        ],
        "Has_Allergy": [
          "StuID",
          "Allergy"
        ],
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ]
      },
      "answer": [
        [
          "animal",
          4
        ],
        [
          "environmental",
          3
        ],
        [
          "food",
          7
        ]
      ]
    },
    "generated_programs": [
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()\nanswer = t1",
      "t1 = Allergy_Type.groupby(['allergytype']).size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Allergy_Type[['allergytype', 'allergy']]\nt2 = t1.groupby('allergytype').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame()",
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = pd.merge(Allergy_Type, Has_Allergy, on='allergy').groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = pd.merge(Allergy_Type, Has_Allergy, on = 'allergy')\nt2 = t1.groupby('allergytype').size().rename('count').to_frame().reset_index()\nanswer = t2[['allergytype', 'count']]",
      "t1 = pd.merge(Allergy_Type, Has_Allergy, left_on='allergy', right_on='allergy')\nt2 = t1['allergytype'].value_counts()\nanswer = t2.to_frame().reset_index().rename(columns={'index': 'allergytype', 'allergytype': 'count'})",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "t1 = Allergy_Type.groupby('allergytype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()",
      "answer = Allergy_Type.groupby('allergytype').size().rename('count').to_frame().reset_index()"
    ],
    "acc@20": 16,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "club_1",
      "query": "SELECT count(*) FROM club WHERE clublocation  =  \"HHH\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "club",
        "WHERE",
        "clublocation",
        "=",
        "``",
        "HHH",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "club",
        "where",
        "clublocation",
        "=",
        "value"
      ],
      "question": "How many clubs are located at \"HHH\"?",
      "question_toks": [
        "How",
        "many",
        "clubs",
        "are",
        "located",
        "at",
        "``",
        "HHH",
        "''",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                12,
                false
              ],
              null
            ],
            "\"HHH\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ],
        "Club": [
          "ClubID",
          "ClubName",
          "ClubDesc",
          "ClubLocation"
        ],
        "Member_of_club": [
          "StuID",
          "ClubID",
          "Position"
        ]
      },
      "answer": [
        [
          1
        ]
      ]
    },
    "generated_programs": [
      "answer = Club[Club['clublocation'] == 'HHH'].shape[0]",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == \"HHH\"].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "t1 = Club.groupby('clublocation').size().rename('count')\nanswer = pd.Series(t1.loc[t1.index == 'HHH'].values[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])",
      "answer = pd.Series(Club[Club['clublocation'] == 'HHH'].shape[0])"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "csu_1",
      "query": "SELECT campusfee FROM campuses AS T1 JOIN csu_fees AS T2 ON T1.id  =  t2.campus WHERE t1.campus  =  \"San Francisco State University\" AND T2.year  =  1996",
      "query_toks": [
        "SELECT",
        "campusfee",
        "FROM",
        "campuses",
        "AS",
        "T1",
        "JOIN",
        "csu_fees",
        "AS",
        "T2",
        "ON",
        "T1.id",
        "=",
        "t2.campus",
        "WHERE",
        "t1.campus",
        "=",
        "``",
        "San",
        "Francisco",
        "State",
        "University",
        "''",
        "AND",
        "T2.year",
        "=",
        "1996"
      ],
      "query_toks_no_value": [
        "select",
        "campusfee",
        "from",
        "campuses",
        "as",
        "t1",
        "join",
        "csu_fees",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "campus",
        "where",
        "t1",
        ".",
        "campus",
        "=",
        "value",
        "and",
        "t2",
        ".",
        "year",
        "=",
        "value"
      ],
      "question": "What is the campus fee of \"San Francisco State University\" in year 1996?",
      "question_toks": [
        "What",
        "is",
        "the",
        "campus",
        "fee",
        "of",
        "``",
        "San",
        "Francisco",
        "State",
        "University",
        "''",
        "in",
        "year",
        "1996",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                6,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  8,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"San Francisco State University\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                7,
                false
              ],
              null
            ],
            1996.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Campuses": [
          "Id",
          "Campus",
          "Location",
          "County",
          "Year"
        ],
        "csu_fees": [
          "Campus",
          "Year",
          "CampusFee"
        ],
        "degrees": [
          "Year",
          "Campus",
          "Degrees"
        ],
        "discipline_enrollments": [
          "Campus",
          "Discipline",
          "Year",
          "Undergraduate",
          "Graduate"
        ],
        "enrollments": [
          "Campus",
          "Year",
          "TotalEnrollment_AY",
          "FTE_AY"
        ],
        "faculty": [
          "Campus",
          "Year",
          "Faculty"
        ]
      },
      "answer": [
        [
          1978
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Campuses, csu_fees, on='id')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'San Francisco State University') \n            & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1.loc[(t1['campus'] == 'San Francisco State University') & (t1['year'] == 1996), 'campusfee']",
      "t1 = pd.merge(csu_fees, Campuses, left_on='campus', right_on='id')\nt2 = t1[(t1['year_y'] == 1996) & (t1['campus_y'] == 'San Francisco State University')]\nanswer = t2['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt2 = t1[(t1['campus'] == 'San Francisco State University') & (t1['year'] == 1996)]\nanswer = pd.Series(t2['campusfee'])",
      "t1 = pd.merge(Campuses, csu_fees, on='id')\nt2 = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]\nanswer = pd.Series(t2['campusfee'])",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'san francisco state university') & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, on='id')\nt2 = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]\nanswer = t2['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, how='inner', left_on='id', right_on='campus')\nt2 = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]\nanswer = t2['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt2 = t1[t1['campus'] == 'San Francisco State University']\nanswer = t2[t2['year'] == 1996]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt1 = t1[t1['campus_x'] == 'San Francisco State University']\nanswer = t1[t1['year'] == 1996]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, on='id')\nanswer = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_x'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nanswer = t1[(t1['campus_x'] == 'San Francisco State University') & (t1['year'] == 1996)]['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt2 = t1[(t1['campus_y'] == 'san francisco state university') & (t1['year'] == 1996)]['campusfee']\nanswer = t2",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt2 = t1[(t1['campus_x'] == 'San Francisco State University') & (t1['year'] == 1996)]\nanswer = t2['campusfee']",
      "t1 = pd.merge(Campuses, csu_fees, left_on='id', right_on='campus')\nt2 = t1[(t1['campus'] == 'San Francisco State University') & (t1['year_y'] == 1996)]\nanswer = t2['campusfee']"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "baseball_1",
      "query": "SELECT count(*) FROM player WHERE birth_country = 'USA' AND bats  =  'R';",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "player",
        "WHERE",
        "birth_country",
        "=",
        "'USA",
        "'",
        "AND",
        "bats",
        "=",
        "'R",
        "'",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "player",
        "where",
        "birth_country",
        "=",
        "value",
        "and",
        "bats",
        "=",
        "value"
      ],
      "question": "How many players born in USA are right-handed batters? That is, have the batter value 'R'.",
      "question_toks": [
        "How",
        "many",
        "players",
        "born",
        "in",
        "USA",
        "are",
        "right-handed",
        "batters",
        "?",
        "That",
        "is",
        ",",
        "have",
        "the",
        "batter",
        "value",
        "'R",
        "'",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              16
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                186,
                false
              ],
              null
            ],
            "\"USA\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                200,
                false
              ],
              null
            ],
            "\"R\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "all_star": [
          "player_id",
          "year",
          "game_num",
          "game_id",
          "team_id",
          "league_id",
          "gp",
          "starting_pos"
        ],
        "appearances": [
          "year",
          "team_id",
          "league_id",
          "player_id",
          "g_all",
          "gs",
          "g_batting",
          "g_defense",
          "g_p",
          "g_c",
          "g_1b",
          "g_2b",
          "g_3b",
          "g_ss",
          "g_lf",
          "g_cf",
          "g_rf",
          "g_of",
          "g_dh",
          "g_ph",
          "g_pr"
        ],
        "manager_award": [
          "player_id",
          "award_id",
          "year",
          "league_id",
          "tie",
          "notes"
        ],
        "player_award": [
          "player_id",
          "award_id",
          "year",
          "league_id",
          "tie",
          "notes"
        ],
        "manager_award_vote": [
          "award_id",
          "year",
          "league_id",
          "player_id",
          "points_won",
          "points_max",
          "votes_first"
        ],
        "player_award_vote": [
          "award_id",
          "year",
          "league_id",
          "player_id",
          "points_won",
          "points_max",
          "votes_first"
        ],
        "batting": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "g",
          "ab",
          "r",
          "h",
          "double",
          "triple",
          "hr",
          "rbi",
          "sb",
          "cs",
          "bb",
          "so",
          "ibb",
          "hbp",
          "sh",
          "sf",
          "g_idp"
        ],
        "batting_postseason": [
          "year",
          "round",
          "player_id",
          "team_id",
          "league_id",
          "g",
          "ab",
          "r",
          "h",
          "double",
          "triple",
          "hr",
          "rbi",
          "sb",
          "cs",
          "bb",
          "so",
          "ibb",
          "hbp",
          "sh",
          "sf",
          "g_idp"
        ],
        "player_college": [
          "player_id",
          "college_id",
          "year"
        ],
        "fielding": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "pos",
          "g",
          "gs",
          "inn_outs",
          "po",
          "a",
          "e",
          "dp",
          "pb",
          "wp",
          "sb",
          "cs",
          "zr"
        ],
        "fielding_outfield": [
          "player_id",
          "year",
          "stint",
          "glf",
          "gcf",
          "grf"
        ],
        "fielding_postseason": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "round",
          "pos",
          "g",
          "gs",
          "inn_outs",
          "po",
          "a",
          "e",
          "dp",
          "tp",
          "pb",
          "sb",
          "cs"
        ],
        "hall_of_fame": [
          "player_id",
          "yearid",
          "votedby",
          "ballots",
          "needed",
          "votes",
          "inducted",
          "category",
          "needed_note"
        ],
        "home_game": [
          "year",
          "league_id",
          "team_id",
          "park_id",
          "span_first",
          "span_last",
          "games",
          "openings",
          "attendance"
        ],
        "manager": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "inseason",
          "g",
          "w",
          "l",
          "rank",
          "plyr_mgr"
        ],
        "manager_half": [
          "player_id",
          "year",
          "team_id",
          "league_id",
          "inseason",
          "half",
          "g",
          "w",
          "l",
          "rank"
        ],
        "player": [
          "player_id",
          "birth_year",
          "birth_month",
          "birth_day",
          "birth_country",
          "birth_state",
          "birth_city",
          "death_year",
          "death_month",
          "death_day",
          "death_country",
          "death_state",
          "death_city",
          "name_first",
          "name_last",
          "name_given",
          "weight",
          "height",
          "bats",
          "throws",
          "debut",
          "final_game",
          "retro_id",
          "bbref_id"
        ],
        "park": [
          "park_id",
          "park_name",
          "park_alias",
          "city",
          "state",
          "country"
        ],
        "pitching": [
          "player_id",
          "year",
          "stint",
          "team_id",
          "league_id",
          "w",
          "l",
          "g",
          "gs",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "h",
          "er",
          "hr",
          "bb",
          "so",
          "baopp",
          "era",
          "ibb",
          "wp",
          "hbp",
          "bk",
          "bfp",
          "gf",
          "r",
          "sh",
          "sf",
          "g_idp"
        ],
        "pitching_postseason": [
          "player_id",
          "year",
          "round",
          "team_id",
          "league_id",
          "w",
          "l",
          "g",
          "gs",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "h",
          "er",
          "hr",
          "bb",
          "so",
          "baopp",
          "era",
          "ibb",
          "wp",
          "hbp",
          "bk",
          "bfp",
          "gf",
          "r",
          "sh",
          "sf",
          "g_idp"
        ],
        "salary": [
          "year",
          "team_id",
          "league_id",
          "player_id",
          "salary"
        ],
        "college": [
          "college_id",
          "name_full",
          "city",
          "state",
          "country"
        ],
        "postseason": [
          "year",
          "round",
          "team_id_winner",
          "league_id_winner",
          "team_id_loser",
          "league_id_loser",
          "wins",
          "losses",
          "ties"
        ],
        "team": [
          "year",
          "league_id",
          "team_id",
          "franchise_id",
          "div_id",
          "rank",
          "g",
          "ghome",
          "w",
          "l",
          "div_win",
          "wc_win",
          "lg_win",
          "ws_win",
          "r",
          "ab",
          "h",
          "double",
          "triple",
          "hr",
          "bb",
          "so",
          "sb",
          "cs",
          "hbp",
          "sf",
          "ra",
          "er",
          "era",
          "cg",
          "sho",
          "sv",
          "ipouts",
          "ha",
          "hra",
          "bba",
          "soa",
          "e",
          "dp",
          "fp",
          "name",
          "park",
          "attendance",
          "bpf",
          "ppf",
          "team_id_br",
          "team_id_lahman45",
          "team_id_retro"
        ],
        "team_franchise": [
          "franchise_id",
          "franchise_name",
          "active",
          "na_assoc"
        ],
        "team_half": [
          "year",
          "league_id",
          "team_id",
          "half",
          "div_id",
          "div_win",
          "rank",
          "g",
          "w",
          "l"
        ]
      },
      "answer": [
        [
          10104
        ]
      ],
      "pandas_converted": "pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])"
    },
    "generated_programs": [
      "t1 = player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')]\nanswer = pd.Series(t1['player_id'].size)",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "t1 = player[player['birth_country'] == 'USA']\nt2 = t1[t1['bats'] == 'R']\nanswer = pd.Series(t2.shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'usa') & (player['bats'] == 'R')].shape[0])",
      "answer = player['player_id'][(player['birth_country'] == 'USA') & (player['bats'] == 'R')].count()",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['bats'] == 'R') & (player['birth_country'] == 'usa')].shape[0])",
      "t1 = player[player['birth_country'] == 'USA']\nt2 = t1[t1['bats'] == 'R']\n#answer = t1.shape[0]\nanswer = t2.shape[0]",
      "t1 = player[player['birth_country'] == 'USA']\nt2 = t1[t1['bats'] == 'R']\nanswer = pd.Series(t2.shape[0])",
      "t1 = player[player['birth_country'] == 'USA']\nt2 = t1[t1['bats'] == 'R']\nanswer = pd.Series(t2.shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['bats'] == 'R') & (player['birth_country'] == 'USA')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])",
      "answer = pd.Series(player[(player['birth_country'] == 'USA') & (player['bats'] == 'R')].shape[0])"
    ],
    "acc@20": 17,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "college_3",
      "query": "SELECT Room FROM FACULTY WHERE Rank  =  \"Professor\" AND Building  =  \"NEB\"",
      "query_toks": [
        "SELECT",
        "Room",
        "FROM",
        "FACULTY",
        "WHERE",
        "Rank",
        "=",
        "``",
        "Professor",
        "''",
        "AND",
        "Building",
        "=",
        "``",
        "NEB",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "room",
        "from",
        "faculty",
        "where",
        "rank",
        "=",
        "value",
        "and",
        "building",
        "=",
        "value"
      ],
      "question": "What are the rooms for members of the faculty who are professors and who live in building NEB?",
      "question_toks": [
        "What",
        "are",
        "the",
        "rooms",
        "for",
        "members",
        "of",
        "the",
        "faculty",
        "who",
        "are",
        "professors",
        "and",
        "who",
        "live",
        "in",
        "building",
        "NEB",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  15,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                12,
                false
              ],
              null
            ],
            "\"Professor\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                16,
                false
              ],
              null
            ],
            "\"NEB\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ],
        "Faculty": [
          "FacID",
          "Lname",
          "Fname",
          "Rank",
          "Sex",
          "Phone",
          "Room",
          "Building"
        ],
        "Department": [
          "DNO",
          "Division",
          "DName",
          "Room",
          "Building",
          "DPhone"
        ],
        "Member_of": [
          "FacID",
          "DNO",
          "Appt_Type"
        ],
        "Course": [
          "CID",
          "CName",
          "Credits",
          "Instructor",
          "Days",
          "Hours",
          "DNO"
        ],
        "Minor_in": [
          "StuID",
          "DNO"
        ],
        "Enrolled_in": [
          "StuID",
          "CID",
          "Grade"
        ],
        "Gradeconversion": [
          "lettergrade",
          "gradepoint"
        ]
      },
      "answer": [
        [
          "219"
        ],
        [
          "224B"
        ],
        [
          "220"
        ],
        [
          "317"
        ],
        [
          "319"
        ]
      ]
    },
    "generated_programs": [
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'neb')]['room']",
      "t1 = Faculty[Faculty['rank'] == 'professor']\nt2 = t1[t1['building'] == 'NEB']\nanswer = t2['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'Professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'neb')]['room']",
      "t1 = Faculty[Faculty['rank'] == 'professor']\nt2 = t1[t1['building'] == 'NEB']\nanswer = t2['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'Professor') & (Faculty['building'] == 'NEB')]['room']",
      "t1 = Faculty[Faculty['rank'] == 'professor']\nt2 = t1[t1['building'] == 'neb']\nanswer = t2['room']",
      "t1 = Faculty[Faculty['rank'] == 'professor']\nt2 = t1[t1['building'] == 'neb']\nanswer = t2['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "t1 = pd.merge(Faculty, Member_of, on='facid')\nt2 = t1[t1['rank'] == 'professor']\nt3 = t2[t2['building'] == 'NEB']\nanswer = t3['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']",
      "t1 = Faculty[Faculty['rank'] == 'professor']\nt2 = t1[t1['building'] == 'NEB']\nanswer = t2['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'neb')]['room']",
      "answer = Faculty[(Faculty['rank'] == 'professor') & (Faculty['building'] == 'NEB')]['room']"
    ],
    "acc@20": 2,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "cre_Theme_park",
      "query": "SELECT T1.Name ,  T2.Tourist_Attraction_ID FROM Tourist_Attractions AS T1 JOIN VISITS AS T2 ON T1.Tourist_Attraction_ID  =  T2.Tourist_Attraction_ID GROUP BY T2.Tourist_Attraction_ID HAVING count(*)  >=  2",
      "query_toks": [
        "SELECT",
        "T1.Name",
        ",",
        "T2.Tourist_Attraction_ID",
        "FROM",
        "Tourist_Attractions",
        "AS",
        "T1",
        "JOIN",
        "VISITS",
        "AS",
        "T2",
        "ON",
        "T1.Tourist_Attraction_ID",
        "=",
        "T2.Tourist_Attraction_ID",
        "GROUP",
        "BY",
        "T2.Tourist_Attraction_ID",
        "HAVING",
        "count",
        "(",
        "*",
        ")",
        ">",
        "=",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "name",
        ",",
        "t2",
        ".",
        "tourist_attraction_id",
        "from",
        "tourist_attractions",
        "as",
        "t1",
        "join",
        "visits",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "tourist_attraction_id",
        "=",
        "t2",
        ".",
        "tourist_attraction_id",
        "group",
        "by",
        "t2",
        ".",
        "tourist_attraction_id",
        "having",
        "count",
        "(",
        "*",
        ")",
        ">",
        "=",
        "value"
      ],
      "question": "Which tourist attractions are visited at least twice? Give me their names and ids.",
      "question_toks": [
        "Which",
        "tourist",
        "attractions",
        "are",
        "visited",
        "at",
        "least",
        "twice",
        "?",
        "Give",
        "me",
        "their",
        "names",
        "and",
        "ids",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              6
            ],
            [
              "table_unit",
              12
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  18,
                  false
                ],
                null
              ],
              [
                0,
                37,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  22,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  37,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            37,
            false
          ]
        ],
        "having": [
          [
            false,
            5,
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Hotel_Star_Ratings": [
          "star_rating_code",
          "star_rating_description"
        ],
        "Locations": [
          "Location_ID",
          "Location_Name",
          "Address",
          "Other_Details"
        ],
        "Ref_Attraction_Types": [
          "Attraction_Type_Code",
          "Attraction_Type_Description"
        ],
        "Visitors": [
          "Tourist_ID",
          "Tourist_Details"
        ],
        "Features": [
          "Feature_ID",
          "Feature_Details"
        ],
        "Hotels": [
          "hotel_id",
          "star_rating_code",
          "pets_allowed_yn",
          "price_range",
          "other_hotel_details"
        ],
        "Tourist_Attractions": [
          "Tourist_Attraction_ID",
          "Attraction_Type_Code",
          "Location_ID",
          "How_to_Get_There",
          "Name",
          "Description",
          "Opening_Hours",
          "Other_Details"
        ],
        "Street_Markets": [
          "Market_ID",
          "Market_Details"
        ],
        "Shops": [
          "Shop_ID",
          "Shop_Details"
        ],
        "Museums": [
          "Museum_ID",
          "Museum_Details"
        ],
        "Royal_Family": [
          "Royal_Family_ID",
          "Royal_Family_Details"
        ],
        "Theme_Parks": [
          "Theme_Park_ID",
          "Theme_Park_Details"
        ],
        "Visits": [
          "Visit_ID",
          "Tourist_Attraction_ID",
          "Tourist_ID",
          "Visit_Date",
          "Visit_Details"
        ],
        "Photos": [
          "Photo_ID",
          "Tourist_Attraction_ID",
          "Name",
          "Description",
          "Filename",
          "Other_Details"
        ],
        "Staff": [
          "Staff_ID",
          "Tourist_Attraction_ID",
          "Name",
          "Other_Details"
        ],
        "Tourist_Attraction_Features": [
          "Tourist_Attraction_ID",
          "Feature_ID"
        ]
      },
      "answer": [
        [
          "US museum",
          6476
        ],
        [
          "fun games",
          6523
        ],
        [
          "exploration trial",
          6852
        ],
        [
          "jungle cruise",
          8698
        ],
        [
          "parking",
          9919
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby(['name', 'tourist_attraction_id']).size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(Visits, Tourist_Attractions, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nanswer = t2[t2 >= 2].reset_index()\nanswer = answer[['tourist_attraction_id']]\nanswer = pd.merge(answer, Tourist_Attractions, on='tourist_attraction_id')",
      "t1 = mydb_util.select('tourist_attractions', '*')\nt2 = mydb_util.select('visits', '*')\nt3 = pd.merge(t1, t2, on='tourist_attraction_id')\nt4 = t3.groupby('tourist_attraction_id').size().rename('count')\nt5 = t4[t4 >= 2].to_frame().reset_index()\nt6 = pd.merge(t5, t1, on='tourist_attraction_id')\nanswer = t6[['tourist_attraction_id', 'name']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id')['name'].unique().rename('name')\nt3 = t2[t2.apply(len) >= 2].to_frame()\nt4 = t3.reset_index().sort_values('tourist_attraction_id')\nanswer = t4[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nt2 = t1.groupby(['tourist_attraction_id']).size().rename('count')\nt3 = pd.merge(t2[t2 >= 2].to_frame().reset_index(), Tourist_Attractions, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nanswer = t3[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nt4 = pd.merge(Tourist_Attractions, t3, on='tourist_attraction_id')\nanswer = t4[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nt4 = pd.merge(t3, Tourist_Attractions, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nanswer = t4[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = pd.merge(t2[t2 >= 2].to_frame().reset_index(), Tourist_Attractions, on='tourist_attraction_id')\nanswer = t3[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Visits, Tourist_Attractions, left_on='tourist_attraction_id', right_on='tourist_attraction_id', how='outer')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nt4 = pd.merge(t3, Tourist_Attractions, on='tourist_attraction_id', how='outer')\nanswer = t4[['tourist_attraction_id', 'name']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby(['tourist_attraction_id', 'name']).size().rename('count')\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(Tourist_Attractions, Visits, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nt2 = t1.groupby(['tourist_attraction_id', 'name']).size()\nt3 = t2[t2 >= 2].to_frame().reset_index()\nanswer = t3[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Visits, Tourist_Attractions, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nanswer = pd.merge(t3, Tourist_Attractions, on='tourist_attraction_id')[['tourist_attraction_id', 'name']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size()\nanswer = Tourist_Attractions[Tourist_Attractions['tourist_attraction_id'].isin(t2[t2 >= 2].index.values)][['tourist_attraction_id', 'name']]",
      "t1 = pd.merge(Visits, Tourist_Attractions, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id', as_index=False).size().rename('count')\nt3 = t2[t2 >= 2]\nt4 = pd.merge(t3, Tourist_Attractions, how='left', left_index=True, right_on='tourist_attraction_id')\nanswer = t4[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2]\nt4 = t3.to_frame().reset_index()\nt5 = pd.merge(Tourist_Attractions, t4, left_on='tourist_attraction_id', right_on='tourist_attraction_id')\nanswer = t5[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby(['name', 'tourist_attraction_id']).size()\nanswer = t2[t2 >= 2].to_frame().reset_index()",
      "t1 = pd.merge(Visits, Tourist_Attractions, on='tourist_attraction_id', how='outer')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nt4 = pd.merge(t3, Tourist_Attractions, on='tourist_attraction_id', how='inner')\nanswer = t4[['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby(['tourist_attraction_id']).size().rename('count')\nt3 = t2.to_frame().reset_index()\nt4 = pd.merge(t3, Tourist_Attractions, on='tourist_attraction_id')\nanswer = t4[t4['count'] >= 2][['name', 'tourist_attraction_id']]",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id').size().rename('count')\nt3 = t2[t2 >= 2].to_frame().reset_index()\nt4 = pd.merge(Tourist_Attractions, \n              t3, \n              on='tourist_attraction_id',\n              how='inner')[['tourist_attraction_id','name']]\nanswer = t4",
      "t1 = pd.merge(Tourist_Attractions, Visits, on='tourist_attraction_id')\nt2 = t1.groupby('tourist_attraction_id', as_index=False)['name'].size()\nt3 = t2[t2 >= 2].to_frame().reset_index()\nanswer = pd.merge(t3, Tourist_Attractions, on='tourist_attraction_id')[['name', 'tourist_attraction_id']]"
    ],
    "acc@20": 8,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "student_1",
      "query": "SELECT T2.lastname FROM list AS T1 JOIN teachers AS T2 ON T1.classroom  =  T2.classroom WHERE T1.firstname  =  \"GELL\" AND T1.lastname  =  \"TAMI\"",
      "query_toks": [
        "SELECT",
        "T2.lastname",
        "FROM",
        "list",
        "AS",
        "T1",
        "JOIN",
        "teachers",
        "AS",
        "T2",
        "ON",
        "T1.classroom",
        "=",
        "T2.classroom",
        "WHERE",
        "T1.firstname",
        "=",
        "``",
        "GELL",
        "''",
        "AND",
        "T1.lastname",
        "=",
        "``",
        "TAMI",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "lastname",
        "from",
        "list",
        "as",
        "t1",
        "join",
        "teachers",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "classroom",
        "=",
        "t2",
        ".",
        "classroom",
        "where",
        "t1",
        ".",
        "firstname",
        "=",
        "value",
        "and",
        "t1",
        ".",
        "lastname",
        "=",
        "value"
      ],
      "question": "Find the last names of all the teachers that teach GELL TAMI.",
      "question_toks": [
        "Find",
        "the",
        "last",
        "names",
        "of",
        "all",
        "the",
        "teachers",
        "that",
        "teach",
        "GELL",
        "TAMI",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ],
              [
                0,
                7,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"GELL\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                1,
                false
              ],
              null
            ],
            "\"TAMI\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "list": [
          "LastName",
          "FirstName",
          "Grade",
          "Classroom"
        ],
        "teachers": [
          "LastName",
          "FirstName",
          "Classroom"
        ]
      },
      "answer": []
    },
    "generated_programs": [
      "t1 = pd.merge(list, teachers, on='classroom')\nt2 = t1[(t1['lastname_x'] == 'gell') & (t1['firstname_x'] == 'tami')]\nanswer = t2['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nt2 = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')]\nanswer = t2['lastname_y']",
      "answer = list[(list['firstname'] == 'gell') & (list['lastname'] == 'tami')].merge(teachers,\n                                                                                  left_on='classroom',\n                                                                                  right_on='classroom').iloc[:,3]",
      "answer = (list[list['firstname'] == 'gell']\n        [list['lastname'] == 'tami']\n        [['classroom']]\n        .merge(teachers, on='classroom')\n        [['lastname']]\n        .drop_duplicates()\n)",
      "t1 = pd.merge(list, teachers, on='classroom', how='inner')\nt2 = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')]\nanswer = t2['lastname_y'].drop_duplicates()",
      "t1 = pd.merge(list, teachers, on='classroom')\nt2 = t1[(t1['firstname_x'] == 'gell') & (t1['lastname_x'] == 'tami')]\nanswer = t2['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nanswer = t1[(t1['firstname_x'] == 'gell') & (t1['lastname_x'] == 'tami')]['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nanswer = t1[(t1['firstname_x'] == 'Gell') & (t1['lastname_x'] == 'Tami')]['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nt2 = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')]\nanswer = t2['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nt2 = t1[t1['firstname'] == 'gell']\nt3 = t2[t2['lastname'] == 'tami']\nanswer = t3['lastname']",
      "t1 = pd.merge(list, teachers, left_on = 'classroom', right_on = 'classroom')\nt2 = t1[(t1['firstname_x'] == 'gell') & (t1['lastname_x'] == 'tami')]\nanswer = t2['lastname_y']",
      "answer = list.merge(teachers, left_on='classroom', right_on='classroom', how='inner')",
      "t1 = pd.merge(teachers, list, on='classroom')\nanswer = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')]['lastname_y']",
      "t1 = pd.merge(list, teachers, left_on='classroom', right_on='classroom')\nanswer = t1[(t1['firstname_x'] == 'gell') & (t1['lastname_x'] == 'tami')]['lastname_y']",
      "t1 = pd.merge(list, teachers, on='classroom')\nanswer = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')][['lastname_y']]",
      "t1 = pd.merge(teachers, list, on='classroom')\nt2 = t1[(t1['firstname_y'] == 'gell') & (t1['lastname_y'] == 'tami')]\nanswer = t2['lastname_x']",
      "t1 = pd.merge(list, teachers, left_on='classroom', right_on='classroom')\nt2 = t1[(t1['firstname_x'] == 'GELL') & (t1['lastname_x'] == 'TAMI')]\nanswer = t2['lastname_y'].unique()",
      "t1 = pd.merge(list, teachers, left_on='classroom', right_on='classroom')\nt2 = t1[(t1['lastname_x'] == 'tami') & (t1['firstname_x'] == 'gell')]\nanswer = t2['lastname_y']",
      "#t1 = list.join(teachers, on = 'classroom').where(list['firstname'] == 'gell', list['lastname'] == 'tami')\nt1 = list[(list['firstname'] == 'gell') & (list['lastname'] == 'tami')]\n#t2 = t1[['lastname', 'classroom']].drop_duplicates()\nt2 = t1.merge(teachers, on = 'classroom')[['lastname', 'classroom']].drop_duplicates()\nanswer = t2['lastname']",
      "t1 = pd.merge(list, teachers, on='classroom')\nanswer = t1[(t1['firstname_x'] == 'gell') & (t1['lastname_x'] == 'tami')]['lastname_y']"
    ],
    "acc@20": 17,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "apartment_rentals",
      "query": "SELECT guest_first_name ,  guest_last_name FROM Guests",
      "query_toks": [
        "SELECT",
        "guest_first_name",
        ",",
        "guest_last_name",
        "FROM",
        "Guests"
      ],
      "query_toks_no_value": [
        "select",
        "guest_first_name",
        ",",
        "guest_last_name",
        "from",
        "guests"
      ],
      "question": "Return the first names and last names of all guests",
      "question_toks": [
        "Return",
        "the",
        "first",
        "names",
        "and",
        "last",
        "names",
        "of",
        "all",
        "guests"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  19,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  20,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Apartment_Buildings": [
          "building_id",
          "building_short_name",
          "building_full_name",
          "building_description",
          "building_address",
          "building_manager",
          "building_phone"
        ],
        "Apartments": [
          "apt_id",
          "building_id",
          "apt_type_code",
          "apt_number",
          "bathroom_count",
          "bedroom_count",
          "room_count"
        ],
        "Apartment_Facilities": [
          "apt_id",
          "facility_code"
        ],
        "Guests": [
          "guest_id",
          "gender_code",
          "guest_first_name",
          "guest_last_name",
          "date_of_birth"
        ],
        "Apartment_Bookings": [
          "apt_booking_id",
          "apt_id",
          "guest_id",
          "booking_status_code",
          "booking_start_date",
          "booking_end_date"
        ],
        "View_Unit_Status": [
          "apt_id",
          "apt_booking_id",
          "status_date",
          "available_yn"
        ]
      },
      "answer": [
        [
          "Kip",
          "DuBuque"
        ],
        [
          "Rebeca",
          "Runolfsdottir"
        ],
        [
          "Keon",
          "Treutel"
        ],
        [
          "Gabe",
          "Bode"
        ],
        [
          "Lou",
          "Grady"
        ],
        [
          "Josefina",
          "Jerde"
        ],
        [
          "Mozell",
          "Toy"
        ],
        [
          "Keith",
          "Hoeger"
        ],
        [
          "Crystal",
          "Runolfsson"
        ],
        [
          "Nikki",
          "Lehner"
        ],
        [
          "Gregoria",
          "Schowalter"
        ],
        [
          "Louvenia",
          "Crona"
        ],
        [
          "Else",
          "Roberts"
        ],
        [
          "Juvenal",
          "Kautzer"
        ],
        [
          "Tamia",
          "Mante"
        ]
      ]
    },
    "generated_programs": [
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']].copy()",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]",
      "answer = Guests[['guest_first_name', 'guest_last_name']]"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "inn_1",
      "query": "SELECT bedType ,  avg(basePrice) FROM Rooms GROUP BY bedType;",
      "query_toks": [
        "SELECT",
        "bedType",
        ",",
        "avg",
        "(",
        "basePrice",
        ")",
        "FROM",
        "Rooms",
        "GROUP",
        "BY",
        "bedType",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "bedtype",
        ",",
        "avg",
        "(",
        "baseprice",
        ")",
        "from",
        "rooms",
        "group",
        "by",
        "bedtype"
      ],
      "question": "What is the average base price of rooms, for each bed type?",
      "question_toks": [
        "What",
        "is",
        "the",
        "average",
        "base",
        "price",
        "of",
        "rooms",
        ",",
        "for",
        "each",
        "bed",
        "type",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ],
            [
              5,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            4,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Rooms": [
          "RoomId",
          "roomName",
          "beds",
          "bedType",
          "maxOccupancy",
          "basePrice",
          "decor"
        ],
        "Reservations": [
          "Code",
          "Room",
          "CheckIn",
          "CheckOut",
          "Rate",
          "LastName",
          "FirstName",
          "Adults",
          "Kids"
        ]
      },
      "answer": [
        [
          "Double",
          100.0
        ],
        [
          "King",
          181.25
        ],
        [
          "Queen",
          150.0
        ]
      ]
    },
    "generated_programs": [
      "answer = Rooms.groupby('bedtype').agg(np.mean)['baseprice']",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype').size()\nt2 = Rooms.groupby('bedtype').agg({'baseprice': np.mean})\nanswer = pd.merge(t1.to_frame(), t2, on='bedtype').rename(columns={0: 'count'})",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().reset_index()",
      "answer = Rooms.groupby('bedtype')['baseprice'].agg(np.mean).to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').mean()\nanswer = answer[['baseprice']]",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean()",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype').agg('mean')['baseprice']\nanswer = t1.to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg_baseprice').to_frame().reset_index()\nanswer = t1",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean()",
      "answer = Rooms.groupby(['bedtype']).agg({'baseprice': 'mean'})",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean()",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nt2 = Rooms.groupby('bedtype').sum().drop('count', axis=1).rename(columns={'baseprice':'total'})\nt3 = pd.merge(t1, t2, on='bedtype')\nt3['avg'] = t3['total']/t3['count']\nanswer = t3['avg'].to_frame()",
      "t1 = Rooms.groupby('bedtype').mean()\nanswer = t1['baseprice'].to_frame()",
      "t1 = Rooms.groupby('bedtype').mean()[['baseprice']].rename(columns = {'baseprice':'avg_baseprice'}).reset_index()\nanswer = t1",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg(baseprice)').to_frame()",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean()",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean().rename('avg(baseprice)').to_frame()",
      "answer = Rooms.groupby('bedtype')['baseprice'].mean()"
    ],
    "acc@20": 6,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "sports_competition",
      "query": "SELECT name FROM club ORDER BY Start_year ASC",
      "query_toks": [
        "SELECT",
        "name",
        "FROM",
        "club",
        "ORDER",
        "BY",
        "Start_year",
        "ASC"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        "from",
        "club",
        "order",
        "by",
        "start_year",
        "asc"
      ],
      "question": "List all club names in ascending order of start year.",
      "question_toks": [
        "List",
        "all",
        "club",
        "names",
        "in",
        "ascending",
        "order",
        "of",
        "start",
        "year",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                4,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "club": [
          "Club_ID",
          "name",
          "Region",
          "Start_year"
        ],
        "club_rank": [
          "Rank",
          "Club_ID",
          "Gold",
          "Silver",
          "Bronze",
          "Total"
        ],
        "player": [
          "Player_ID",
          "name",
          "Position",
          "Club_ID",
          "Apps",
          "Tries",
          "Goals",
          "Points"
        ],
        "competition": [
          "Competition_ID",
          "Year",
          "Competition_type",
          "Country"
        ],
        "competition_result": [
          "Competition_ID",
          "Club_ID_1",
          "Club_ID_2",
          "Score"
        ]
      },
      "answer": [
        [
          "BK Slide"
        ],
        [
          "HGS2"
        ],
        [
          "ASC"
        ],
        [
          "IFG"
        ],
        [
          "AIB"
        ],
        [
          "HSBIF"
        ]
      ]
    },
    "generated_programs": [
      "answer = club[['name']].sort_values('start_year', ascending = True)",
      "answer = club['name'].sort_values(ascending=True)",
      "answer = club[['name']].sort_values('start_year', ascending=True)",
      "answer = club[['name', 'start_year']].sort_values('start_year', ascending = True)['name']",
      "answer = club[['name']].sort_values('start_year', ascending=True)",
      "answer = club.sort_values('start_year')['name']",
      "answer = club.sort_values('start_year', ascending = True)['name']",
      "answer = club[['name']].sort_values('start_year', ascending = True)",
      "answer = club.sort_values('start_year', ascending=True)[['name']]",
      "answer = club.sort_values('start_year')['name']",
      "answer = club[['name']].sort_values('start_year', ascending = True)",
      "answer = club[['name']].sort_values('start_year', ascending = True)",
      "answer = club.sort_values('start_year')['name']",
      "answer = club[['name']].sort_values('start_year')",
      "t1 = club[['name', 'start_year']]\nt2 = t1.sort_values('start_year', ascending = True)\nanswer = t2['name']",
      "answer = club[['name']].sort_values('start_year')",
      "answer = club[['name']].sort_values('start_year')",
      "answer = club.sort_values('start_year', ascending = True)[['name']]",
      "answer = club.sort_values('start_year')['name']",
      "answer = club[['name']].sort_values('start_year', ascending = True)"
    ],
    "acc@20": 9,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "book_2",
      "query": "SELECT COUNT (DISTINCT Publication_Date) FROM publication",
      "query_toks": [
        "SELECT",
        "COUNT",
        "(",
        "DISTINCT",
        "Publication_Date",
        ")",
        "FROM",
        "publication"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "distinct",
        "publication_date",
        ")",
        "from",
        "publication"
      ],
      "question": "How many distinct publication dates are there in our record?",
      "question_toks": [
        "How",
        "many",
        "distinct",
        "publication",
        "dates",
        "are",
        "there",
        "in",
        "our",
        "record",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  4,
                  true
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "publication": [
          "Publication_ID",
          "Book_ID",
          "Publisher",
          "Publication_Date",
          "Price"
        ],
        "book": [
          "Book_ID",
          "Title",
          "Issues",
          "Writer"
        ]
      },
      "answer": [
        [
          6
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "\nanswer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].unique().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().shape[0])",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "t1 = publication['publication_date'].drop_duplicates()\nanswer = t1.size",
      "answer = pd.Series(publication['publication_date'].unique().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].unique().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)",
      "answer = pd.Series(publication['publication_date'].drop_duplicates().size)"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "sports_competition",
      "query": "SELECT country FROM competition WHERE competition_type  =  'Tournament' GROUP BY country ORDER BY count(*) DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "country",
        "FROM",
        "competition",
        "WHERE",
        "competition_type",
        "=",
        "'Tournament",
        "'",
        "GROUP",
        "BY",
        "country",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "country",
        "from",
        "competition",
        "where",
        "competition_type",
        "=",
        "value",
        "group",
        "by",
        "country",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "what is the name of the country that participated in the most tournament competitions?",
      "question_toks": [
        "what",
        "is",
        "the",
        "name",
        "of",
        "the",
        "country",
        "that",
        "participated",
        "in",
        "the",
        "most",
        "tournament",
        "competitions",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  22,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                21,
                false
              ],
              null
            ],
            "\"Tournament\"",
            null
          ]
        ],
        "groupBy": [
          [
            0,
            22,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "club": [
          "Club_ID",
          "name",
          "Region",
          "Start_year"
        ],
        "club_rank": [
          "Rank",
          "Club_ID",
          "Gold",
          "Silver",
          "Bronze",
          "Total"
        ],
        "player": [
          "Player_ID",
          "name",
          "Position",
          "Club_ID",
          "Apps",
          "Tries",
          "Goals",
          "Points"
        ],
        "competition": [
          "Competition_ID",
          "Year",
          "Competition_type",
          "Country"
        ],
        "competition_result": [
          "Competition_ID",
          "Club_ID_1",
          "Club_ID_2",
          "Score"
        ]
      },
      "answer": [
        [
          "Slovenia"
        ]
      ]
    },
    "generated_programs": [
      "t1 = competition[competition['competition_type'] == 'tournament'].groupby('country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).reset_index()\nanswer = t2['country']",
      "t1 = competition[competition['competition_type'] == 'tournament'].groupby('country').size().rename('count')\nt2 = t1.sort_values(ascending = False).head(1).to_frame().reset_index()\nanswer = t2['country']",
      "t1 = competition[competition['competition_type'] == 'Tournament']\nanswer = t1['country'].value_counts().idxmax()",
      "answer = competition[competition['competition_type'] == 'tournament'].groupby('country').size().sort_values(ascending=False).head(1).index",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "answer = competition[competition['competition_type'] == 'tournament'].groupby('country').size().sort_values(ascending=False).head(1).index.values",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().to_frame().reset_index()\nt3 = t2.sort_values(by=0, ascending=False).head(1)\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nanswer = t1.groupby('country').size().rename('count').sort_values(ascending=False).head(1).to_frame().reset_index()['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending = False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country', as_index = False).size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count').sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nanswer = t2.sort_values(ascending=False).head(1).to_frame().reset_index()['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.to_frame().sort_values('count', ascending=False).head(1).reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.to_frame().reset_index()\nt4 = t3.sort_values('count', ascending=False).head(1)\nanswer = t4['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count').to_frame().reset_index()\nanswer = t2.nlargest(1, 'count')['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending = False).head(1).to_frame().reset_index()\nanswer = t3['country']",
      "t1 = competition[competition['competition_type'] == 'tournament'].groupby('country').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['country']",
      "t1 = competition[competition['competition_type'] == 'tournament']\nt2 = t1.groupby('country').size().rename('count')\nt3 = t2.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t3['country']"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "culture_company",
      "query": "SELECT publisher ,  count(*) FROM book_club GROUP BY publisher",
      "query_toks": [
        "SELECT",
        "publisher",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "book_club",
        "GROUP",
        "BY",
        "publisher"
      ],
      "query_toks_no_value": [
        "select",
        "publisher",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "book_club",
        "group",
        "by",
        "publisher"
      ],
      "question": "How many books are there for each publisher?",
      "question_toks": [
        "How",
        "many",
        "books",
        "are",
        "there",
        "for",
        "each",
        "publisher",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            5,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "book_club": [
          "book_club_id",
          "Year",
          "Author_or_Editor",
          "Book_Title",
          "Publisher",
          "Category",
          "Result"
        ],
        "movie": [
          "movie_id",
          "Title",
          "Year",
          "Director",
          "Budget_million",
          "Gross_worldwide"
        ],
        "culture_company": [
          "Company_name",
          "Type",
          "Incorporated_in",
          "Group_Equity_Shareholding",
          "book_club_id",
          "movie_id"
        ]
      },
      "answer": [
        [
          "Alyson",
          3
        ],
        [
          "Banned Books",
          2
        ],
        [
          "Crossing Press",
          1
        ],
        [
          "International Polygonics",
          1
        ],
        [
          "Mysterious Press",
          1
        ],
        [
          "Naiad Press",
          2
        ],
        [
          "St. Martin's Press",
          1
        ],
        [
          "William Morrow",
          1
        ]
      ]
    },
    "generated_programs": [
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count').reset_index()\nanswer = t1[['publisher', 'count']]",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = pd.DataFrame(t1)",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame().reset_index()",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame()",
      "t1 = book_club\nt2 = t1.groupby('publisher').size().rename('count')\nanswer = t2.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count').to_frame().reset_index()\nanswer = t1",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = book_club.groupby('publisher').size().rename('count').reset_index()\nanswer = t1",
      "t1 = book_club.groupby('publisher')['book_title'].size().rename('count')\nanswer = t1",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame()",
      "answer = book_club.groupby('publisher').size().rename('count').to_frame().reset_index()"
    ],
    "acc@20": 15,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT T2.name FROM genres AS T1 JOIN tracks AS T2 ON T1.id = T2.genre_id JOIN media_types AS T3 ON T3.id = T2.media_type_id WHERE T1.name = \"Rock\" AND T3.name = \"MPEG audio file\";",
      "query_toks": [
        "SELECT",
        "T2.name",
        "FROM",
        "genres",
        "AS",
        "T1",
        "JOIN",
        "tracks",
        "AS",
        "T2",
        "ON",
        "T1.id",
        "=",
        "T2.genre_id",
        "JOIN",
        "media_types",
        "AS",
        "T3",
        "ON",
        "T3.id",
        "=",
        "T2.media_type_id",
        "WHERE",
        "T1.name",
        "=",
        "``",
        "Rock",
        "''",
        "AND",
        "T3.name",
        "=",
        "``",
        "MPEG",
        "audio",
        "file",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "t2",
        ".",
        "name",
        "from",
        "genres",
        "as",
        "t1",
        "join",
        "tracks",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "genre_id",
        "join",
        "media_types",
        "as",
        "t3",
        "on",
        "t3",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "media_type_id",
        "where",
        "t1",
        ".",
        "name",
        "=",
        "value",
        "and",
        "t3",
        ".",
        "name",
        "=",
        "value"
      ],
      "question": "List the name of tracks belongs to genre Rock and whose media type is MPEG audio file.",
      "question_toks": [
        "List",
        "the",
        "name",
        "of",
        "tracks",
        "belongs",
        "to",
        "genre",
        "Rock",
        "and",
        "whose",
        "media",
        "type",
        "is",
        "MPEG",
        "audio",
        "file",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ],
            [
              "table_unit",
              8
            ],
            [
              "table_unit",
              7
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  36,
                  false
                ],
                null
              ],
              [
                0,
                53,
                false
              ],
              null
            ],
            "and",
            [
              false,
              2,
              [
                0,
                [
                  0,
                  47,
                  false
                ],
                null
              ],
              [
                0,
                52,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  50,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                37,
                false
              ],
              null
            ],
            "\"Rock\"",
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                48,
                false
              ],
              null
            ],
            "\"MPEG audio file\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "For Those About To Rock (We Salute You)"
        ],
        [
          "Put The Finger On You"
        ],
        [
          "Let's Get It Up"
        ],
        [
          "Inject The Venom"
        ],
        [
          "Snowballed"
        ],
        [
          "Evil Walks"
        ],
        [
          "C.O.D."
        ],
        [
          "Breaking The Rules"
        ],
        [
          "Night Of The Long Knives"
        ],
        [
          "Spellbound"
        ],
        [
          "Go Down"
        ],
        [
          "Dog Eat Dog"
        ],
        [
          "Let There Be Rock"
        ],
        [
          "Bad Boy Boogie"
        ],
        [
          "Problem Child"
        ],
        [
          "Overdose"
        ],
        [
          "Hell Ain't A Bad Place To Be"
        ],
        [
          "Whole Lotta Rosie"
        ],
        [
          "Walk On Water"
        ],
        [
          "Love In An Elevator"
        ],
        [
          "Rag Doll"
        ],
        [
          "What It Takes"
        ],
        [
          "Dude (Looks Like A Lady)"
        ],
        [
          "Janie's Got A Gun"
        ],
        [
          "Cryin'"
        ],
        [
          "Amazing"
        ],
        [
          "Blind Man"
        ],
        [
          "Deuces Are Wild"
        ],
        [
          "The Other Side"
        ],
        [
          "Crazy"
        ],
        [
          "Eat The Rich"
        ],
        [
          "Angel"
        ],
        [
          "Livin' On The Edge"
        ],
        [
          "All I Really Want"
        ],
        [
          "You Oughta Know"
        ],
        [
          "Perfect"
        ],
        [
          "Hand In My Pocket"
        ],
        [
          "Right Through You"
        ],
        [
          "Forgiven"
        ],
        [
          "You Learn"
        ],
        [
          "Head Over Feet"
        ],
        [
          "Mary Jane"
        ],
        [
          "Ironic"
        ],
        [
          "Not The Doctor"
        ],
        [
          "Wake Up"
        ],
        [
          "You Oughta Know (Alternate)"
        ],
        [
          "We Die Young"
        ],
        [
          "Man In The Box"
        ],
        [
          "Sea Of Sorrow"
        ],
        [
          "Bleed The Freak"
        ],
        [
          "I Can't Remember"
        ],
        [
          "Love, Hate, Love"
        ],
        [
          "It Ain't Like That"
        ],
        [
          "Sunshine"
        ],
        [
          "Put You Down"
        ],
        [
          "Confusion"
        ],
        [
          "I Know Somethin (Bout You)"
        ],
        [
          "Real Thing"
        ],
        [
          "Cochise"
        ],
        [
          "Show Me How to Live"
        ],
        [
          "Gasoline"
        ],
        [
          "What You Are"
        ],
        [
          "Like a Stone"
        ],
        [
          "Set It Off"
        ],
        [
          "Shadow on the Sun"
        ],
        [
          "I am the Highway"
        ],
        [
          "Exploder"
        ],
        [
          "Hypnotize"
        ],
        [
          "Bring'em Back Alive"
        ],
        [
          "Light My Way"
        ],
        [
          "Getaway Car"
        ],
        [
          "The Last Remaining Light"
        ],
        [
          "You Shook Me"
        ],
        [
          "I Can't Quit You Baby"
        ],
        [
          "Communication Breakdown"
        ],
        [
          "Dazed and Confused"
        ],
        [
          "The Girl I Love She Got Long Black Wavy Hair"
        ],
        [
          "What is and Should Never Be"
        ],
        [
          "Communication Breakdown(2)"
        ],
        [
          "Travelling Riverside Blues"
        ],
        [
          "Whole Lotta Love"
        ],
        [
          "Somethin' Else"
        ],
        [
          "Communication Breakdown(3)"
        ],
        [
          "I Can't Quit You Baby(2)"
        ],
        [
          "You Shook Me(2)"
        ],
        [
          "How Many More Times"
        ],
        [
          "Debra Kadabra"
        ],
        [
          "Carolina Hard-Core Ecstasy"
        ],
        [
          "Sam With The Showing Scalp Flat Top"
        ],
        [
          "Poofter's Froth Wyoming Plans Ahead"
        ],
        [
          "200 Years Old"
        ],
        [
          "Cucamonga"
        ],
        [
          "Advance Romance"
        ],
        [
          "Man With The Woman Head"
        ],
        [
          "Muffin Man"
        ],
        [
          "A Kind Of Magic"
        ],
        [
          "Under Pressure"
        ],
        [
          "Radio GA GA"
        ],
        [
          "I Want It All"
        ],
        [
          "I Want To Break Free"
        ],
        [
          "Innuendo"
        ],
        [
          "It's A Hard Life"
        ],
        [
          "Breakthru"
        ],
        [
          "Who Wants To Live Forever"
        ],
        [
          "Headlong"
        ],
        [
          "The Miracle"
        ],
        [
          "I'm Going Slightly Mad"
        ],
        [
          "The Invisible Man"
        ],
        [
          "Hammer To Fall"
        ],
        [
          "Friends Will Be Friends"
        ],
        [
          "The Show Must Go On"
        ],
        [
          "One Vision"
        ],
        [
          "Detroit Rock City"
        ],
        [
          "Black Diamond"
        ],
        [
          "Hard Luck Woman"
        ],
        [
          "Sure Know Something"
        ],
        [
          "Love Gun"
        ],
        [
          "Deuce"
        ],
        [
          "Goin' Blind"
        ],
        [
          "Shock Me"
        ],
        [
          "Do You Love Me"
        ],
        [
          "She"
        ],
        [
          "I Was Made For Loving You"
        ],
        [
          "Shout It Out Loud"
        ],
        [
          "God Of Thunder"
        ],
        [
          "Calling Dr. Love"
        ],
        [
          "Beth"
        ],
        [
          "Strutter"
        ],
        [
          "Rock And Roll All Nite"
        ],
        [
          "Cold Gin"
        ],
        [
          "Plaster Caster"
        ],
        [
          "God Gave Rock 'n' Roll To You"
        ],
        [
          "Into The Light"
        ],
        [
          "River Song"
        ],
        [
          "She Give Me ..."
        ],
        [
          "Don't You Cry"
        ],
        [
          "Love Is Blind"
        ],
        [
          "Slave"
        ],
        [
          "Cry For Love"
        ],
        [
          "Living On Love"
        ],
        [
          "Midnight Blue"
        ],
        [
          "Too Many Tears"
        ],
        [
          "Don't Lie To Me"
        ],
        [
          "Wherever You May Go"
        ],
        [
          "Burn"
        ],
        [
          "Stormbringer"
        ],
        [
          "Gypsy"
        ],
        [
          "Lady Double Dealer"
        ],
        [
          "Mistreated"
        ],
        [
          "Smoke On The Water"
        ],
        [
          "You Fool No One"
        ],
        [
          "Custard Pie"
        ],
        [
          "The Rover"
        ],
        [
          "In My Time Of Dying"
        ],
        [
          "Houses Of The Holy"
        ],
        [
          "Trampled Under Foot"
        ],
        [
          "Kashmir"
        ],
        [
          "(Da Le) Yaleo"
        ],
        [
          "Love Of My Life"
        ],
        [
          "Put Your Lights On"
        ],
        [
          "Africa Bamba"
        ],
        [
          "Smooth"
        ],
        [
          "Do You Like The Way"
        ],
        [
          "Maria Maria"
        ],
        [
          "Migra"
        ],
        [
          "Corazon Espinado"
        ],
        [
          "Wishing It Was"
        ],
        [
          "El Farol"
        ],
        [
          "Primavera"
        ],
        [
          "The Calling"
        ],
        [
          "Space Truckin'"
        ],
        [
          "Going Down / Highway Star"
        ],
        [
          "Mistreated (Alternate Version)"
        ],
        [
          "You Fool No One (Alternate Version)"
        ],
        [
          "Susie Q"
        ],
        [
          "I Put A Spell On You"
        ],
        [
          "Proud Mary"
        ],
        [
          "Bad Moon Rising"
        ],
        [
          "Lodi"
        ],
        [
          "Green River"
        ],
        [
          "Commotion"
        ],
        [
          "Down On The Corner"
        ],
        [
          "Fortunate Son"
        ],
        [
          "Travelin' Band"
        ],
        [
          "Who'll Stop The Rain"
        ],
        [
          "Up Around The Bend"
        ],
        [
          "Run Through The Jungle"
        ],
        [
          "Lookin' Out My Back Door"
        ],
        [
          "Long As I Can See The Light"
        ],
        [
          "I Heard It Through The Grapevine"
        ],
        [
          "Have You Ever Seen The Rain?"
        ],
        [
          "Hey Tonight"
        ],
        [
          "Sweet Hitch-Hiker"
        ],
        [
          "Someday Never Comes"
        ],
        [
          "Walking On The Water"
        ],
        [
          "Suzie-Q, Pt. 2"
        ],
        [
          "Born On The Bayou"
        ],
        [
          "Good Golly Miss Molly"
        ],
        [
          "Tombstone Shadow"
        ],
        [
          "Wrote A Song For Everyone"
        ],
        [
          "Night Time Is The Right Time"
        ],
        [
          "Cotton Fields"
        ],
        [
          "It Came Out Of The Sky"
        ],
        [
          "Don't Look Now"
        ],
        [
          "The Midnight Special"
        ],
        [
          "Before You Accuse Me"
        ],
        [
          "My Baby Left Me"
        ],
        [
          "Pagan Baby"
        ],
        [
          "(Wish I Could) Hideaway"
        ],
        [
          "It's Just A Thought"
        ],
        [
          "Molina"
        ],
        [
          "Born To Move"
        ],
        [
          "Lookin' For A Reason"
        ],
        [
          "Hello Mary Lou"
        ],
        [
          "Comin' Home"
        ],
        [
          "Lady Luck"
        ],
        [
          "Gettin' Tighter"
        ],
        [
          "Dealer"
        ],
        [
          "I Need Love"
        ],
        [
          "Drifter"
        ],
        [
          "Love Child"
        ],
        [
          "This Time Around / Owed to 'G' instrumental"
        ],
        [
          "You Keep On Moving"
        ],
        [
          "Speed King"
        ],
        [
          "Bloodsucker"
        ],
        [
          "Child In Time"
        ],
        [
          "Flight Of The Rat"
        ],
        [
          "Into The Fire"
        ],
        [
          "Living Wreck"
        ],
        [
          "Hard Lovin' Man"
        ],
        [
          "Fireball"
        ],
        [
          "No No No"
        ],
        [
          "Strange Kind Of Woman"
        ],
        [
          "Anyone's Daughter"
        ],
        [
          "The Mule"
        ],
        [
          "Fools"
        ],
        [
          "No One Came"
        ],
        [
          "Knocking At Your Back Door"
        ],
        [
          "Bad Attitude"
        ],
        [
          "Child In Time (Son Of Aleric - Instrumental)"
        ],
        [
          "Nobody's Home"
        ],
        [
          "Black Night"
        ],
        [
          "Perfect Strangers"
        ],
        [
          "The Unwritten Law"
        ],
        [
          "Call Of The Wild"
        ],
        [
          "Hush"
        ],
        [
          "Smoke On The Water"
        ],
        [
          "Space Trucking"
        ],
        [
          "Highway Star"
        ],
        [
          "Maybe I'm A Leo"
        ],
        [
          "Pictures Of Home"
        ],
        [
          "Never Before"
        ],
        [
          "Smoke On The Water"
        ],
        [
          "Lazy"
        ],
        [
          "Space Truckin'"
        ],
        [
          "Vavoom : Ted The Mechanic"
        ],
        [
          "Loosen My Strings"
        ],
        [
          "Soon Forgotten"
        ],
        [
          "Sometimes I Feel Like Screaming"
        ],
        [
          "Cascades : I'm Not Your Lover"
        ],
        [
          "The Aviator"
        ],
        [
          "Rosa's Cantina"
        ],
        [
          "A Castle Full Of Rascals"
        ],
        [
          "A Touch Away"
        ],
        [
          "Hey Cisco"
        ],
        [
          "Somebody Stole My Guitar"
        ],
        [
          "The Purpendicular Waltz"
        ],
        [
          "King Of Dreams"
        ],
        [
          "The Cut Runs Deep"
        ],
        [
          "Fire In The Basement"
        ],
        [
          "Truth Hurts"
        ],
        [
          "Breakfast In Bed"
        ],
        [
          "Love Conquers All"
        ],
        [
          "Fortuneteller"
        ],
        [
          "Too Much Is Not Enough"
        ],
        [
          "Wicked Ways"
        ],
        [
          "Stormbringer"
        ],
        [
          "Love Don't Mean a Thing"
        ],
        [
          "Holy Man"
        ],
        [
          "Hold On"
        ],
        [
          "Lady Double Dealer"
        ],
        [
          "You Can't Do it Right (With the One You Love)"
        ],
        [
          "High Ball Shooter"
        ],
        [
          "The Gypsy"
        ],
        [
          "Soldier Of Fortune"
        ],
        [
          "The Battle Rages On"
        ],
        [
          "Lick It Up"
        ],
        [
          "Anya"
        ],
        [
          "Talk About Love"
        ],
        [
          "Time To Kill"
        ],
        [
          "Ramshackle Man"
        ],
        [
          "A Twist In The Tail"
        ],
        [
          "Nasty Piece Of Work"
        ],
        [
          "Solitaire"
        ],
        [
          "One Man's Meat"
        ],
        [
          "Pour Some Sugar On Me"
        ],
        [
          "Photograph"
        ],
        [
          "Love Bites"
        ],
        [
          "Let's Get Rocked"
        ],
        [
          "Two Steps Behind [Acoustic Version]"
        ],
        [
          "Animal"
        ],
        [
          "Heaven Is"
        ],
        [
          "Rocket"
        ],
        [
          "When Love & Hate Collide"
        ],
        [
          "Action"
        ],
        [
          "Make Love Like A Man"
        ],
        [
          "Armageddon It"
        ],
        [
          "Have You Ever Needed Someone So Bad"
        ],
        [
          "Rock Of Ages"
        ],
        [
          "Hysteria"
        ],
        [
          "Bringin' On The Heartbreak"
        ],
        [
          "Get Out"
        ],
        [
          "Ricochet"
        ],
        [
          "Evidence"
        ],
        [
          "The Gentle Art Of Making Enemies"
        ],
        [
          "Star A.D."
        ],
        [
          "Cuckoo For Caca"
        ],
        [
          "Caralho Voador"
        ],
        [
          "Ugly In The Morning"
        ],
        [
          "Digging The Grave"
        ],
        [
          "Take This Bottle"
        ],
        [
          "King For A Day"
        ],
        [
          "What A Day"
        ],
        [
          "The Last To Know"
        ],
        [
          "Just A Man"
        ],
        [
          "Absolute Zero"
        ],
        [
          "In Your Honor"
        ],
        [
          "No Way Back"
        ],
        [
          "Best Of You"
        ],
        [
          "DOA"
        ],
        [
          "Hell"
        ],
        [
          "The Last Song"
        ],
        [
          "Free Me"
        ],
        [
          "Resolve"
        ],
        [
          "The Deepest Blues Are Black"
        ],
        [
          "End Over End"
        ],
        [
          "Still"
        ],
        [
          "What If I Do?"
        ],
        [
          "Miracle"
        ],
        [
          "Another Round"
        ],
        [
          "Friend Of A Friend"
        ],
        [
          "Over And Out"
        ],
        [
          "On The Mend"
        ],
        [
          "Virginia Moon"
        ],
        [
          "Cold Day In The Sun"
        ],
        [
          "Razor"
        ],
        [
          "Doll"
        ],
        [
          "Monkey Wrench"
        ],
        [
          "Hey, Johnny Park!"
        ],
        [
          "My Poor Brain"
        ],
        [
          "Wind Up"
        ],
        [
          "Up In Arms"
        ],
        [
          "My Hero"
        ],
        [
          "See You"
        ],
        [
          "Enough Space"
        ],
        [
          "February Stars"
        ],
        [
          "Everlong"
        ],
        [
          "Walking After You"
        ],
        [
          "New Way Home"
        ],
        [
          "The Wicker Man"
        ],
        [
          "Ghost Of The Navigator"
        ],
        [
          "Brave New World"
        ],
        [
          "Blood Brothers"
        ],
        [
          "The Mercenary"
        ],
        [
          "Dream Of Mirrors"
        ],
        [
          "The Fallen Angel"
        ],
        [
          "The Nomad"
        ],
        [
          "Out Of The Silent Planet"
        ],
        [
          "The Thin Line Between Love & Hate"
        ],
        [
          "Be Quick Or Be Dead"
        ],
        [
          "From Here To Eternity"
        ],
        [
          "Afraid To Shoot Strangers"
        ],
        [
          "Fear Is The Key"
        ],
        [
          "Childhood's End"
        ],
        [
          "Wasting Love"
        ],
        [
          "The Fugitive"
        ],
        [
          "Chains Of Misery"
        ],
        [
          "The Apparition"
        ],
        [
          "Judas Be My Guide"
        ],
        [
          "Weekend Warrior"
        ],
        [
          "Fear Of The Dark"
        ],
        [
          "Be Quick Or Be Dead"
        ],
        [
          "The Number Of The Beast"
        ],
        [
          "Wrathchild"
        ],
        [
          "From Here To Eternity"
        ],
        [
          "Can I Play With Madness"
        ],
        [
          "Wasting Love"
        ],
        [
          "Tailgunner"
        ],
        [
          "The Evil That Men Do"
        ],
        [
          "Afraid To Shoot Strangers"
        ],
        [
          "Fear Of The Dark"
        ],
        [
          "Bring Your Daughter... To The Slaughter..."
        ],
        [
          "The Clairvoyant"
        ],
        [
          "Heaven Can Wait"
        ],
        [
          "Run To The Hills"
        ],
        [
          "2 Minutes To Midnight"
        ],
        [
          "Iron Maiden"
        ],
        [
          "Hallowed Be Thy Name"
        ],
        [
          "The Trooper"
        ],
        [
          "Sanctuary"
        ],
        [
          "Running Free"
        ],
        [
          "Dream Of Mirrors"
        ],
        [
          "The Clansman"
        ],
        [
          "Fear Of The Dark"
        ],
        [
          "Iron Maiden"
        ],
        [
          "The Number Of The Beast"
        ],
        [
          "Hallowed Be Thy Name"
        ],
        [
          "Sanctuary"
        ],
        [
          "Run To The Hills"
        ],
        [
          "The Number Of The Beast"
        ],
        [
          "Sign Of The Cross"
        ],
        [
          "Lord Of The Flies"
        ],
        [
          "Man On The Edge"
        ],
        [
          "Fortunes Of War"
        ],
        [
          "Look For The Truth"
        ],
        [
          "The Aftermath"
        ],
        [
          "Judgement Of Heaven"
        ],
        [
          "Blood On The World's Hands"
        ],
        [
          "The Edge Of Darkness"
        ],
        [
          "2 A.M."
        ],
        [
          "The Unbeliever"
        ],
        [
          "Futureal"
        ],
        [
          "The Angel And The Gambler"
        ],
        [
          "Lightning Strikes Twice"
        ],
        [
          "The Clansman"
        ],
        [
          "When Two Worlds Collide"
        ],
        [
          "The Educated Fool"
        ],
        [
          "Don't Look To The Eyes Of A Stranger"
        ],
        [
          "Como Estais Amigos"
        ],
        [
          "When You Gonna Learn (Digeridoo)"
        ],
        [
          "Too Young To Die"
        ],
        [
          "Hooked Up"
        ],
        [
          "If I Like It, I Do It"
        ],
        [
          "Music Of The Wind"
        ],
        [
          "Emergency On Planet Earth"
        ],
        [
          "Whatever It Is, I Just Can't Stop"
        ],
        [
          "Blow Your Mind"
        ],
        [
          "Revolution 1993"
        ],
        [
          "Didgin' Out"
        ],
        [
          "Foxy Lady"
        ],
        [
          "Manic Depression"
        ],
        [
          "Red House"
        ],
        [
          "Can You See Me"
        ],
        [
          "Love Or Confusion"
        ],
        [
          "I Don't Live Today"
        ],
        [
          "May This Be Love"
        ],
        [
          "Fire"
        ],
        [
          "Third Stone From The Sun"
        ],
        [
          "Remember"
        ],
        [
          "Are You Experienced?"
        ],
        [
          "Hey Joe"
        ],
        [
          "Stone Free"
        ],
        [
          "Purple Haze"
        ],
        [
          "51st Anniversary"
        ],
        [
          "The Wind Cries Mary"
        ],
        [
          "Highway Chile"
        ],
        [
          "Comin' Home"
        ],
        [
          "Plaster Caster"
        ],
        [
          "Goin' Blind"
        ],
        [
          "Do You Love Me"
        ],
        [
          "Domino"
        ],
        [
          "Sure Know Something"
        ],
        [
          "A World Without Heroes"
        ],
        [
          "Rock Bottom"
        ],
        [
          "See You Tonight"
        ],
        [
          "I Still Love You"
        ],
        [
          "Every Time I Look At You"
        ],
        [
          "2,000 Man"
        ],
        [
          "Beth"
        ],
        [
          "Nothin' To Lose"
        ],
        [
          "Rock And Roll All Nite"
        ],
        [
          "Immigrant Song"
        ],
        [
          "Heartbreaker"
        ],
        [
          "Since I've Been Loving You"
        ],
        [
          "Black Dog"
        ],
        [
          "Dazed And Confused"
        ],
        [
          "Stairway To Heaven"
        ],
        [
          "Going To California"
        ],
        [
          "That's The Way"
        ],
        [
          "Whole Lotta Love (Medley)"
        ],
        [
          "Thank You"
        ],
        [
          "We're Gonna Groove"
        ],
        [
          "Poor Tom"
        ],
        [
          "I Can't Quit You Baby"
        ],
        [
          "Walter's Walk"
        ],
        [
          "Ozone Baby"
        ],
        [
          "Darlene"
        ],
        [
          "Bonzo's Montreux"
        ],
        [
          "Wearing And Tearing"
        ],
        [
          "The Song Remains The Same"
        ],
        [
          "The Rain Song"
        ],
        [
          "Over The Hills And Far Away"
        ],
        [
          "The Crunge"
        ],
        [
          "Dancing Days"
        ],
        [
          "D'Yer Mak'er"
        ],
        [
          "No Quarter"
        ],
        [
          "The Ocean"
        ],
        [
          "In The Evening"
        ],
        [
          "South Bound Saurez"
        ],
        [
          "Fool In The Rain"
        ],
        [
          "Hot Dog"
        ],
        [
          "Carouselambra"
        ],
        [
          "All My Love"
        ],
        [
          "I'm Gonna Crawl"
        ],
        [
          "Black Dog"
        ],
        [
          "Rock & Roll"
        ],
        [
          "The Battle Of Evermore"
        ],
        [
          "Stairway To Heaven"
        ],
        [
          "Misty Mountain Hop"
        ],
        [
          "Four Sticks"
        ],
        [
          "Going To California"
        ],
        [
          "When The Levee Breaks"
        ],
        [
          "Good Times Bad Times"
        ],
        [
          "Babe I'm Gonna Leave You"
        ],
        [
          "You Shook Me"
        ],
        [
          "Dazed and Confused"
        ],
        [
          "Your Time Is Gonna Come"
        ],
        [
          "Black Mountain Side"
        ],
        [
          "Communication Breakdown"
        ],
        [
          "I Can't Quit You Baby"
        ],
        [
          "How Many More Times"
        ],
        [
          "Whole Lotta Love"
        ],
        [
          "What Is And What Should Never Be"
        ],
        [
          "The Lemon Song"
        ],
        [
          "Thank You"
        ],
        [
          "Heartbreaker"
        ],
        [
          "Living Loving Maid (She's Just A Woman)"
        ],
        [
          "Ramble On"
        ],
        [
          "Moby Dick"
        ],
        [
          "Bring It On Home"
        ],
        [
          "Immigrant Song"
        ],
        [
          "Friends"
        ],
        [
          "Celebration Day"
        ],
        [
          "Since I've Been Loving You"
        ],
        [
          "Out On The Tiles"
        ],
        [
          "Gallows Pole"
        ],
        [
          "Tangerine"
        ],
        [
          "That's The Way"
        ],
        [
          "Bron-Y-Aur Stomp"
        ],
        [
          "Hats Off To (Roy) Harper"
        ],
        [
          "In The Light"
        ],
        [
          "Bron-Yr-Aur"
        ],
        [
          "Down By The Seaside"
        ],
        [
          "Ten Years Gone"
        ],
        [
          "Night Flight"
        ],
        [
          "The Wanton Song"
        ],
        [
          "Boogie With Stu"
        ],
        [
          "Black Country Woman"
        ],
        [
          "Sick Again"
        ],
        [
          "Achilles Last Stand"
        ],
        [
          "For Your Life"
        ],
        [
          "Royal Orleans"
        ],
        [
          "Nobody's Fault But Mine"
        ],
        [
          "Candy Store Rock"
        ],
        [
          "Hots On For Nowhere"
        ],
        [
          "Tea For One"
        ],
        [
          "Rock & Roll"
        ],
        [
          "Celebration Day"
        ],
        [
          "The Song Remains The Same"
        ],
        [
          "Rain Song"
        ],
        [
          "Dazed And Confused"
        ],
        [
          "No Quarter"
        ],
        [
          "Stairway To Heaven"
        ],
        [
          "Moby Dick"
        ],
        [
          "Whole Lotta Love"
        ],
        [
          "Are You Gonna Go My Way"
        ],
        [
          "Fly Away"
        ],
        [
          "Rock And Roll Is Dead"
        ],
        [
          "Again"
        ],
        [
          "It Ain't Over 'Til It's Over"
        ],
        [
          "Can't Get You Off My Mind"
        ],
        [
          "Mr. Cab Driver"
        ],
        [
          "American Woman"
        ],
        [
          "Stand By My Woman"
        ],
        [
          "Always On The Run"
        ],
        [
          "Heaven Help"
        ],
        [
          "I Belong To You"
        ],
        [
          "Believe"
        ],
        [
          "Let Love Rule"
        ],
        [
          "Black Velveteen"
        ],
        [
          "Pseudo Silk Kimono"
        ],
        [
          "Kayleigh"
        ],
        [
          "Lavender"
        ],
        [
          "Bitter Suite: Brief Encounter / Lost Weekend / Blue Angel"
        ],
        [
          "Heart Of Lothian: Wide Boy / Curtain Call"
        ],
        [
          "Waterhole (Expresso Bongo)"
        ],
        [
          "Lords Of The Backstage"
        ],
        [
          "Blind Curve: Vocal Under A Bloodlight / Passing Strangers / Mylo / Perimeter Walk / Threshold"
        ],
        [
          "Childhoods End?"
        ],
        [
          "White Feather"
        ],
        [
          "Down Under"
        ],
        [
          "Overkill"
        ],
        [
          "Be Good Johnny"
        ],
        [
          "Everything I Need"
        ],
        [
          "Down by the Sea"
        ],
        [
          "Who Can It Be Now?"
        ],
        [
          "It's a Mistake"
        ],
        [
          "Dr. Heckyll & Mr. Jive"
        ],
        [
          "Shakes and Ladders"
        ],
        [
          "No Sign of Yesterday"
        ],
        [
          "Intro"
        ],
        [
          "School"
        ],
        [
          "Drain You"
        ],
        [
          "Aneurysm"
        ],
        [
          "Smells Like Teen Spirit"
        ],
        [
          "Been A Son"
        ],
        [
          "Lithium"
        ],
        [
          "Sliver"
        ],
        [
          "Spank Thru"
        ],
        [
          "Scentless Apprentice"
        ],
        [
          "Heart-Shaped Box"
        ],
        [
          "Milk It"
        ],
        [
          "Negative Creep"
        ],
        [
          "Polly"
        ],
        [
          "Breed"
        ],
        [
          "Tourette's"
        ],
        [
          "Blew"
        ],
        [
          "Smells Like Teen Spirit"
        ],
        [
          "In Bloom"
        ],
        [
          "Come As You Are"
        ],
        [
          "Breed"
        ],
        [
          "Lithium"
        ],
        [
          "Polly"
        ],
        [
          "Territorial Pissings"
        ],
        [
          "Drain You"
        ],
        [
          "Lounge Act"
        ],
        [
          "Stay Away"
        ],
        [
          "On A Plain"
        ],
        [
          "Something In The Way"
        ],
        [
          "Time"
        ],
        [
          "P.S.Apare\u00e7a"
        ],
        [
          "Sangue Latino"
        ],
        [
          "Folhas Secas"
        ],
        [
          "Poeira"
        ],
        [
          "M\u00e1gica"
        ],
        [
          "Quem Mata A Mulher Mata O Melhor"
        ],
        [
          "Mundar\u00e9u"
        ],
        [
          "O Bra\u00e7o Da Minha Guitarra"
        ],
        [
          "Deus"
        ],
        [
          "M\u00e3e Terra"
        ],
        [
          "\u00c0s Vezes"
        ],
        [
          "Menino De Rua"
        ],
        [
          "Prazer E F\u00e9"
        ],
        [
          "Elza"
        ],
        [
          "Shining In The Light"
        ],
        [
          "When The World Was Young"
        ],
        [
          "Upon A Golden Horse"
        ],
        [
          "Blue Train"
        ],
        [
          "Please Read The Letter"
        ],
        [
          "Most High"
        ],
        [
          "Heart In Your Hand"
        ],
        [
          "Walking Into Clarksdale"
        ],
        [
          "Burning Up"
        ],
        [
          "When I Was A Child"
        ],
        [
          "House Of Love"
        ],
        [
          "Sons Of Freedom"
        ],
        [
          "Wrathchild"
        ],
        [
          "Killers"
        ],
        [
          "Prowler"
        ],
        [
          "Murders In The Rue Morgue"
        ],
        [
          "Women In Uniform"
        ],
        [
          "Remember Tomorrow"
        ],
        [
          "Sanctuary"
        ],
        [
          "Running Free"
        ],
        [
          "Phantom Of The Opera"
        ],
        [
          "Iron Maiden"
        ],
        [
          "Corduroy"
        ],
        [
          "Given To Fly"
        ],
        [
          "Hail, Hail"
        ],
        [
          "Daughter"
        ],
        [
          "Elderly Woman Behind The Counter In A Small Town"
        ],
        [
          "Untitled"
        ],
        [
          "MFC"
        ],
        [
          "Go"
        ],
        [
          "Red Mosquito"
        ],
        [
          "Even Flow"
        ],
        [
          "Off He Goes"
        ],
        [
          "Nothingman"
        ],
        [
          "Do The Evolution"
        ],
        [
          "Better Man"
        ],
        [
          "Black"
        ],
        [
          "F*Ckin' Up"
        ],
        [
          "Can't Keep"
        ],
        [
          "Save You"
        ],
        [
          "Love Boat Captain"
        ],
        [
          "Cropduster"
        ],
        [
          "Ghost"
        ],
        [
          "I Am Mine"
        ],
        [
          "Thumbing My Way"
        ],
        [
          "You Are"
        ],
        [
          "Get Right"
        ],
        [
          "Green Disease"
        ],
        [
          "Help Help"
        ],
        [
          "Bushleager"
        ],
        [
          "1/2 Full"
        ],
        [
          "Arc"
        ],
        [
          "All or None"
        ],
        [
          "Once"
        ],
        [
          "Evenflow"
        ],
        [
          "Alive"
        ],
        [
          "Why Go"
        ],
        [
          "Black"
        ],
        [
          "Jeremy"
        ],
        [
          "Oceans"
        ],
        [
          "Porch"
        ],
        [
          "Garden"
        ],
        [
          "Deep"
        ],
        [
          "Release"
        ],
        [
          "Go"
        ],
        [
          "Animal"
        ],
        [
          "Daughter"
        ],
        [
          "Glorified G"
        ],
        [
          "Dissident"
        ],
        [
          "W.M.A."
        ],
        [
          "Blood"
        ],
        [
          "Rearviewmirror"
        ],
        [
          "Rats"
        ],
        [
          "Elderly Woman Behind The Counter In A Small Town"
        ],
        [
          "Leash"
        ],
        [
          "Indifference"
        ],
        [
          "Speak To Me/Breathe"
        ],
        [
          "On The Run"
        ],
        [
          "Time"
        ],
        [
          "The Great Gig In The Sky"
        ],
        [
          "Money"
        ],
        [
          "Us And Them"
        ],
        [
          "Any Colour You Like"
        ],
        [
          "Brain Damage"
        ],
        [
          "Eclipse"
        ],
        [
          "Bohemian Rhapsody"
        ],
        [
          "Another One Bites The Dust"
        ],
        [
          "Killer Queen"
        ],
        [
          "Fat Bottomed Girls"
        ],
        [
          "Bicycle Race"
        ],
        [
          "You're My Best Friend"
        ],
        [
          "Don't Stop Me Now"
        ],
        [
          "Save Me"
        ],
        [
          "Crazy Little Thing Called Love"
        ],
        [
          "Somebody To Love"
        ],
        [
          "Now I'm Here"
        ],
        [
          "Good Old-Fashioned Lover Boy"
        ],
        [
          "Play The Game"
        ],
        [
          "Flash"
        ],
        [
          "Seven Seas Of Rhye"
        ],
        [
          "We Will Rock You"
        ],
        [
          "We Are The Champions"
        ],
        [
          "We Will Rock You"
        ],
        [
          "We Are The Champions"
        ],
        [
          "Sheer Heart Attack"
        ],
        [
          "All Dead, All Dead"
        ],
        [
          "Spread Your Wings"
        ],
        [
          "Fight From The Inside"
        ],
        [
          "Get Down, Make Love"
        ],
        [
          "Sleep On The Sidewalk"
        ],
        [
          "Who Needs You"
        ],
        [
          "It's Late"
        ],
        [
          "My Melancholy Blues"
        ],
        [
          "How The West Was Won And Where It Got Us"
        ],
        [
          "The Wake-Up Bomb"
        ],
        [
          "New Test Leper"
        ],
        [
          "Undertow"
        ],
        [
          "E-Bow The Letter"
        ],
        [
          "Leave"
        ],
        [
          "Departure"
        ],
        [
          "Bittersweet Me"
        ],
        [
          "Be Mine"
        ],
        [
          "Binky The Doormat"
        ],
        [
          "Zither"
        ],
        [
          "So Fast, So Numb"
        ],
        [
          "Low Desert"
        ],
        [
          "Electrolite"
        ],
        [
          "Maluco Beleza"
        ],
        [
          "O Dia Em Que A Terra Parou"
        ],
        [
          "No Fundo Do Quintal Da Escola"
        ],
        [
          "O Segredo Do Universo"
        ],
        [
          "As Profecias"
        ],
        [
          "Mata Virgem"
        ],
        [
          "Sapato 36"
        ],
        [
          "Todo Mundo Explica"
        ],
        [
          "Que Luz \u00c9 Essa"
        ],
        [
          "Diamante De Mendigo"
        ],
        [
          "Neg\u00f3cio \u00c9"
        ],
        [
          "Muita Estrela, Pouca Constela\u00e7\u00e3o"
        ],
        [
          "S\u00e9culo XXI"
        ],
        [
          "Rock Das Aranhas (Ao Vivo) (Live)"
        ],
        [
          "By The Way"
        ],
        [
          "Universally Speaking"
        ],
        [
          "This Is The Place"
        ],
        [
          "Dosed"
        ],
        [
          "Don't Forget Me"
        ],
        [
          "The Zephyr Song"
        ],
        [
          "Can't Stop"
        ],
        [
          "I Could Die For You"
        ],
        [
          "Midnight"
        ],
        [
          "Throw Away Your Television"
        ],
        [
          "Cabron"
        ],
        [
          "Tear"
        ],
        [
          "On Mercury"
        ],
        [
          "Minor Thing"
        ],
        [
          "Warm Tape"
        ],
        [
          "Venice Queen"
        ],
        [
          "Around The World"
        ],
        [
          "Parallel Universe"
        ],
        [
          "Scar Tissue"
        ],
        [
          "Otherside"
        ],
        [
          "Get On Top"
        ],
        [
          "Californication"
        ],
        [
          "Easily"
        ],
        [
          "Porcelain"
        ],
        [
          "Emit Remmus"
        ],
        [
          "I Like Dirt"
        ],
        [
          "This Velvet Glove"
        ],
        [
          "Savior"
        ],
        [
          "Purple Stain"
        ],
        [
          "Right On Time"
        ],
        [
          "Road Trippin'"
        ],
        [
          "The Spirit Of Radio"
        ],
        [
          "The Trees"
        ],
        [
          "Something For Nothing"
        ],
        [
          "Freewill"
        ],
        [
          "Xanadu"
        ],
        [
          "Bastille Day"
        ],
        [
          "By-Tor And The Snow Dog"
        ],
        [
          "Anthem"
        ],
        [
          "Closer To The Heart"
        ],
        [
          "2112 Overture"
        ],
        [
          "The Temples Of Syrinx"
        ],
        [
          "La Villa Strangiato"
        ],
        [
          "Fly By Night"
        ],
        [
          "Finding My Way"
        ],
        [
          "Jingo"
        ],
        [
          "El Corazon Manda"
        ],
        [
          "La Puesta Del Sol"
        ],
        [
          "Persuasion"
        ],
        [
          "As The Years Go by"
        ],
        [
          "Soul Sacrifice"
        ],
        [
          "Fried Neckbones And Home Fries"
        ],
        [
          "Santana Jam"
        ],
        [
          "Evil Ways"
        ],
        [
          "We've Got To Get Together/Jingo"
        ],
        [
          "Rock Me"
        ],
        [
          "Just Ain't Good Enough"
        ],
        [
          "Funky Piano"
        ],
        [
          "The Way You Do To Mer"
        ],
        [
          "Holding Back The Years"
        ],
        [
          "Money's Too Tight To Mention"
        ],
        [
          "The Right Thing"
        ],
        [
          "It's Only Love"
        ],
        [
          "A New Flame"
        ],
        [
          "You've Got It"
        ],
        [
          "If You Don't Know Me By Now"
        ],
        [
          "Stars"
        ],
        [
          "Something Got Me Started"
        ],
        [
          "Thrill Me"
        ],
        [
          "Your Mirror"
        ],
        [
          "For Your Babies"
        ],
        [
          "So Beautiful"
        ],
        [
          "Angel"
        ],
        [
          "Fairground"
        ],
        [
          "\u00c1gua E Fogo"
        ],
        [
          "Tr\u00eas Lados"
        ],
        [
          "Ela Desapareceu"
        ],
        [
          "Balada Do Amor Inabal\u00e1vel"
        ],
        [
          "Can\u00e7\u00e3o Noturna"
        ],
        [
          "Mu\u00e7ulmano"
        ],
        [
          "Maquinarama"
        ],
        [
          "Rebeli\u00e3o"
        ],
        [
          "A \u00daltima Guerra"
        ],
        [
          "Fica"
        ],
        [
          "Ali"
        ],
        [
          "Preto Dami\u00e3o"
        ],
        [
          "\u00c9 Uma Partida De Futebol"
        ],
        [
          "Eu Disse A Ela"
        ],
        [
          "Z\u00e9 Trindade"
        ],
        [
          "Garota Nacional"
        ],
        [
          "T\u00e3o Seu"
        ],
        [
          "Sem Terra"
        ],
        [
          "Os Exilados"
        ],
        [
          "Um Dia Qualquer"
        ],
        [
          "Los Pretos"
        ],
        [
          "Sul Da Am\u00e9rica"
        ],
        [
          "Pocon\u00e9"
        ],
        [
          "Nothing To Say"
        ],
        [
          "Flower"
        ],
        [
          "Loud Love"
        ],
        [
          "Hands All Over"
        ],
        [
          "Get On The Snake"
        ],
        [
          "Jesus Christ Pose"
        ],
        [
          "Outshined"
        ],
        [
          "Rusty Cage"
        ],
        [
          "Spoonman"
        ],
        [
          "The Day I Tried To Live"
        ],
        [
          "Black Hole Sun"
        ],
        [
          "Fell On Black Days"
        ],
        [
          "Pretty Noose"
        ],
        [
          "Burden In My Hand"
        ],
        [
          "Blow Up The Outside World"
        ],
        [
          "Ty Cobb"
        ],
        [
          "Bleed Together"
        ],
        [
          "Dead And Bloated"
        ],
        [
          "Sex Type Thing"
        ],
        [
          "Wicked Garden"
        ],
        [
          "No Memory"
        ],
        [
          "Sin"
        ],
        [
          "Naked Sunday"
        ],
        [
          "Creep"
        ],
        [
          "Piece Of Pie"
        ],
        [
          "Plush"
        ],
        [
          "Wet My Bed"
        ],
        [
          "Crackerman"
        ],
        [
          "Where The River Goes"
        ],
        [
          "The Sun Road"
        ],
        [
          "Dark Corners"
        ],
        [
          "Duende"
        ],
        [
          "Black Light Syndrome"
        ],
        [
          "Falling in Circles"
        ],
        [
          "Book of Hours"
        ],
        [
          "Chaos-Control"
        ],
        [
          "War (The Process)"
        ],
        [
          "The Saint"
        ],
        [
          "Rise"
        ],
        [
          "Take The Power"
        ],
        [
          "Breathe"
        ],
        [
          "Nico"
        ],
        [
          "American Gothic"
        ],
        [
          "Ashes And Ghosts"
        ],
        [
          "Shape The Sky"
        ],
        [
          "Speed Of Light"
        ],
        [
          "True Believers"
        ],
        [
          "My Bridges Burn"
        ],
        [
          "She Sells Sanctuary"
        ],
        [
          "Fire Woman"
        ],
        [
          "Lil' Evil"
        ],
        [
          "Spirit Walker"
        ],
        [
          "The Witch"
        ],
        [
          "Revolution"
        ],
        [
          "Wild Hearted Son"
        ],
        [
          "Love Removal Machine"
        ],
        [
          "Rain"
        ],
        [
          "Edie (Ciao Baby)"
        ],
        [
          "Heart Of Soul"
        ],
        [
          "Love"
        ],
        [
          "Wild Flower"
        ],
        [
          "Go West"
        ],
        [
          "Resurrection Joe"
        ],
        [
          "Sun King"
        ],
        [
          "Sweet Soul Sister"
        ],
        [
          "Earth Mofo"
        ],
        [
          "Break on Through"
        ],
        [
          "Soul Kitchen"
        ],
        [
          "The Crystal Ship"
        ],
        [
          "Twentienth Century Fox"
        ],
        [
          "Alabama Song"
        ],
        [
          "Light My Fire"
        ],
        [
          "Back Door Man"
        ],
        [
          "I Looked At You"
        ],
        [
          "End Of The Night"
        ],
        [
          "Take It As It Comes"
        ],
        [
          "The End"
        ],
        [
          "Roxanne"
        ],
        [
          "Can't Stand Losing You"
        ],
        [
          "Message in a Bottle"
        ],
        [
          "Walking on the Moon"
        ],
        [
          "Don't Stand so Close to Me"
        ],
        [
          "De Do Do Do, De Da Da Da"
        ],
        [
          "Every Little Thing She Does is Magic"
        ],
        [
          "Invisible Sun"
        ],
        [
          "Spirit's in the Material World"
        ],
        [
          "Every Breath You Take"
        ],
        [
          "King Of Pain"
        ],
        [
          "Wrapped Around Your Finger"
        ],
        [
          "Don't Stand So Close to Me '86"
        ],
        [
          "Message in a Bottle (new classic rock mix)"
        ],
        [
          "Time Is On My Side"
        ],
        [
          "Heart Of Stone"
        ],
        [
          "Play With Fire"
        ],
        [
          "Satisfaction"
        ],
        [
          "As Tears Go By"
        ],
        [
          "Get Off Of My Cloud"
        ],
        [
          "Mother's Little Helper"
        ],
        [
          "19th Nervous Breakdown"
        ],
        [
          "Paint It Black"
        ],
        [
          "Under My Thumb"
        ],
        [
          "Ruby Tuesday"
        ],
        [
          "Let's Spend The Night Together"
        ],
        [
          "Intro"
        ],
        [
          "You Got Me Rocking"
        ],
        [
          "Gimmie Shelters"
        ],
        [
          "Flip The Switch"
        ],
        [
          "Memory Motel"
        ],
        [
          "Corinna"
        ],
        [
          "Saint Of Me"
        ],
        [
          "Wainting On A Friend"
        ],
        [
          "Sister Morphine"
        ],
        [
          "Live With Me"
        ],
        [
          "Respectable"
        ],
        [
          "Thief In The Night"
        ],
        [
          "The Last Time"
        ],
        [
          "Out Of Control"
        ],
        [
          "Love Is Strong"
        ],
        [
          "You Got Me Rocking"
        ],
        [
          "Sparks Will Fly"
        ],
        [
          "The Worst"
        ],
        [
          "New Faces"
        ],
        [
          "Moon Is Up"
        ],
        [
          "Out Of Tears"
        ],
        [
          "I Go Wild"
        ],
        [
          "Brand New Car"
        ],
        [
          "Sweethearts Together"
        ],
        [
          "Suck On The Jugular"
        ],
        [
          "Blinded By Rainbows"
        ],
        [
          "Baby Break It Down"
        ],
        [
          "Thru And Thru"
        ],
        [
          "Mean Disposition"
        ],
        [
          "I Can't Explain"
        ],
        [
          "Anyway, Anyhow, Anywhere"
        ],
        [
          "My Generation"
        ],
        [
          "Substitute"
        ],
        [
          "I'm A Boy"
        ],
        [
          "Boris The Spider"
        ],
        [
          "Happy Jack"
        ],
        [
          "Pictures Of Lily"
        ],
        [
          "I Can See For Miles"
        ],
        [
          "Magic Bus"
        ],
        [
          "Pinball Wizard"
        ],
        [
          "The Seeker"
        ],
        [
          "Baba O'Riley"
        ],
        [
          "Won't Get Fooled Again (Full Length Version)"
        ],
        [
          "Let's See Action"
        ],
        [
          "5.15"
        ],
        [
          "Join Together"
        ],
        [
          "Squeeze Box"
        ],
        [
          "Who Are You (Single Edit Version)"
        ],
        [
          "You Better You Bet"
        ],
        [
          "Zoo Station"
        ],
        [
          "Even Better Than The Real Thing"
        ],
        [
          "One"
        ],
        [
          "Until The End Of The World"
        ],
        [
          "Who's Gonna Ride Your Wild Horses"
        ],
        [
          "So Cruel"
        ],
        [
          "The Fly"
        ],
        [
          "Mysterious Ways"
        ],
        [
          "Tryin' To Throw Your Arms Around The World"
        ],
        [
          "Ultraviolet (Light My Way)"
        ],
        [
          "Acrobat"
        ],
        [
          "Love Is Blindness"
        ],
        [
          "Beautiful Day"
        ],
        [
          "Stuck In A Moment You Can't Get Out Of"
        ],
        [
          "Elevation"
        ],
        [
          "Walk On"
        ],
        [
          "Kite"
        ],
        [
          "In A Little While"
        ],
        [
          "Wild Honey"
        ],
        [
          "Peace On Earth"
        ],
        [
          "When I Look At The World"
        ],
        [
          "New York"
        ],
        [
          "Grace"
        ],
        [
          "The Three Sunrises"
        ],
        [
          "Spanish Eyes"
        ],
        [
          "Sweetest Thing"
        ],
        [
          "Love Comes Tumbling"
        ],
        [
          "Bass Trap"
        ],
        [
          "Dancing Barefoot"
        ],
        [
          "Everlasting Love"
        ],
        [
          "Unchained Melody"
        ],
        [
          "Walk To The Water"
        ],
        [
          "Luminous Times (Hold On To Love)"
        ],
        [
          "Hallelujah Here She Comes"
        ],
        [
          "Silver And Gold"
        ],
        [
          "Endless Deep"
        ],
        [
          "A Room At The Heartbreak Hotel"
        ],
        [
          "Trash, Trampoline And The Party Girl"
        ],
        [
          "Vertigo"
        ],
        [
          "Miracle Drug"
        ],
        [
          "Sometimes You Can't Make It On Your Own"
        ],
        [
          "Love And Peace Or Else"
        ],
        [
          "City Of Blinding Lights"
        ],
        [
          "All Because Of You"
        ],
        [
          "A Man And A Woman"
        ],
        [
          "Crumbs From Your Table"
        ],
        [
          "One Step Closer"
        ],
        [
          "Original Of The Species"
        ],
        [
          "Yahweh"
        ],
        [
          "Discotheque"
        ],
        [
          "Do You Feel Loved"
        ],
        [
          "Mofo"
        ],
        [
          "If God Will Send His Angels"
        ],
        [
          "Staring At The Sun"
        ],
        [
          "Last Night On Earth"
        ],
        [
          "Gone"
        ],
        [
          "Miami"
        ],
        [
          "The Playboy Mansion"
        ],
        [
          "If You Wear That Velvet Dress"
        ],
        [
          "Please"
        ],
        [
          "Wake Up Dead Man"
        ],
        [
          "Helter Skelter"
        ],
        [
          "Van Diemen's Land"
        ],
        [
          "Desire"
        ],
        [
          "Hawkmoon 269"
        ],
        [
          "All Along The Watchtower"
        ],
        [
          "I Still Haven't Found What I'm Looking for"
        ],
        [
          "Freedom For My People"
        ],
        [
          "Silver And Gold"
        ],
        [
          "Pride (In The Name Of Love)"
        ],
        [
          "Angel Of Harlem"
        ],
        [
          "Love Rescue Me"
        ],
        [
          "When Love Comes To Town"
        ],
        [
          "Heartland"
        ],
        [
          "God Part II"
        ],
        [
          "The Star Spangled Banner"
        ],
        [
          "Bullet The Blue Sky"
        ],
        [
          "All I Want Is You"
        ],
        [
          "Pride (In The Name Of Love)"
        ],
        [
          "New Year's Day"
        ],
        [
          "With Or Without You"
        ],
        [
          "I Still Haven't Found What I'm Looking For"
        ],
        [
          "Sunday Bloody Sunday"
        ],
        [
          "Bad"
        ],
        [
          "Where The Streets Have No Name"
        ],
        [
          "I Will Follow"
        ],
        [
          "The Unforgettable Fire"
        ],
        [
          "Sweetest Thing"
        ],
        [
          "Desire"
        ],
        [
          "When Love Comes To Town"
        ],
        [
          "Angel Of Harlem"
        ],
        [
          "All I Want Is You"
        ],
        [
          "Sunday Bloody Sunday"
        ],
        [
          "Seconds"
        ],
        [
          "New Year's Day"
        ],
        [
          "Like A Song..."
        ],
        [
          "Drowning Man"
        ],
        [
          "The Refugee"
        ],
        [
          "Two Hearts Beat As One"
        ],
        [
          "Red Light"
        ],
        [
          "Surrender"
        ],
        [
          "\"40\""
        ],
        [
          "Zooropa"
        ],
        [
          "Babyface"
        ],
        [
          "Numb"
        ],
        [
          "Lemon"
        ],
        [
          "Stay (Faraway, So Close!)"
        ],
        [
          "Daddy's Gonna Pay For Your Crashed Car"
        ],
        [
          "Some Days Are Better Than Others"
        ],
        [
          "The First Time"
        ],
        [
          "Dirty Day"
        ],
        [
          "The Wanderer"
        ],
        [
          "Where Have All The Good Times Gone?"
        ],
        [
          "Hang 'Em High"
        ],
        [
          "Cathedral"
        ],
        [
          "Secrets"
        ],
        [
          "Intruder"
        ],
        [
          "(Oh) Pretty Woman"
        ],
        [
          "Dancing In The Street"
        ],
        [
          "Little Guitars (Intro)"
        ],
        [
          "Little Guitars"
        ],
        [
          "Big Bad Bill (Is Sweet William Now)"
        ],
        [
          "The Full Bug"
        ],
        [
          "Happy Trails"
        ],
        [
          "Eruption"
        ],
        [
          "Ain't Talkin' 'bout Love"
        ],
        [
          "Runnin' With The Devil"
        ],
        [
          "Dance the Night Away"
        ],
        [
          "And the Cradle Will Rock..."
        ],
        [
          "Unchained"
        ],
        [
          "Jump"
        ],
        [
          "Panama"
        ],
        [
          "Why Can't This Be Love"
        ],
        [
          "Dreams"
        ],
        [
          "When It's Love"
        ],
        [
          "Poundcake"
        ],
        [
          "Right Now"
        ],
        [
          "Can't Stop Loving You"
        ],
        [
          "Humans Being"
        ],
        [
          "Can't Get This Stuff No More"
        ],
        [
          "Me Wise Magic"
        ],
        [
          "Runnin' With The Devil"
        ],
        [
          "Eruption"
        ],
        [
          "You Really Got Me"
        ],
        [
          "Ain't Talkin' 'Bout Love"
        ],
        [
          "I'm The One"
        ],
        [
          "Jamie's Cryin'"
        ],
        [
          "Atomic Punk"
        ],
        [
          "Feel Your Love Tonight"
        ],
        [
          "Little Dreamer"
        ],
        [
          "Ice Cream Man"
        ],
        [
          "On Fire"
        ],
        [
          "Neworld"
        ],
        [
          "Without You"
        ],
        [
          "One I Want"
        ],
        [
          "From Afar"
        ],
        [
          "Dirty Water Dog"
        ],
        [
          "Once"
        ],
        [
          "Fire in the Hole"
        ],
        [
          "Josephina"
        ],
        [
          "Year to the Day"
        ],
        [
          "Primary"
        ],
        [
          "Ballot or the Bullet"
        ],
        [
          "How Many Say I"
        ],
        [
          "Sucker Train Blues"
        ],
        [
          "Do It For The Kids"
        ],
        [
          "Big Machine"
        ],
        [
          "Illegal I Song"
        ],
        [
          "Spectacle"
        ],
        [
          "Fall To Pieces"
        ],
        [
          "Headspace"
        ],
        [
          "Superhuman"
        ],
        [
          "Set Me Free"
        ],
        [
          "You Got No Right"
        ],
        [
          "Slither"
        ],
        [
          "Dirty Little Thing"
        ],
        [
          "Loving The Alien"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='id_x', right_on='id')\nt3 = t2[t2['name_x'] == 'Rock'].drop(['id_x','id_y','name_x','name_y','genre_id'],axis=1)\nanswer = t3[t3['name'] == 'MPEG audio file']['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]['name']",
      "t1 = pd.merge(tracks, genres, on='genre_id')\nt2 = pd.merge(t1, media_types, on='media_type_id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, on='id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')][['name']]",
      "t1 = pd.merge(genres, tracks, on='id')\nt2 = pd.merge(t1, media_types, on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[t2['name_x'] == 'Rock'][t2['name_y'] == 'MPEG audio file']['name_y']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, on='id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[t2['name_x'] == 'Rock'][t2['name_y'] == 'MPEG audio file']['name_x']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(tracks, genres, on='genre_id')\nt2 = pd.merge(t1, media_types, on='media_type_id')\nt3 = t2[(t2['name_x']=='Rock') & (t2['name_y']=='MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[t2['name_x'] == 'Rock'][t2['name_y'] == 'MPEG audio file']\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, how='left', on='id')\nt2 = pd.merge(t1, media_types, how='left', on='id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]['name_x']",
      "\nt1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, on='id')\nt2 = pd.merge(t1, media_types, on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, left_on='id', right_on='genre_id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nt3 = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]\nanswer = t3['name']",
      "t1 = pd.merge(genres, tracks, on='id')\nt2 = pd.merge(t1, media_types, left_on='media_type_id', right_on='id')\nanswer = t2[(t2['name_x'] == 'Rock') & (t2['name_y'] == 'MPEG audio file')]['name']"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "cre_Doc_Control_Systems",
      "query": "SELECT document_type_description FROM Ref_Document_Types WHERE document_type_code = \"Paper\";",
      "query_toks": [
        "SELECT",
        "document_type_description",
        "FROM",
        "Ref_Document_Types",
        "WHERE",
        "document_type_code",
        "=",
        "``",
        "Paper",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "document_type_description",
        "from",
        "ref_document_types",
        "where",
        "document_type_code",
        "=",
        "value"
      ],
      "question": "What is the description of document type 'Paper'?",
      "question_toks": [
        "What",
        "is",
        "the",
        "description",
        "of",
        "document",
        "type",
        "'Paper",
        "'",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                1,
                false
              ],
              null
            ],
            "\"Paper\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Document_Types": [
          "document_type_code",
          "document_type_description"
        ],
        "Roles": [
          "role_code",
          "role_description"
        ],
        "Addresses": [
          "address_id",
          "address_details"
        ],
        "Ref_Document_Status": [
          "document_status_code",
          "document_status_description"
        ],
        "Ref_Shipping_Agents": [
          "shipping_agent_code",
          "shipping_agent_name",
          "shipping_agent_description"
        ],
        "Documents": [
          "document_id",
          "document_status_code",
          "document_type_code",
          "shipping_agent_code",
          "receipt_date",
          "receipt_number",
          "other_details"
        ],
        "Employees": [
          "employee_id",
          "role_code",
          "employee_name",
          "other_details"
        ],
        "Document_Drafts": [
          "document_id",
          "draft_number",
          "draft_details"
        ],
        "Draft_Copies": [
          "document_id",
          "draft_number",
          "copy_number"
        ],
        "Circulation_History": [
          "document_id",
          "draft_number",
          "copy_number",
          "employee_id"
        ],
        "Documents_Mailed": [
          "document_id",
          "mailed_to_address_id",
          "mailing_date"
        ]
      },
      "answer": [
        [
          "u"
        ]
      ]
    },
    "generated_programs": [
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = pd.Series(Ref_Document_Types.loc[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description'][0])",
      "t1 = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']\nanswer = t1['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types.loc[Ref_Document_Types['document_type_code'] == 'Paper', 'document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description'].unique()",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']",
      "answer = Ref_Document_Types[Ref_Document_Types['document_type_code'] == 'Paper']['document_type_description']"
    ],
    "acc@20": 7,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "e_learning",
      "query": "SELECT T1.course_description ,  T1.course_name FROM Courses AS T1 JOIN Student_Course_Enrolment AS T2 ON T1.course_id  =  T2.course_id GROUP BY T1.course_name HAVING COUNT(*)  >  2",
      "query_toks": [
        "SELECT",
        "T1.course_description",
        ",",
        "T1.course_name",
        "FROM",
        "Courses",
        "AS",
        "T1",
        "JOIN",
        "Student_Course_Enrolment",
        "AS",
        "T2",
        "ON",
        "T1.course_id",
        "=",
        "T2.course_id",
        "GROUP",
        "BY",
        "T1.course_name",
        "HAVING",
        "COUNT",
        "(",
        "*",
        ")",
        ">",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "course_description",
        ",",
        "t1",
        ".",
        "course_name",
        "from",
        "courses",
        "as",
        "t1",
        "join",
        "student_course_enrolment",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "course_id",
        "=",
        "t2",
        ".",
        "course_id",
        "group",
        "by",
        "t1",
        ".",
        "course_name",
        "having",
        "count",
        "(",
        "*",
        ")",
        ">",
        "value"
      ],
      "question": "What are the descriptions and names of the courses that have student enrollment bigger than 2?",
      "question_toks": [
        "What",
        "are",
        "the",
        "descriptions",
        "and",
        "names",
        "of",
        "the",
        "courses",
        "that",
        "have",
        "student",
        "enrollment",
        "bigger",
        "than",
        "2",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ],
            [
              "table_unit",
              4
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  20,
                  false
                ],
                null
              ],
              [
                0,
                27,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  24,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  23,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            23,
            false
          ]
        ],
        "having": [
          [
            false,
            3,
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Course_Authors_and_Tutors": [
          "author_id",
          "author_tutor_ATB",
          "login_name",
          "password",
          "personal_name",
          "middle_name",
          "family_name",
          "gender_mf",
          "address_line_1"
        ],
        "Students": [
          "student_id",
          "date_of_registration",
          "date_of_latest_logon",
          "login_name",
          "password",
          "personal_name",
          "middle_name",
          "family_name"
        ],
        "Subjects": [
          "subject_id",
          "subject_name"
        ],
        "Courses": [
          "course_id",
          "author_id",
          "subject_id",
          "course_name",
          "course_description"
        ],
        "Student_Course_Enrolment": [
          "registration_id",
          "student_id",
          "course_id",
          "date_of_enrolment",
          "date_of_completion"
        ],
        "Student_Tests_Taken": [
          "registration_id",
          "date_test_taken",
          "test_result"
        ]
      },
      "answer": [
        [
          "French",
          "French"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(Courses, t3, on='course_name')[['course_description', 'course_name']]\nanswer = t4.drop_duplicates()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_name', 'course_description']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby(['course_id', 'course_name']).size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Courses, left_on='course_id', right_on='course_id')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Courses, on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "answer = Courses[Courses['course_id'].isin(Student_Course_Enrolment.groupby('course_id').size()[Student_Course_Enrolment.groupby('course_id').size() > 2].index)][['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_name']).size().rename('count')\nanswer = Courses[Courses['course_name'].isin(t2[t2 > 2].index)][['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = t3.merge(Courses, on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nanswer = Courses[Courses['course_name'].isin(t2[t2 > 2].index)][['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby(['course_name']).size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Courses, left_on='course_name', right_on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(Courses, t3, on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_name', 'course_description']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_description', 'course_name']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby(['course_name']).size().rename('count')\nt3 = t2[t2 > 2].reset_index()\nanswer = pd.merge(Courses, t3[['course_name']], on='course_name')[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_name'], as_index = False).size().rename('count').to_frame().reset_index()\nt3 = t2[t2['count'] > 2].set_index('course_name')\nt4 = pd.merge(t3, Courses, how='left', left_on='course_name', right_on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_name', 'course_description']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby(['course_name']).size().rename('count')\nt3 = t2[t2 > 2].to_frame().reset_index()\nt4 = pd.merge(t3, Courses, left_on='course_name', right_on='course_name')\nanswer = t4[['course_description', 'course_name']]",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby(['course_description', 'course_name']).size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nt3 = Courses.merge(t2, how = 'inner', on = 'course_name', suffixes = ('', '_t2')).drop('count_t2', axis = 1)\nt4 = t3[t3['course_description'] != np.nan]\nanswer = t4",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, left_on='course_id', right_on='course_id')\nt2 = t1.groupby('course_name').size().rename('count')\nanswer = t2[t2 > 2].to_frame().reset_index()",
      "t1 = pd.merge(Courses, Student_Course_Enrolment, on='course_id')\nt2 = t1.groupby('course_name').size().to_frame().rename(columns = {0: 'count'}).reset_index()\nanswer = Courses[Courses['course_name'].isin(t2[t2['count'] > 2]['course_name'])][['course_name', 'course_description']]"
    ],
    "acc@20": 11,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "customers_and_invoices",
      "query": "SELECT product_id ,  count(DISTINCT order_id) FROM Order_items GROUP BY product_id",
      "query_toks": [
        "SELECT",
        "product_id",
        ",",
        "count",
        "(",
        "DISTINCT",
        "order_id",
        ")",
        "FROM",
        "Order_items",
        "GROUP",
        "BY",
        "product_id"
      ],
      "query_toks_no_value": [
        "select",
        "product_id",
        ",",
        "count",
        "(",
        "distinct",
        "order_id",
        ")",
        "from",
        "order_items",
        "group",
        "by",
        "product_id"
      ],
      "question": "Show the product ids and the number of unique orders containing each product.",
      "question_toks": [
        "Show",
        "the",
        "product",
        "ids",
        "and",
        "the",
        "number",
        "of",
        "unique",
        "orders",
        "containing",
        "each",
        "product",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              7
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  45,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  44,
                  true
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            45,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Customers": [
          "customer_id",
          "customer_first_name",
          "customer_middle_initial",
          "customer_last_name",
          "gender",
          "email_address",
          "login_name",
          "login_password",
          "phone_number",
          "town_city",
          "state_county_province",
          "country"
        ],
        "Orders": [
          "order_id",
          "customer_id",
          "date_order_placed",
          "order_details"
        ],
        "Invoices": [
          "invoice_number",
          "order_id",
          "invoice_date"
        ],
        "Accounts": [
          "account_id",
          "customer_id",
          "date_account_opened",
          "account_name",
          "other_account_details"
        ],
        "Product_Categories": [
          "production_type_code",
          "product_type_description",
          "vat_rating"
        ],
        "Products": [
          "product_id",
          "parent_product_id",
          "production_type_code",
          "unit_price",
          "product_name",
          "product_color",
          "product_size"
        ],
        "Financial_Transactions": [
          "transaction_id",
          "account_id",
          "invoice_number",
          "transaction_type",
          "transaction_date",
          "transaction_amount",
          "transaction_comment",
          "other_transaction_details"
        ],
        "Order_Items": [
          "order_item_id",
          "order_id",
          "product_id",
          "product_quantity",
          "other_order_item_details"
        ],
        "Invoice_Line_Items": [
          "order_item_id",
          "invoice_number",
          "product_id",
          "product_title",
          "product_quantity",
          "product_price",
          "derived_product_cost",
          "derived_vat_payable",
          "derived_total_cost"
        ]
      },
      "answer": [
        [
          3,
          1
        ],
        [
          4,
          2
        ],
        [
          5,
          2
        ],
        [
          7,
          1
        ],
        [
          9,
          1
        ],
        [
          10,
          1
        ],
        [
          12,
          1
        ],
        [
          13,
          1
        ],
        [
          14,
          3
        ],
        [
          15,
          1
        ]
      ]
    },
    "generated_programs": [
      "t1 = Order_Items.groupby('product_id').size().rename('count').to_frame().reset_index()\nanswer = t1[['product_id', 'count']]",
      "t1 = Order_Items.groupby('product_id').agg('nunique')['order_id'].rename('count').to_frame()\nanswer = t1.reset_index()",
      "",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t = Order_Items.groupby(['product_id']).agg({'order_id':'nunique'})\nanswer = t.rename({'order_id':'num_orders'}, axis = 1).reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nanswer = t1.sort_index().to_frame().reset_index()",
      "t1 = Order_Items.groupby('product_id').size()\nanswer = pd.DataFrame(t1).rename(columns={0: 'count'}).reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = pd.merge(Orders, Order_Items, on='order_id')\nt2 = t1.groupby('product_id').order_id.nunique().to_frame().rename(columns={'order_id': 'count'}).reset_index()\nanswer = t2",
      "answer = Order_Items.groupby('product_id').size().rename('count').to_frame().reset_index()",
      "t1 = Order_Items.groupby('product_id').agg({'order_id': pd.Series.nunique}).rename(columns={'order_id': 'count'})\nanswer = t1.sort_values('product_id', ascending = True)",
      "answer = Order_Items.groupby('product_id').order_id.nunique().reset_index(name='count')",
      "t1 = Order_Items.groupby('product_id').agg({'order_id': pd.Series.nunique})\nanswer = t1.rename(columns={'order_id': 'count'}).reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nt2 = t1.to_frame().reset_index()\nanswer = t2[['product_id', 'count']]",
      "t1 = Order_Items.groupby(['product_id']).agg({'order_id': pd.Series.nunique}).rename(columns = {'order_id': 'count'})\nanswer = t1.reset_index()",
      "answer = pd.merge(Order_Items, Invoice_Line_Items, left_on='order_item_id', right_on='order_item_id').groupby(['product_id', 'order_id']).size().rename('count')\\\n    .reset_index().groupby('product_id').count().reset_index()",
      "t1 = Order_Items.groupby('product_id').order_id.unique().apply(lambda x: len(x)).rename('count').to_frame()\nanswer = t1.reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Order_Items.groupby('product_id').size().rename('count').to_frame().reset_index()\nanswer = t1[['product_id', 'count']]"
    ],
    "acc@20": 7,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "cre_Docs_and_Epenses",
      "query": "SELECT STATEMENT_ID ,  statement_details FROM Statements",
      "query_toks": [
        "SELECT",
        "STATEMENT_ID",
        ",",
        "statement_details",
        "FROM",
        "Statements"
      ],
      "query_toks_no_value": [
        "select",
        "statement_id",
        ",",
        "statement_details",
        "from",
        "statements"
      ],
      "question": "List all statement ids and statement details.",
      "question_toks": [
        "List",
        "all",
        "statement",
        "ids",
        "and",
        "statement",
        "details",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  15,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  16,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Document_Types": [
          "Document_Type_Code",
          "Document_Type_Name",
          "Document_Type_Description"
        ],
        "Ref_Budget_Codes": [
          "Budget_Type_Code",
          "Budget_Type_Description"
        ],
        "Projects": [
          "Project_ID",
          "Project_Details"
        ],
        "Documents": [
          "Document_ID",
          "Document_Type_Code",
          "Project_ID",
          "Document_Date",
          "Document_Name",
          "Document_Description",
          "Other_Details"
        ],
        "Statements": [
          "Statement_ID",
          "Statement_Details"
        ],
        "Documents_with_Expenses": [
          "Document_ID",
          "Budget_Type_Code",
          "Document_Details"
        ],
        "Accounts": [
          "Account_ID",
          "Statement_ID",
          "Account_Details"
        ]
      },
      "answer": [
        [
          57,
          "Open Project"
        ],
        [
          192,
          "Private Project"
        ]
      ]
    },
    "generated_programs": [
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "t1 = Statements[['statement_id', 'statement_details']]\nanswer = t1",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]",
      "answer = Statements[['statement_id', 'statement_details']]"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "phone_1",
      "query": "SELECT avg(T1.ROM_MiB) FROM chip_model AS T1 JOIN phone AS T2 ON T1.Model_name  =  T2.chip_model WHERE T2.Company_name = \"Nokia Corporation\";",
      "query_toks": [
        "SELECT",
        "avg",
        "(",
        "T1.ROM_MiB",
        ")",
        "FROM",
        "chip_model",
        "AS",
        "T1",
        "JOIN",
        "phone",
        "AS",
        "T2",
        "ON",
        "T1.Model_name",
        "=",
        "T2.chip_model",
        "WHERE",
        "T2.Company_name",
        "=",
        "``",
        "Nokia",
        "Corporation",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "avg",
        "(",
        "t1",
        ".",
        "rom_mib",
        ")",
        "from",
        "chip_model",
        "as",
        "t1",
        "join",
        "phone",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "model_name",
        "=",
        "t2",
        ".",
        "chip_model",
        "where",
        "t2",
        ".",
        "company_name",
        "=",
        "value"
      ],
      "question": "What is the average ROM size of phones produced by the company named \"Nokia Corporation\"?",
      "question_toks": [
        "What",
        "is",
        "the",
        "average",
        "ROM",
        "size",
        "of",
        "phones",
        "produced",
        "by",
        "the",
        "company",
        "named",
        "``",
        "Nokia",
        "Corporation",
        "''",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              2
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                20,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              5,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                15,
                false
              ],
              null
            ],
            "\"Nokia Corporation\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "chip_model": [
          "Model_name",
          "Launch_year",
          "RAM_MiB",
          "ROM_MiB",
          "Slots",
          "WiFi",
          "Bluetooth"
        ],
        "screen_mode": [
          "Graphics_mode",
          "Char_cells",
          "Pixels",
          "Hardware_colours",
          "used_kb",
          "map",
          "Type"
        ],
        "phone": [
          "Company_name",
          "Hardware_Model_name",
          "Accreditation_type",
          "Accreditation_level",
          "Date",
          "chip_model",
          "screen_mode"
        ]
      },
      "answer": [
        [
          32.0
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(chip_model, phone, on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = t2['rom_mib'].mean()",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = t2.rom_mib.mean()",
      "t1 = pd.merge(phone, chip_model, on='chip_model')\nanswer = pd.Series(round(t1[t1['company_name'] == \"Nokia Corporation\"]['rom_mib'].mean(), 2))",
      "t1 = pd.merge(phone, chip_model, left_on='chip_model', right_on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())",
      "t1 = pd.merge(chip_model, phone, on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())",
      "t1 = pd.merge(phone, chip_model, on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean(), dtype='float64')",
      "t1 = pd.merge(phone, chip_model, on='chip_model')\nanswer = pd.Series(t1[t1['company_name'] == 'Nokia Corporation']['rom_mib'].mean())",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = t2.rom_mib.mean()",
      "t1 = pd.merge(chip_model, phone, on='model_name')\nanswer = t1[t1['company_name'] == 'Nokia Corporation']['rom_mib'].mean()",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nanswer = t1[t1['company_name'] == \"Nokia Corporation\"]['rom_mib'].mean()",
      "t1 = pd.merge(chip_model, phone, on=['model_name'])\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())",
      "t1 = pd.merge(phone, chip_model, on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = t2['rom_mib'].mean()",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = t2['rom_mib'].mean()",
      "t1 = pd.merge(chip_model, phone, on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].astype(float).mean())",
      "t1 = pd.merge(chip_model, phone, on='model_name')\nanswer = pd.Series(t1[t1['company_name'] == 'nokia corporation']['rom_mib'].mean())",
      "t1 = pd.merge(phone, chip_model, on='model_name')\nanswer = pd.Series(t1[t1['company_name'] == 'Nokia Corporation']['rom_mib'].mean())",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nanswer = pd.Series(t1[t1['company_name'] == 'Nokia Corporation']['rom_mib'].mean())",
      "t1 = pd.merge(phone, chip_model, left_on='chip_model', right_on='model_name')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())",
      "t1 = pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model')\nt2 = t1[t1['company_name'] == 'Nokia Corporation']\nanswer = pd.Series(t2['rom_mib'].mean())"
    ],
    "acc@20": 9,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "csu_1",
      "query": "SELECT count(*) FROM campuses",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "campuses"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "campuses"
      ],
      "question": "What is the total number of campuses?",
      "question_toks": [
        "What",
        "is",
        "the",
        "total",
        "number",
        "of",
        "campuses",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Campuses": [
          "Id",
          "Campus",
          "Location",
          "County",
          "Year"
        ],
        "csu_fees": [
          "Campus",
          "Year",
          "CampusFee"
        ],
        "degrees": [
          "Year",
          "Campus",
          "Degrees"
        ],
        "discipline_enrollments": [
          "Campus",
          "Discipline",
          "Year",
          "Undergraduate",
          "Graduate"
        ],
        "enrollments": [
          "Campus",
          "Year",
          "TotalEnrollment_AY",
          "FTE_AY"
        ],
        "faculty": [
          "Campus",
          "Year",
          "Faculty"
        ]
      },
      "answer": [
        [
          23
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses['id'].unique().size)",
      "# answer: 23\nanswer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])",
      "answer = pd.Series(Campuses.shape[0])"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "manufactory_1",
      "query": "SELECT avg(price) FROM products",
      "query_toks": [
        "SELECT",
        "avg",
        "(",
        "price",
        ")",
        "FROM",
        "products"
      ],
      "query_toks_no_value": [
        "select",
        "avg",
        "(",
        "price",
        ")",
        "from",
        "products"
      ],
      "question": "What is the average price across all products?",
      "question_toks": [
        "What",
        "is",
        "the",
        "average",
        "price",
        "across",
        "all",
        "products",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              5,
              [
                0,
                [
                  0,
                  8,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Manufacturers": [
          "Code",
          "Name",
          "Headquarter",
          "Founder",
          "Revenue"
        ],
        "Products": [
          "Code",
          "Name",
          "Price",
          "Manufacturer"
        ]
      },
      "answer": [
        [
          153.72727272727272
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(np.mean(Products['price']))",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())",
      "answer = pd.Series(Products['price'].mean())"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "department_store",
      "query": "SELECT avg(product_price) FROM products WHERE product_type_code  =  'Clothes'",
      "query_toks": [
        "SELECT",
        "avg",
        "(",
        "product_price",
        ")",
        "FROM",
        "products",
        "WHERE",
        "product_type_code",
        "=",
        "'Clothes",
        "'"
      ],
      "query_toks_no_value": [
        "select",
        "avg",
        "(",
        "product_price",
        ")",
        "from",
        "products",
        "where",
        "product_type_code",
        "=",
        "value"
      ],
      "question": "Find the average price of all product clothes.",
      "question_toks": [
        "Find",
        "the",
        "average",
        "price",
        "of",
        "all",
        "product",
        "clothes",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              5
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              5,
              [
                0,
                [
                  0,
                  21,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                19,
                false
              ],
              null
            ],
            "\"Clothes\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Addresses": [
          "address_id",
          "address_details"
        ],
        "Staff": [
          "staff_id",
          "staff_gender",
          "staff_name"
        ],
        "Suppliers": [
          "supplier_id",
          "supplier_name",
          "supplier_phone"
        ],
        "Department_Store_Chain": [
          "dept_store_chain_id",
          "dept_store_chain_name"
        ],
        "Customers": [
          "customer_id",
          "payment_method_code",
          "customer_code",
          "customer_name",
          "customer_address",
          "customer_phone",
          "customer_email"
        ],
        "Products": [
          "product_id",
          "product_type_code",
          "product_name",
          "product_price"
        ],
        "Supplier_Addresses": [
          "supplier_id",
          "address_id",
          "date_from",
          "date_to"
        ],
        "Customer_Addresses": [
          "customer_id",
          "address_id",
          "date_from",
          "date_to"
        ],
        "Customer_Orders": [
          "order_id",
          "customer_id",
          "order_status_code",
          "order_date"
        ],
        "Department_Stores": [
          "dept_store_id",
          "dept_store_chain_id",
          "store_name",
          "store_address",
          "store_phone",
          "store_email"
        ],
        "Departments": [
          "department_id",
          "dept_store_id",
          "department_name"
        ],
        "Order_Items": [
          "order_item_id",
          "order_id",
          "product_id"
        ],
        "Product_Suppliers": [
          "product_id",
          "supplier_id",
          "date_supplied_from",
          "date_supplied_to",
          "total_amount_purchased",
          "total_value_purchased"
        ],
        "Staff_Department_Assignments": [
          "staff_id",
          "department_id",
          "date_assigned_from",
          "job_title_code",
          "date_assigned_to"
        ]
      },
      "answer": [
        [
          715.5366666666666
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "t1 = Products[Products['product_type_code'] == 'clothes']\nanswer = pd.Series(np.average(t1['product_price']))",
      "answer = products[products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = products[products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = products[products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = Products[Products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = Products[Products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = Products[Products['product_type_code'] == 'clothes'].agg({'product_price': 'mean'})",
      "answer = Products[Products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = Products[Products['product_type_code'] == 'clothes']['product_price'].mean()",
      "answer = pd.Series(Products[Products['product_type_code'] == 'clothes']['product_price'].mean())",
      "answer = pd.Series(products[products['product_type_code'] == 'clothes']['product_price'].mean())"
    ],
    "acc@20": 0,
    "pass@20": 0.0
  },
  {
    "example": {
      "db_id": "hr_1",
      "query": "SELECT employee_id ,  first_name ,  last_name ,  salary FROM employees WHERE salary  >  ( SELECT AVG (salary) FROM employees ) AND department_id IN ( SELECT department_id FROM employees WHERE first_name LIKE '%J%')",
      "query_toks": [
        "SELECT",
        "employee_id",
        ",",
        "first_name",
        ",",
        "last_name",
        ",",
        "salary",
        "FROM",
        "employees",
        "WHERE",
        "salary",
        ">",
        "(",
        "SELECT",
        "AVG",
        "(",
        "salary",
        ")",
        "FROM",
        "employees",
        ")",
        "AND",
        "department_id",
        "IN",
        "(",
        "SELECT",
        "department_id",
        "FROM",
        "employees",
        "WHERE",
        "first_name",
        "LIKE",
        "'",
        "%",
        "J",
        "%",
        "'",
        ")"
      ],
      "query_toks_no_value": [
        "select",
        "employee_id",
        ",",
        "first_name",
        ",",
        "last_name",
        ",",
        "salary",
        "from",
        "employees",
        "where",
        "salary",
        ">",
        "(",
        "select",
        "avg",
        "(",
        "salary",
        ")",
        "from",
        "employees",
        ")",
        "and",
        "department_id",
        "in",
        "(",
        "select",
        "department_id",
        "from",
        "employees",
        "where",
        "first_name",
        "like",
        "value",
        ")"
      ],
      "question": "display the employee number, name( first name and last name ), and salary for all employees who earn more than the average salary and who work in a department with any employee with a 'J' in their first name.",
      "question_toks": [
        "display",
        "the",
        "employee",
        "number",
        ",",
        "name",
        "(",
        "first",
        "name",
        "and",
        "last",
        "name",
        ")",
        ",",
        "and",
        "salary",
        "for",
        "all",
        "employees",
        "who",
        "earn",
        "more",
        "than",
        "the",
        "average",
        "salary",
        "and",
        "who",
        "work",
        "in",
        "a",
        "department",
        "with",
        "any",
        "employee",
        "with",
        "a",
        "'J",
        "'",
        "in",
        "their",
        "first",
        "name",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              4
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  14,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  15,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  16,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  21,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                21,
                false
              ],
              null
            ],
            {
              "from": {
                "table_units": [
                  [
                    "table_unit",
                    4
                  ]
                ],
                "conds": []
              },
              "select": [
                false,
                [
                  [
                    5,
                    [
                      0,
                      [
                        0,
                        21,
                        false
                      ],
                      null
                    ]
                  ]
                ]
              ],
              "where": [],
              "groupBy": [],
              "having": [],
              "orderBy": [],
              "limit": null,
              "intersect": null,
              "union": null,
              "except": null
            },
            null
          ],
          "and",
          [
            false,
            8,
            [
              0,
              [
                0,
                24,
                false
              ],
              null
            ],
            {
              "from": {
                "table_units": [
                  [
                    "table_unit",
                    4
                  ]
                ],
                "conds": []
              },
              "select": [
                false,
                [
                  [
                    0,
                    [
                      0,
                      [
                        0,
                        24,
                        false
                      ],
                      null
                    ]
                  ]
                ]
              ],
              "where": [
                [
                  false,
                  9,
                  [
                    0,
                    [
                      0,
                      15,
                      false
                    ],
                    null
                  ],
                  "\"%J%\"",
                  null
                ]
              ],
              "groupBy": [],
              "having": [],
              "orderBy": [],
              "limit": null,
              "intersect": null,
              "union": null,
              "except": null
            },
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "regions": [
          "REGION_ID",
          "REGION_NAME"
        ],
        "countries": [
          "COUNTRY_ID",
          "COUNTRY_NAME",
          "REGION_ID"
        ],
        "departments": [
          "DEPARTMENT_ID",
          "DEPARTMENT_NAME",
          "MANAGER_ID",
          "LOCATION_ID"
        ],
        "jobs": [
          "JOB_ID",
          "JOB_TITLE",
          "MIN_SALARY",
          "MAX_SALARY"
        ],
        "employees": [
          "EMPLOYEE_ID",
          "FIRST_NAME",
          "LAST_NAME",
          "EMAIL",
          "PHONE_NUMBER",
          "HIRE_DATE",
          "JOB_ID",
          "SALARY",
          "COMMISSION_PCT",
          "MANAGER_ID",
          "DEPARTMENT_ID"
        ],
        "job_history": [
          "EMPLOYEE_ID",
          "START_DATE",
          "END_DATE",
          "JOB_ID",
          "DEPARTMENT_ID"
        ],
        "locations": [
          "LOCATION_ID",
          "STREET_ADDRESS",
          "POSTAL_CODE",
          "CITY",
          "STATE_PROVINCE",
          "COUNTRY_ID"
        ]
      },
      "answer": [
        [
          108,
          "Nancy",
          "Greenberg",
          12000
        ],
        [
          109,
          "Daniel",
          "Faviet",
          9000
        ],
        [
          110,
          "John",
          "Chen",
          8200
        ],
        [
          111,
          "Ismael",
          "Sciarra",
          7700
        ],
        [
          112,
          "Jose Manuel",
          "Urman",
          7800
        ],
        [
          113,
          "Luis",
          "Popp",
          6900
        ],
        [
          120,
          "Matthew",
          "Weiss",
          8000
        ],
        [
          121,
          "Adam",
          "Fripp",
          8200
        ],
        [
          122,
          "Payam",
          "Kaufling",
          7900
        ],
        [
          123,
          "Shanta",
          "Vollman",
          6500
        ],
        [
          145,
          "John",
          "Russell",
          14000
        ],
        [
          146,
          "Karen",
          "Partners",
          13500
        ],
        [
          147,
          "Alberto",
          "Errazuriz",
          12000
        ],
        [
          148,
          "Gerald",
          "Cambrault",
          11000
        ],
        [
          149,
          "Eleni",
          "Zlotkey",
          10500
        ],
        [
          150,
          "Peter",
          "Tucker",
          10000
        ],
        [
          151,
          "David",
          "Bernstein",
          9500
        ],
        [
          152,
          "Peter",
          "Hall",
          9000
        ],
        [
          153,
          "Christopher",
          "Olsen",
          8000
        ],
        [
          154,
          "Nanette",
          "Cambrault",
          7500
        ],
        [
          155,
          "Oliver",
          "Tuvault",
          7000
        ],
        [
          156,
          "Janette",
          "King",
          10000
        ],
        [
          157,
          "Patrick",
          "Sully",
          9500
        ],
        [
          158,
          "Allan",
          "McEwen",
          9000
        ],
        [
          159,
          "Lindsey",
          "Smith",
          8000
        ],
        [
          160,
          "Louise",
          "Doran",
          7500
        ],
        [
          161,
          "Sarath",
          "Sewall",
          7000
        ],
        [
          162,
          "Clara",
          "Vishney",
          10500
        ],
        [
          163,
          "Danielle",
          "Greene",
          9500
        ],
        [
          164,
          "Mattea",
          "Marvins",
          7200
        ],
        [
          165,
          "David",
          "Lee",
          6800
        ],
        [
          168,
          "Lisa",
          "Ozer",
          11500
        ],
        [
          169,
          "Harrison",
          "Bloom",
          10000
        ],
        [
          170,
          "Tayler",
          "Fox",
          9600
        ],
        [
          171,
          "William",
          "Smith",
          7400
        ],
        [
          172,
          "Elizabeth",
          "Bates",
          7300
        ],
        [
          174,
          "Ellen",
          "Abel",
          11000
        ],
        [
          175,
          "Alyssa",
          "Hutton",
          8800
        ],
        [
          176,
          "Jonathon",
          "Taylor",
          8600
        ],
        [
          177,
          "Jack",
          "Livingston",
          8400
        ]
      ]
    },
    "generated_programs": [
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J', case=False)]\nt3 = pd.merge(t1, t2, on='department_id', how='inner')\nanswer = t3[['employee_id', 'first_name_x', 'last_name_x', 'salary_x']]",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J')]\nt3 = pd.merge(t1, t2, on='department_id')\nanswer = t3[['employee_id', 'first_name_x', 'last_name_x', 'salary_x']]",
      "t1 = pd.Series(employees['salary'].mean())\nt2 = employees[employees['salary'] > t1[0]].copy()\nt3 = employees[employees['first_name'].str.contains('J')]\nanswer = pd.merge(t2[['employee_id', 'first_name', 'last_name', 'salary']], t3[['department_id']], on='department_id', how = 'inner')",
      "t1 = employees[(employees['salary'] > employees['salary'].mean()) & (employees['department_id'].isin(employees[employees['first_name'].str.contains('J')]['department_id']))]\nanswer = t1[['employee_id', 'first_name', 'last_name', 'salary',]]",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J')]['department_id'].unique()\nt3 = t1[t1['department_id'].isin(t2)]\nanswer = t3[['employee_id', 'first_name', 'last_name', 'salary']]",
      "avg_salary = employees['salary'].mean()\nt1 = employees[employees['salary'] > avg_salary]\nt2 = employees[employees['first_name'].str.contains('J')]\nt3 = t1[t1['department_id'].isin(t2['department_id'])]\nanswer = t3[['employee_id', 'first_name', 'last_name', 'salary']]",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('j', na=False)]\nanswer = t1[t1['department_id'].isin(t2['department_id'])][['employee_id', 'first_name', 'last_name', 'salary']]\n   ",
      "answer = employees[['employee_id', 'first_name', 'last_name', 'salary']][(employees['salary'] > employees['salary'].mean()) & (employees['department_id'].isin(employees[employees['first_name'].str.contains('J')]['department_id']))]",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('j')]\nanswer = pd.merge(t1, t2, on='department_id')[['employee_id', 'first_name_x', 'last_name_x', 'salary']]",
      "t1 = employees[['employee_id', 'first_name', 'last_name', 'salary', 'department_id']][employees['first_name'].str.contains('j', regex=True, na=False)]\nanswer = employees[['employee_id', 'first_name', 'last_name', 'salary']][employees['salary'] > employees['salary'].mean()].merge(t1, on='department_id', how='inner')",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J')]\nt3 = t2['department_id'].unique()\nt4 = t1[t1['department_id'].isin(t3)]\nanswer = t4[['employee_id', 'first_name', 'last_name', 'salary']]",
      "answer = employees[employees['salary'] > employees['salary'].mean()][employees['department_id'].isin(employees[employees['first_name'].str.contains('j', case=False)]['department_id'])][['employee_id', 'first_name', 'last_name', 'salary']]",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J', case=False)]\nt3 = t1[t1['department_id'].isin(t2['department_id'])][['employee_id', 'first_name', 'last_name', 'salary']]\nanswer = t3",
      "t1 = employees[employees['salary'] > employees['salary'].mean()]\nanswer = t1[t1['department_id'].isin(employees[employees['first_name'].str.contains('j', case=False)]['department_id'])][['employee_id', 'first_name', 'last_name', 'salary']]",
      "t1 = employees.loc[employees['salary'] > employees['salary'].mean()]\nt2 = employees[employees['first_name'].str.contains('J')]\nt3 = pd.merge(t1, t2, on='department_id')\nanswer = t3[['employee_id', 'first_name', 'last_name', 'salary']]",
      "t1 = pd.merge(employees, departments, on='department_id')\nt2 = t1.groupby('department_id').salary.mean().rename('average_salary')\nt3 = pd.merge(t1, t2.to_frame(), on='department_id')\nt4 = t3[t3['salary_x'] > t3['average_salary']]\nt5 = pd.merge(t4, employees, on='department_id')\nt6 = t5[t5['first_name_y'].str.contains('J')]\nt7 = t6.drop_duplicates(subset='employee_id_x')\nanswer = t7[['employee_id_x', 'first_name_x', 'last_name_x', 'salary_x']]",
      "t1 = employees.groupby('department_id').mean().reset_index()\nt2 = pd.merge(employees, t1, on='department_id')\nt3 = t2[t2['salary_x'] > t2['salary_y']]\nt4 = employees[employees['first_name'].str.contains('j', case = False)]\nt5 = pd.merge(t3, t4, on='department_id')\nanswer = t5[['employee_id_x','first_name_x','last_name_x','salary_x']].drop_duplicates()",
      "answer = employees[employees['salary'] > employees['salary'].mean()][employees['department_id'].isin(employees[employees['first_name'].str.contains('J')]['department_id'])][['employee_id', 'first_name', 'last_name', 'salary']]",
      "t1 = employees.groupby('department_id')['salary'].mean().rename('avg_salary').reset_index()\nt2 = pd.merge(employees, t1, on='department_id')\nt3 = t2[t2['salary_y'] >= t2['salary_x']]\nt4 = employees[employees['first_name'].str.contains('J', case=False)]['department_id']\nt5 = pd.merge(t3[['employee_id','first_name','last_name','salary_x','department_id']], t4.to_frame(), on='department_id', how='inner')\nanswer = t5[['employee_id','first_name','last_name','salary_x']]",
      "t1 = employees.groupby('employee_id').mean()['salary'].rename('salary')\nt1 = pd.DataFrame(index=t1.index, data=t1.values)\nt2 = employees[employees['first_name'].str.contains('J', regex=False)]\nt3 = pd.merge(employees, t1, on='employee_id')\nt4 = pd.merge(t3, t2, on='department_id')\nanswer = t4[t4['salary_x'] > t4['salary_y']][['employee_id', 'first_name_x', 'last_name_x', 'salary_x']]"
    ],
    "acc@20": 9,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "sports_competition",
      "query": "SELECT Competition_type ,  COUNT(*) FROM competition GROUP BY Competition_type",
      "query_toks": [
        "SELECT",
        "Competition_type",
        ",",
        "COUNT",
        "(",
        "*",
        ")",
        "FROM",
        "competition",
        "GROUP",
        "BY",
        "Competition_type"
      ],
      "query_toks_no_value": [
        "select",
        "competition_type",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "competition",
        "group",
        "by",
        "competition_type"
      ],
      "question": "List the types of competition and the number of competitions of each type.",
      "question_toks": [
        "List",
        "the",
        "types",
        "of",
        "competition",
        "and",
        "the",
        "number",
        "of",
        "competitions",
        "of",
        "each",
        "type",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              3
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  21,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            21,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "club": [
          "Club_ID",
          "name",
          "Region",
          "Start_year"
        ],
        "club_rank": [
          "Rank",
          "Club_ID",
          "Gold",
          "Silver",
          "Bronze",
          "Total"
        ],
        "player": [
          "Player_ID",
          "name",
          "Position",
          "Club_ID",
          "Apps",
          "Tries",
          "Goals",
          "Points"
        ],
        "competition": [
          "Competition_ID",
          "Year",
          "Competition_type",
          "Country"
        ],
        "competition_result": [
          "Competition_ID",
          "Club_ID_1",
          "Club_ID_2",
          "Score"
        ]
      },
      "answer": [
        [
          "Friendly",
          8
        ],
        [
          "Tournament",
          3
        ]
      ]
    },
    "generated_programs": [
      "answer = competition.groupby(['competition_type']).size().rename('count').to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = competition.groupby('competition_type')['competition_id'].size().rename('count').to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = competition.groupby('competition_type').size().rename('count').to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = competition.groupby('competition_type').size().rename('count').to_frame()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = competition.groupby('competition_type').size().to_frame(name='count').reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = competition.groupby('competition_type').size().rename('count').to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = competition.groupby('competition_type').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = pd.Series(competition['competition_type']).value_counts().rename('count')\nanswer = t1.to_frame().reset_index().rename(columns={'index': 'competition_type'})"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "inn_1",
      "query": "SELECT roomname FROM rooms WHERE baseprice BETWEEN 120 AND 150",
      "query_toks": [
        "SELECT",
        "roomname",
        "FROM",
        "rooms",
        "WHERE",
        "baseprice",
        "BETWEEN",
        "120",
        "AND",
        "150"
      ],
      "query_toks_no_value": [
        "select",
        "roomname",
        "from",
        "rooms",
        "where",
        "baseprice",
        "between",
        "value",
        "and",
        "value"
      ],
      "question": "Find the name of rooms whose base price is between 120 and 150.",
      "question_toks": [
        "Find",
        "the",
        "name",
        "of",
        "rooms",
        "whose",
        "base",
        "price",
        "is",
        "between",
        "120",
        "and",
        "150",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            1,
            [
              0,
              [
                0,
                6,
                false
              ],
              null
            ],
            120.0,
            150.0
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Rooms": [
          "RoomId",
          "roomName",
          "beds",
          "bedType",
          "maxOccupancy",
          "basePrice",
          "decor"
        ],
        "Reservations": [
          "Code",
          "Room",
          "CheckIn",
          "CheckOut",
          "Rate",
          "LastName",
          "FirstName",
          "Adults",
          "Kids"
        ]
      },
      "answer": [
        [
          "Recluse and defiance"
        ],
        [
          "Interim but salutary"
        ],
        [
          "Mendicant with cryptic"
        ],
        [
          "Immutable before decorum"
        ]
      ]
    },
    "generated_programs": [
      "answer = Rooms[(Rooms.baseprice >= 120) & (Rooms.baseprice <= 150)]['roomname']",
      "t1 = Rooms.ix[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]\nanswer = t1['roomname']",
      "answer = Rooms[(Rooms['baseprice'] > 120) & (Rooms['baseprice'] < 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] > 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[Rooms['baseprice'].between(120, 150)]['roomname']",
      "answer = Rooms[Rooms.baseprice.between(120, 150)][['roomname']]",
      "answer = Rooms[(Rooms['baseprice']>120) & (Rooms['baseprice']<150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] > 120) & (Rooms['baseprice'] < 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "t1 = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]\nanswer = t1['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)][['roomname']]",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']",
      "answer = Rooms[(Rooms['baseprice'] >= 120) & (Rooms['baseprice'] <= 150)]['roomname']"
    ],
    "acc@20": 16,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "inn_1",
      "query": "SELECT bedType ,  count(*) FROM Rooms GROUP BY bedType;",
      "query_toks": [
        "SELECT",
        "bedType",
        ",",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "Rooms",
        "GROUP",
        "BY",
        "bedType",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "bedtype",
        ",",
        "count",
        "(",
        "*",
        ")",
        "from",
        "rooms",
        "group",
        "by",
        "bedtype"
      ],
      "question": "What are the number of rooms for each bed type?",
      "question_toks": [
        "What",
        "are",
        "the",
        "number",
        "of",
        "rooms",
        "for",
        "each",
        "bed",
        "type",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ],
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            4,
            false
          ]
        ],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Rooms": [
          "RoomId",
          "roomName",
          "beds",
          "bedType",
          "maxOccupancy",
          "basePrice",
          "decor"
        ],
        "Reservations": [
          "Code",
          "Room",
          "CheckIn",
          "CheckOut",
          "Rate",
          "LastName",
          "FirstName",
          "Adults",
          "Kids"
        ]
      },
      "answer": [
        [
          "Double",
          2
        ],
        [
          "King",
          4
        ],
        [
          "Queen",
          4
        ]
      ]
    },
    "generated_programs": [
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "t1 = Rooms.groupby('bedtype').size().rename('count').to_frame()\nanswer = t1.reset_index()",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype')['roomid'].size().rename('count').to_frame()",
      "answer = Rooms.groupby('bedtype')['roomid'].size().rename('count')",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = t1.to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count')",
      "answer = Rooms.groupby('bedtype')['roomid'].count().to_frame().rename(columns={'roomid':'count'})",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame()",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame()",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = pd.Series(t1)",
      "answer = Rooms.groupby('bedtype').size().rename('count').to_frame().reset_index()",
      "answer = Rooms.groupby('bedtype').size().rename('count')",
      "t1 = Rooms.groupby('bedtype').size().rename('count')\nanswer = t1.to_frame().reset_index()"
    ],
    "acc@20": 12,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "county_public_safety",
      "query": "SELECT Name FROM county_public_safety WHERE County_ID NOT IN (SELECT County_ID FROM city)",
      "query_toks": [
        "SELECT",
        "Name",
        "FROM",
        "county_public_safety",
        "WHERE",
        "County_ID",
        "NOT",
        "IN",
        "(",
        "SELECT",
        "County_ID",
        "FROM",
        "city",
        ")"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        "from",
        "county_public_safety",
        "where",
        "county_id",
        "not",
        "in",
        "(",
        "select",
        "county_id",
        "from",
        "city",
        ")"
      ],
      "question": "List the names of counties that do not have any cities.",
      "question_toks": [
        "List",
        "the",
        "names",
        "of",
        "counties",
        "that",
        "do",
        "not",
        "have",
        "any",
        "cities",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            true,
            8,
            [
              0,
              [
                0,
                1,
                false
              ],
              null
            ],
            {
              "from": {
                "table_units": [
                  [
                    "table_unit",
                    1
                  ]
                ],
                "conds": []
              },
              "select": [
                false,
                [
                  [
                    0,
                    [
                      0,
                      [
                        0,
                        11,
                        false
                      ],
                      null
                    ]
                  ]
                ]
              ],
              "where": [],
              "groupBy": [],
              "having": [],
              "orderBy": [],
              "limit": null,
              "intersect": null,
              "union": null,
              "except": null
            },
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "county_public_safety": [
          "County_ID",
          "Name",
          "Population",
          "Police_officers",
          "Residents_per_officer",
          "Case_burden",
          "Crime_rate",
          "Police_force",
          "Location"
        ],
        "city": [
          "City_ID",
          "County_ID",
          "Name",
          "White",
          "Black",
          "Amerindian",
          "Asian",
          "Multiracial",
          "Hispanic"
        ]
      },
      "answer": []
    },
    "generated_programs": [
      "\n# t1 = city.groupby('county_id').size().rename('count')\n# t2 = county_public_safety.merge(t1, on='county_id', how='left')\n# answer = t2[t2['count'] == 0]['name']",
      "city_county_ids = set(city['county_id'])\ncounty_not_have_city_ids = set(county_public_safety['county_id']) - city_county_ids\nanswer = county_public_safety[county_public_safety['county_id'].isin(county_not_have_city_ids)]['name']",
      "t1 = pd.merge(county_public_safety, city, left_on='county_id', right_on='county_id', how='left')\nt2 = t1[pd.isnull(t1['city_id'])]\nanswer = t2['name']",
      "t1 = county_public_safety['county_id']\nt2 = city['county_id']\nt3 = county_public_safety[~t1.isin(t2)]\nanswer = t3['name']",
      "city_county_id = city['county_id'].unique()\nt1 = county_public_safety[~county_public_safety['county_id'].isin(city_county_id)]\nanswer = t1['name']",
      "t1 = city['county_id'].drop_duplicates()\nt2 = county_public_safety[~county_public_safety['county_id'].isin(t1)]\nanswer = t2['name']",
      "t1 = city.groupby('county_id').size()\nt2 = county_public_safety[~county_public_safety['county_id'].isin(t1.index)]\nanswer = t2['name']",
      "answer = county_public_safety[~county_public_safety['county_id'].isin(city['county_id'])]['name']",
      "t1 = city.groupby('county_id').size().rename('count').reset_index()\nanswer = county_public_safety[~county_public_safety['county_id'].isin(t1['county_id'])]['name']",
      "t1 = city['county_id'].drop_duplicates()\nt2 = county_public_safety[~county_public_safety['county_id'].isin(t1)]['name']\nanswer = t2",
      "t1 = county_public_safety['county_id'].isin(city['county_id'])\nanswer = county_public_safety[~t1]['name']",
      "a = city['county_id'].unique()\nanswer = county_public_safety[~county_public_safety['county_id'].isin(a)]['name']",
      "t1 = city['county_id'].drop_duplicates()\nt2 = county_public_safety[~ county_public_safety['county_id'].isin(t1)]\nanswer = t2['name']",
      "answer = county_public_safety[~county_public_safety['county_id'].isin(city['county_id'])]['name']",
      "t1 = city[['county_id']].drop_duplicates()\nanswer = county_public_safety[~county_public_safety['county_id'].isin(t1['county_id'])]['name']",
      "t1 = city['county_id'].unique()\nanswer = county_public_safety[~county_public_safety['county_id'].isin(t1)]['name']",
      "t1 = city['county_id'].unique()\nt2 = county_public_safety[~county_public_safety['county_id'].isin(t1)]['name']\nanswer = t2",
      "t1 = city['county_id'].unique()\nt2 = county_public_safety[-county_public_safety['county_id'].isin(t1)]\nanswer = t2['name']",
      "t1 = pd.merge(county_public_safety, city, on='county_id', how='left')\nt2 = t1[t1['city_id'].isnull()]\nanswer = t2['name']",
      "answer = county_public_safety[~county_public_safety['county_id'].isin(city['county_id'])]['name']"
    ],
    "acc@20": 17,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "music_4",
      "query": "SELECT T1.Famous_Title FROM artist AS T1 JOIN volume AS T2 ON T1.Artist_ID  =  T2.Artist_ID WHERE T2.Weeks_on_Top  >  2 INTERSECT SELECT T1.Famous_Title FROM artist AS T1 JOIN volume AS T2 ON T1.Artist_ID  =  T2.Artist_ID WHERE T2.Weeks_on_Top  <  2",
      "query_toks": [
        "SELECT",
        "T1.Famous_Title",
        "FROM",
        "artist",
        "AS",
        "T1",
        "JOIN",
        "volume",
        "AS",
        "T2",
        "ON",
        "T1.Artist_ID",
        "=",
        "T2.Artist_ID",
        "WHERE",
        "T2.Weeks_on_Top",
        ">",
        "2",
        "INTERSECT",
        "SELECT",
        "T1.Famous_Title",
        "FROM",
        "artist",
        "AS",
        "T1",
        "JOIN",
        "volume",
        "AS",
        "T2",
        "ON",
        "T1.Artist_ID",
        "=",
        "T2.Artist_ID",
        "WHERE",
        "T2.Weeks_on_Top",
        "<",
        "2"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "famous_title",
        "from",
        "artist",
        "as",
        "t1",
        "join",
        "volume",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "artist_id",
        "=",
        "t2",
        ".",
        "artist_id",
        "where",
        "t2",
        ".",
        "weeks_on_top",
        ">",
        "value",
        "intersect",
        "select",
        "t1",
        ".",
        "famous_title",
        "from",
        "artist",
        "as",
        "t1",
        "join",
        "volume",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "artist_id",
        "=",
        "t2",
        ".",
        "artist_id",
        "where",
        "t2",
        ".",
        "weeks_on_top",
        "<",
        "value"
      ],
      "question": "What are the famous titles of artists who have not only had volumes that spent more than 2 weeks on top but also volumes that spent less than 2 weeks on top?",
      "question_toks": [
        "What",
        "are",
        "the",
        "famous",
        "titles",
        "of",
        "artists",
        "who",
        "have",
        "not",
        "only",
        "had",
        "volumes",
        "that",
        "spent",
        "more",
        "than",
        "2",
        "weeks",
        "on",
        "top",
        "but",
        "also",
        "volumes",
        "that",
        "spent",
        "less",
        "than",
        "2",
        "weeks",
        "on",
        "top",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ],
            [
              "table_unit",
              1
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ],
              [
                0,
                11,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                9,
                false
              ],
              null
            ],
            2.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": {
          "from": {
            "table_units": [
              [
                "table_unit",
                0
              ],
              [
                "table_unit",
                1
              ]
            ],
            "conds": [
              [
                false,
                2,
                [
                  0,
                  [
                    0,
                    1,
                    false
                  ],
                  null
                ],
                [
                  0,
                  11,
                  false
                ],
                null
              ]
            ]
          },
          "select": [
            false,
            [
              [
                0,
                [
                  0,
                  [
                    0,
                    4,
                    false
                  ],
                  null
                ]
              ]
            ]
          ],
          "where": [
            [
              false,
              4,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ],
              2.0,
              null
            ]
          ],
          "groupBy": [],
          "having": [],
          "orderBy": [],
          "limit": null,
          "intersect": null,
          "union": null,
          "except": null
        },
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artist": [
          "Artist_ID",
          "Artist",
          "Age",
          "Famous_Title",
          "Famous_Release_date"
        ],
        "volume": [
          "Volume_ID",
          "Volume_Issue",
          "Issue_Date",
          "Weeks_on_Top",
          "Song",
          "Artist_ID"
        ],
        "music_festival": [
          "ID",
          "Music_Festival",
          "Date_of_ceremony",
          "Category",
          "Volume",
          "Result"
        ]
      },
      "answer": [
        [
          "Bergen 1996"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title'].unique()\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = t3[t3['famous_title'].isin(t2)]['famous_title'].unique()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title']\nt3 = t1[t1['weeks_on_top'] < 2]['famous_title']\nanswer = t2.intersection(t3)",
      "t1 = pd.merge(artist, volume, left_on='artist_id', right_on='artist_id')\nset1 = set(t1[t1['weeks_on_top'] > 2]['famous_title'])\nset2 = set(t1[t1['weeks_on_top'] < 2]['famous_title'])\nset3 = set1.intersection(set2)\nanswer = pd.Series(list(set3))",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title'].unique()\nt3 = t1[t1['weeks_on_top'] < 2]['famous_title'].unique()\nanswer = t2[np.isin(t2, t3)]",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = pd.merge(t2, t3, on='famous_title', how='inner')['famous_title'].unique()\nt2 = t1[t1['weeks_on_top'] > 2][['famous_title']]\nt3 = t1[t1['weeks_on_top'] < 2][['famous_title']]\nanswer = pd.merge(t2, t3, on='famous_title', how='inner')['famous_title'].unique()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = t2.merge(t3, how='inner', on='famous_title')['famous_title'].drop_duplicates()",
      "t1 = pd.merge(artist, volume, on='artist_id')[['famous_title', 'weeks_on_top']]\nt2 = t1[t1['weeks_on_top'] > 2].drop_duplicates()\nt3 = t1[t1['weeks_on_top'] < 2].drop_duplicates()\nanswer = t2.merge(t3, on='famous_title', how='inner')['famous_title']",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] < 2]\nt3 = t1[t1['weeks_on_top'] > 2]\nt4 = t3[['famous_title']]\nt5 = t2[['famous_title']]\nanswer = t4.merge(t5, on='famous_title', how='inner')['famous_title']",
      "t1 = pd.merge(artist, volume, on='artist_id', how='inner')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title'].rename('famous_title')\nt3 = t1[t1['weeks_on_top'] < 2]['famous_title'].rename('famous_title')\nanswer = pd.merge(t2, t3, on='famous_title', how='inner')",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = t2[['famous_title', 'weeks_on_top']].append(t3[['famous_title', 'weeks_on_top']]).drop_duplicates()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = t2['famous_title'].append(t3['famous_title']).drop_duplicates().reset_index().drop('index', axis=1)",
      "t1 = pd.merge(artist, volume, on='artist_id')\nmore = t1[t1['weeks_on_top'] > 2]\nless = t1[t1['weeks_on_top'] < 2]\nanswer = pd.merge(more, less, on='famous_title').groupby('famous_title').size().to_frame(name='count').reset_index()['famous_title']",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nanswer = t2.merge(t3, on='famous_title', how='inner')['famous_title'].unique()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nt4 = pd.merge(t2, t3, left_on='famous_title', right_on='famous_title', how='inner')\nanswer = t4['famous_title'].drop_duplicates()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title'].unique()\nt3 = t1[t1['weeks_on_top'] < 2]['famous_title'].unique()\nanswer = np.intersect1d(t2, t3)",
      "t1 = pd.merge(artist, volume, left_on='artist_id', right_on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nt4 = pd.merge(t2['famous_title'], t3['famous_title'], on='famous_title')\nanswer = t4.drop_duplicates()",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2].drop_duplicates(subset=['famous_title'])\nt3 = t1[t1['weeks_on_top'] < 2].drop_duplicates(subset=['famous_title'])\nanswer = pd.merge(t2, t3, on='famous_title')[['famous_title']]",
      "t1 = pd.merge(artist, volume[volume['weeks_on_top'] > 2], on='artist_id')\nt2 = pd.merge(artist, volume[volume['weeks_on_top'] < 2], on='artist_id')\nanswer = pd.merge(t1[['famous_title']].drop_duplicates(), t2[['famous_title']].drop_duplicates(), on='famous_title', how='intersection')",
      "t1 = pd.merge(artist, volume, on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]['famous_title'].unique()\nt3 = t1[t1['weeks_on_top'] < 2]['famous_title'].unique()\nt4 = np.intersect1d(t2, t3)\nanswer = pd.Series(t4)",
      "t1 = pd.merge(artist, volume, left_on='artist_id', right_on='artist_id')\nt2 = t1[t1['weeks_on_top'] > 2]\nt3 = t1[t1['weeks_on_top'] < 2]\nt4 = t2.merge(t3, on='famous_title', how='inner')\nanswer = t4['famous_title'].unique()"
    ],
    "acc@20": 11,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "music_1",
      "query": "SELECT T1.country FROM artist AS T1 JOIN song AS T2 ON T1.artist_name  =  T2.artist_name GROUP BY T2.artist_name ORDER BY count(*) LIMIT 1",
      "query_toks": [
        "SELECT",
        "T1.country",
        "FROM",
        "artist",
        "AS",
        "T1",
        "JOIN",
        "song",
        "AS",
        "T2",
        "ON",
        "T1.artist_name",
        "=",
        "T2.artist_name",
        "GROUP",
        "BY",
        "T2.artist_name",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "country",
        "from",
        "artist",
        "as",
        "t1",
        "join",
        "song",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "artist_name",
        "=",
        "t2",
        ".",
        "artist_name",
        "group",
        "by",
        "t2",
        ".",
        "artist_name",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "limit",
        "value"
      ],
      "question": "What country is the artist who made the fewest songs from?",
      "question_toks": [
        "What",
        "country",
        "is",
        "the",
        "artist",
        "who",
        "made",
        "the",
        "fewest",
        "songs",
        "from",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ],
            [
              "table_unit",
              3
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ],
              [
                0,
                14,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            14,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "genre": [
          "g_name",
          "rating",
          "most_popular_in"
        ],
        "artist": [
          "artist_name",
          "country",
          "gender",
          "preferred_genre"
        ],
        "files": [
          "f_id",
          "artist_name",
          "file_size",
          "duration",
          "formats"
        ],
        "song": [
          "song_name",
          "artist_name",
          "country",
          "f_id",
          "genre_is",
          "rating",
          "languages",
          "releasedate",
          "resolution"
        ]
      },
      "answer": [
        [
          "USA"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nt4 = pd.merge(t3, artist, on='artist_name')\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nt4 = pd.merge(t3, artist, on='artist_name') \nanswer = t4['country']",
      "t1 = pd.merge(artist, song, left_on='artist_name', right_on='artist_name')\nt2 = t1.groupby(['artist_name']).size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nanswer = t3['artist_name'].map(lambda x: artist[artist['artist_name'] == x].squeeze()['country'])",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nt3 = pd.merge(t2, artist, on='artist_name')\nanswer = t3[['country']].sort_values('count', ascending=True).head(1)",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame()\nt3 = t2.sort_values(ascending=True).head(1).to_frame().reset_index()\nt4 = pd.merge(t3, t1, on='artist_name')\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, left_on='artist_name', right_on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.to_frame().reset_index().sort_values('count', ascending=True).head(1)\nanswer = artist[artist['artist_name'] == t3.iloc[0]['artist_name']]['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nt3 = t2.sort_values('count').head(1)\nanswer = artist[artist['artist_name'].isin(t3['artist_name'])]['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nanswer = t1[t1['artist_name'] == t3.iloc[0,0]]['country'].unique()",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nanswer = t2.sort_values('count').iloc[0]['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby(['country']).size().rename('count')\nanswer = t2.sort_values().head(1).index.get_values()",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nt3 = pd.merge(t2, artist, left_on='artist_name', right_on='artist_name')\nt4 = t3.sort_values('count', ascending=True).head(1)\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, left_on='artist_name', right_on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values(ascending=True).head(1).to_frame().reset_index()\nt4 = pd.merge(t3, artist, left_on='artist_name', right_on='artist_name')\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nt3 = pd.merge(t2, artist, on='artist_name')\nanswer = t3.sort_values('count').head(1)['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nt4 = pd.merge(artist, t3, on='artist_name')\nanswer = t4['country']",
      "t2 = pd.merge(artist, song, on='artist_name')\nanswer = pd.Series(t2.groupby('artist_name').size().rename('count').sort_values().head(1).reset_index()['country'])",
      "t1 = pd.merge(artist, song, left_on='artist_name', right_on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count').to_frame().reset_index()\nt3 = pd.merge(t2, artist, left_on='artist_name', right_on='artist_name')\nanswer = t3[t3['count'] == t3['count'].min()]['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values()[:1].reset_index()\nanswer = t3['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values().head(1).to_frame().reset_index()\nt4 = pd.merge(t3, artist, on='artist_name')\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = pd.merge(t2, artist, on='artist_name')\nt4 = t3.sort_values('count').head(1)\nanswer = t4['country']",
      "t1 = pd.merge(artist, song, on='artist_name')\nt2 = t1.groupby('artist_name').size().rename('count')\nt3 = t2.sort_values()\nt4 = t3.head(1).reset_index()\nt5 = t4.join(t1.set_index('artist_name'), on='artist_name')\nanswer = t5['country'].unique()"
    ],
    "acc@20": 10,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT composer FROM tracks WHERE name = \"Fast As a Shark\";",
      "query_toks": [
        "SELECT",
        "composer",
        "FROM",
        "tracks",
        "WHERE",
        "name",
        "=",
        "``",
        "Fast",
        "As",
        "a",
        "Shark",
        "''",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "composer",
        "from",
        "tracks",
        "where",
        "name",
        "=",
        "value"
      ],
      "question": "Who is the composer of track Fast As a Shark?",
      "question_toks": [
        "Who",
        "is",
        "the",
        "composer",
        "of",
        "track",
        "Fast",
        "As",
        "a",
        "Shark",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              8
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  54,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                50,
                false
              ],
              null
            ],
            "\"Fast As a Shark\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "F. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman"
        ]
      ],
      "pandas_converted": "tracks[tracks['name'] == 'Fast As a Shark']['composer']"
    },
    "generated_programs": [
      "answer = tracks[tracks['name'] == 'Fast As a Shark'][['composer']].iloc[0, 0]",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As a Shark']['composer']",
      "answer = tracks[tracks['name']=='Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As a Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As a Shark']['composer']",
      "t1 = tracks[tracks['name'] == 'Fast As A Shark']['composer']\nanswer = t1",
      "\nanswer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "t1 = tracks[tracks['name'] == 'Fast As A Shark']\nanswer = t1['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As a Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks.loc[tracks['name'] == 'Fast As A Shark', 'composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']",
      "answer = tracks.loc[tracks['name']=='Fast As A Shark','composer']",
      "answer = tracks[tracks['name'] == 'Fast As a Shark']['composer']",
      "answer = tracks[tracks['name'] == 'Fast As A Shark']['composer']"
    ],
    "acc@20": 5,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "cre_Doc_Tracking_DB",
      "query": "SELECT location_code FROM Document_locations GROUP BY location_code ORDER BY count(*) DESC LIMIT 1",
      "query_toks": [
        "SELECT",
        "location_code",
        "FROM",
        "Document_locations",
        "GROUP",
        "BY",
        "location_code",
        "ORDER",
        "BY",
        "count",
        "(",
        "*",
        ")",
        "DESC",
        "LIMIT",
        "1"
      ],
      "query_toks_no_value": [
        "select",
        "location_code",
        "from",
        "document_locations",
        "group",
        "by",
        "location_code",
        "order",
        "by",
        "count",
        "(",
        "*",
        ")",
        "desc",
        "limit",
        "value"
      ],
      "question": "Find the code of the location with the largest number of documents.",
      "question_toks": [
        "Find",
        "the",
        "code",
        "of",
        "the",
        "location",
        "with",
        "the",
        "largest",
        "number",
        "of",
        "documents",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              6
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  25,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            25,
            false
          ]
        ],
        "having": [],
        "orderBy": [
          "desc",
          [
            [
              0,
              [
                3,
                0,
                false
              ],
              null
            ]
          ]
        ],
        "limit": 1,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Ref_Document_Types": [
          "Document_Type_Code",
          "Document_Type_Name",
          "Document_Type_Description"
        ],
        "Ref_Calendar": [
          "Calendar_Date",
          "Day_Number"
        ],
        "Ref_Locations": [
          "Location_Code",
          "Location_Name",
          "Location_Description"
        ],
        "Roles": [
          "Role_Code",
          "Role_Name",
          "Role_Description"
        ],
        "All_Documents": [
          "Document_ID",
          "Date_Stored",
          "Document_Type_Code",
          "Document_Name",
          "Document_Description",
          "Other_Details"
        ],
        "Employees": [
          "Employee_ID",
          "Role_Code",
          "Employee_Name",
          "Gender_MFU",
          "Date_of_Birth",
          "Other_Details"
        ],
        "Document_Locations": [
          "Document_ID",
          "Location_Code",
          "Date_in_Location_From",
          "Date_in_Locaton_To"
        ],
        "Documents_to_be_Destroyed": [
          "Document_ID",
          "Destruction_Authorised_by_Employee_ID",
          "Destroyed_by_Employee_ID",
          "Planned_Destruction_Date",
          "Actual_Destruction_Date",
          "Other_Details"
        ]
      },
      "answer": [
        [
          "x"
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Document_Locations.groupby('location_code').size().sort_values(ascending=False).head(1).to_frame().reset_index()['location_code'][0])",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending = False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().sort_values(ascending=False).to_frame().reset_index()\nanswer = t1['location_code'].head(1)",
      "answer = Document_Locations.groupby('location_code').size().sort_values(ascending=False).head(1).to_frame().reset_index()['location_code']",
      "t1 = Document_Locations[['location_code', 'document_id']].groupby('location_code').size().rename('count').to_frame()\nanswer = pd.merge(Document_Locations, t1, left_on='location_code', right_index=True).sort_values('count', ascending=False).head(1)['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count').to_frame().reset_index()\nt2 = t1.sort_values('count', ascending=False).head(1)\nanswer = t2['location_code']",
      "answer = Document_Locations.groupby('location_code')['location_code'].count().sort_values(ascending=False).head(1)",
      "t1 = Document_Locations.groupby(['location_code']).size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "locations = pd.merge(Document_Locations, Ref_Locations, on='location_code')\nt1 = locations.groupby(['location_code']).size().rename('count').to_frame().reset_index()\nanswer = t1.nlargest(1, 'count')['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count').to_frame().reset_index()\nanswer = Ref_Locations[Ref_Locations['location_code'] == t1['location_code'].iloc[0]]['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = pd.merge(Document_Locations, Ref_Locations, left_on='location_code', right_on='location_code')\nanswer = t1.groupby('location_code').size().sort_values(ascending=False).head(1).index",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']",
      "t1 = Document_Locations.groupby('location_code').size().rename('count')\nt2 = t1.sort_values(ascending=False).head(1).to_frame().reset_index()\nanswer = t2['location_code']"
    ],
    "acc@20": 17,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "race_track",
      "query": "SELECT name ,  CLASS ,  date FROM race",
      "query_toks": [
        "SELECT",
        "name",
        ",",
        "CLASS",
        ",",
        "date",
        "FROM",
        "race"
      ],
      "query_toks_no_value": [
        "select",
        "name",
        ",",
        "class",
        ",",
        "date",
        "from",
        "race"
      ],
      "question": "Show name, class, and date for all races.",
      "question_toks": [
        "Show",
        "name",
        ",",
        "class",
        ",",
        "and",
        "date",
        "for",
        "all",
        "races",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  4,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "race": [
          "Race_ID",
          "Name",
          "Class",
          "Date",
          "Track_ID"
        ],
        "track": [
          "Track_ID",
          "Name",
          "Location",
          "Seating",
          "Year_Opened"
        ]
      },
      "answer": [
        [
          "Rolex 24 At Daytona",
          "DP/GT",
          "January 26 January 27"
        ],
        [
          "Gainsco Grand Prix of Miami",
          "DP/GT",
          "March 29"
        ],
        [
          "Mexico City 250",
          "DP/GT",
          "April 19"
        ],
        [
          "Bosch Engineering 250 at VIR",
          "GT",
          "April 27"
        ],
        [
          "RumBum.com 250",
          "DP/GT",
          "May 17"
        ],
        [
          "Lime Rock GT Classic 250",
          "GT",
          "May 26"
        ],
        [
          "Sahlen's Six Hours of the Glen",
          "DP/GT",
          "June 7"
        ]
      ]
    },
    "generated_programs": [
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']].sort_values('date')",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]",
      "answer = race[['name', 'class', 'date']]"
    ],
    "acc@20": 19,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "soccer_2",
      "query": "SELECT cName ,  enr FROM College WHERE enr  >  10000 AND state = \"LA\"",
      "query_toks": [
        "SELECT",
        "cName",
        ",",
        "enr",
        "FROM",
        "College",
        "WHERE",
        "enr",
        ">",
        "10000",
        "AND",
        "state",
        "=",
        "``",
        "LA",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "cname",
        ",",
        "enr",
        "from",
        "college",
        "where",
        "enr",
        ">",
        "value",
        "and",
        "state",
        "=",
        "value"
      ],
      "question": "Find the name, enrollment of the colleges whose size is bigger than 10000 and location is in state LA.",
      "question_toks": [
        "Find",
        "the",
        "name",
        ",",
        "enrollment",
        "of",
        "the",
        "colleges",
        "whose",
        "size",
        "is",
        "bigger",
        "than",
        "10000",
        "and",
        "location",
        "is",
        "in",
        "state",
        "LA",
        "."
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  1,
                  false
                ],
                null
              ]
            ],
            [
              0,
              [
                0,
                [
                  0,
                  3,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            3,
            [
              0,
              [
                0,
                3,
                false
              ],
              null
            ],
            10000.0,
            null
          ],
          "and",
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            "\"LA\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "College": [
          "cName",
          "state",
          "enr"
        ],
        "Player": [
          "pID",
          "pName",
          "yCard",
          "HS"
        ],
        "Tryout": [
          "pID",
          "cName",
          "pPos",
          "decision"
        ]
      },
      "answer": [
        [
          "LSU",
          18000
        ]
      ]
    },
    "generated_programs": [
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "t1 = College[College['state'] == 'LA']\nanswer = t1[t1['enr'] > 10000][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')]",
      "t1 = College[College['state'] == 'LA'][['cname', 'enr']]\nt2 = t1[t1['enr'] > 10000]\nanswer = t2",
      "t1 = College.loc[College['enr'] > 10000]\nt2 = t1.loc[t1['state'] == 'la']\nanswer = t2[['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]",
      "answer = College[(College['state'] == 'la') & (College['enr'] > 10000)][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['state'] == \"LA\") & (College['enr'] > 10000)][['cname', 'enr']]",
      "t1 = College[(College['enr'] > 10000) & (College['state'] == 'LA')]\nanswer = t1[['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'LA')][['cname', 'enr']]",
      "answer = College[(College['enr'] > 10000) & (College['state'] == 'la')][['cname', 'enr']]"
    ],
    "acc@20": 11,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "store_1",
      "query": "SELECT T1.title FROM albums AS T1 JOIN tracks AS T2 ON T1.id = T2.album_id GROUP BY T1.id HAVING count(T1.id)  >  10;",
      "query_toks": [
        "SELECT",
        "T1.title",
        "FROM",
        "albums",
        "AS",
        "T1",
        "JOIN",
        "tracks",
        "AS",
        "T2",
        "ON",
        "T1.id",
        "=",
        "T2.album_id",
        "GROUP",
        "BY",
        "T1.id",
        "HAVING",
        "count",
        "(",
        "T1.id",
        ")",
        ">",
        "10",
        ";"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "title",
        "from",
        "albums",
        "as",
        "t1",
        "join",
        "tracks",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "id",
        "=",
        "t2",
        ".",
        "album_id",
        "group",
        "by",
        "t1",
        ".",
        "id",
        "having",
        "count",
        "(",
        "t1",
        ".",
        "id",
        ")",
        ">",
        "value"
      ],
      "question": "What are the names of the albums that have more than 10 tracks?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "the",
        "albums",
        "that",
        "have",
        "more",
        "than",
        "10",
        "tracks",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ],
            [
              "table_unit",
              8
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ],
              [
                0,
                51,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  6,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [
          [
            0,
            5,
            false
          ]
        ],
        "having": [
          [
            false,
            3,
            [
              0,
              [
                3,
                5,
                false
              ],
              null
            ],
            10.0,
            null
          ]
        ],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "artists": [
          "id",
          "name"
        ],
        "sqlite_sequence": [
          "name",
          "seq"
        ],
        "albums": [
          "id",
          "title",
          "artist_id"
        ],
        "employees": [
          "id",
          "last_name",
          "first_name",
          "title",
          "reports_to",
          "birth_date",
          "hire_date",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email"
        ],
        "customers": [
          "id",
          "first_name",
          "last_name",
          "company",
          "address",
          "city",
          "state",
          "country",
          "postal_code",
          "phone",
          "fax",
          "email",
          "support_rep_id"
        ],
        "genres": [
          "id",
          "name"
        ],
        "invoices": [
          "id",
          "customer_id",
          "invoice_date",
          "billing_address",
          "billing_city",
          "billing_state",
          "billing_country",
          "billing_postal_code",
          "total"
        ],
        "media_types": [
          "id",
          "name"
        ],
        "tracks": [
          "id",
          "name",
          "album_id",
          "media_type_id",
          "genre_id",
          "composer",
          "milliseconds",
          "bytes",
          "unit_price"
        ],
        "invoice_lines": [
          "id",
          "invoice_id",
          "track_id",
          "unit_price",
          "quantity"
        ],
        "playlists": [
          "id",
          "name"
        ],
        "playlist_tracks": [
          "playlist_id",
          "track_id"
        ]
      },
      "answer": [
        [
          "Big Ones"
        ],
        [
          "Jagged Little Pill"
        ],
        [
          "Facelift"
        ],
        [
          "Warner 25 Anos"
        ],
        [
          "Audioslave"
        ],
        [
          "Out Of Exile"
        ],
        [
          "BackBeat Soundtrack"
        ],
        [
          "Alcohol Fueled Brewtality Live! [Disc 1]"
        ],
        [
          "Body Count"
        ],
        [
          "Chemical Wedding"
        ],
        [
          "The Best Of Buddy Guy - The Millenium Collection"
        ],
        [
          "Prenda Minha"
        ],
        [
          "Minha Historia"
        ],
        [
          "Afrociberdelia"
        ],
        [
          "Da Lama Ao Caos"
        ],
        [
          "Ac\u00fastico MTV live"
        ],
        [
          "Cidade Negra - Hits"
        ],
        [
          "Ax\u00e9 Bahia 2001"
        ],
        [
          "BBC Sessions [Disc 1] live"
        ],
        [
          "Carnaval 2001"
        ],
        [
          "Chill: Brazil (Disc 1)"
        ],
        [
          "Chill: Brazil (Disc 2)"
        ],
        [
          "Garage Inc. (Disc 1)"
        ],
        [
          "Greatest Hits II"
        ],
        [
          "Greatest Kiss"
        ],
        [
          "Heart of the Night"
        ],
        [
          "International Superhits"
        ],
        [
          "Into The Light"
        ],
        [
          "Meus Momentos"
        ],
        [
          "Minha Hist\u00f3ria"
        ],
        [
          "Sambas De Enredo 2001"
        ],
        [
          "Supernatural"
        ],
        [
          "The Best of Ed Motta"
        ],
        [
          "The Essential Miles Davis [Disc 1]"
        ],
        [
          "Up An' Atom"
        ],
        [
          "Vin\u00edcius De Moraes - Sem Limite"
        ],
        [
          "Vozes do MPB"
        ],
        [
          "Chronicle, Vol. 1"
        ],
        [
          "Chronicle, Vol. 2"
        ],
        [
          "C\u00e1ssia Eller - Cole\u00e7\u00e3o Sem Limite [Disc 2]"
        ],
        [
          "C\u00e1ssia Eller - Sem Limite [Disc 1]"
        ],
        [
          "Knocking at Your Back Door: The Best Of Deep Purple in the 80's"
        ],
        [
          "Purpendicular"
        ],
        [
          "Vault: Def Leppard's Greatest Hits"
        ],
        [
          "Djavan Ao Vivo - Vol. 02"
        ],
        [
          "Djavan Ao Vivo - Vol. 1"
        ],
        [
          "Elis Regina-Minha Hist\u00f3ria"
        ],
        [
          "The Cream Of Clapton"
        ],
        [
          "Unplugged"
        ],
        [
          "Album Of The Year"
        ],
        [
          "Angel Dust"
        ],
        [
          "King For A Day Fool For A Lifetime"
        ],
        [
          "The Real Thing"
        ],
        [
          "Deixa Entrar"
        ],
        [
          "One By One"
        ],
        [
          "The Colour And The Shape"
        ],
        [
          "My Way: The Best Of Frank Sinatra [Disc 1]"
        ],
        [
          "Roda De Funk"
        ],
        [
          "As Can\u00e7\u00f5es de Eu Tu Eles"
        ],
        [
          "Quanta Gente Veio Ver (Live)"
        ],
        [
          "Faceless"
        ],
        [
          "American Idiot"
        ],
        [
          "Appetite for Destruction"
        ],
        [
          "Use Your Illusion I"
        ],
        [
          "Use Your Illusion II"
        ],
        [
          "Blue Moods"
        ],
        [
          "A Matter of Life and Death"
        ],
        [
          "A Real Dead One"
        ],
        [
          "A Real Live One"
        ],
        [
          "Dance Of Death"
        ],
        [
          "Fear Of The Dark"
        ],
        [
          "Live After Death"
        ],
        [
          "The X Factor"
        ],
        [
          "Sex Machine"
        ],
        [
          "Synkronized"
        ],
        [
          "The Return Of The Space Cowboy"
        ],
        [
          "Get Born"
        ],
        [
          "Are You Experienced?"
        ],
        [
          "Jorge Ben Jor 25 Anos"
        ],
        [
          "Jota Quest-1995"
        ],
        [
          "Cafezinho"
        ],
        [
          "Living After Midnight"
        ],
        [
          "Unplugged live"
        ],
        [
          "A TempestadeTempestade Ou O Livro Dos Dias"
        ],
        [
          "Mais Do Mesmo"
        ],
        [
          "Greatest Hits"
        ],
        [
          "Lulu Santos - RCA 100 Anos De M\u00fasica - \u00c1lbum 01"
        ],
        [
          "Lulu Santos - RCA 100 Anos De M\u00fasica - \u00c1lbum 02"
        ],
        [
          "Barulhinho Bom"
        ],
        [
          "Seek And Shall Find: More Of The Best (1963-1981)"
        ],
        [
          "Black Album"
        ],
        [
          "Garage Inc. (Disc 2)"
        ],
        [
          "Load"
        ],
        [
          "ReLoad"
        ],
        [
          "St. Anger"
        ],
        [
          "Miles Ahead"
        ],
        [
          "Milton Nascimento Ao Vivo"
        ],
        [
          "Minas"
        ],
        [
          "Ace Of Spades"
        ],
        [
          "Demorou..."
        ],
        [
          "Motley Crue Greatest Hits"
        ],
        [
          "From The Muddy Banks Of The Wishkah live"
        ],
        [
          "Nevermind"
        ],
        [
          "Compositores"
        ],
        [
          "Olodum"
        ],
        [
          "Ac\u00fastico MTV"
        ],
        [
          "Arquivo II"
        ],
        [
          "Arquivo Os Paralamas Do Sucesso"
        ],
        [
          "Tribute"
        ],
        [
          "Walking Into Clarksdale"
        ],
        [
          "Original Soundtracks 1"
        ],
        [
          "Live On Two Legs live"
        ],
        [
          "Pearl Jam"
        ],
        [
          "Riot Act"
        ],
        [
          "Ten"
        ],
        [
          "Vs."
        ],
        [
          "Os C\u00e3es Ladram Mas A Caravana N\u00e3o P\u00e1ra"
        ],
        [
          "Greatest Hits I"
        ],
        [
          "News Of The World"
        ],
        [
          "Out Of Time"
        ],
        [
          "Green"
        ],
        [
          "New Adventures In Hi-Fi"
        ],
        [
          "The Best Of R.E.M.: The IRS Years"
        ],
        [
          "Raul Seixas"
        ],
        [
          "Blood Sugar Sex Magik"
        ],
        [
          "By The Way"
        ],
        [
          "Californication"
        ],
        [
          "Retrospective I (1974-1980)"
        ],
        [
          "Maquinarama"
        ],
        [
          "O Samba Pocon\u00e9"
        ],
        [
          "Judas 0: B-Sides and Rarities"
        ],
        [
          "Rotten Apples: Greatest Hits"
        ],
        [
          "A-Sides"
        ],
        [
          "Core"
        ],
        [
          "Mezmerize"
        ],
        [
          "The Singles"
        ],
        [
          "Beyond Good And Evil"
        ],
        [
          "Pure Cult: The Best Of The Cult (For Rockers, Ravers, Lovers & Sinners) UK"
        ],
        [
          "The Doors"
        ],
        [
          "The Police Greatest Hits"
        ],
        [
          "Hot Rocks, 1964-1971 (Disc 1)"
        ],
        [
          "No Security"
        ],
        [
          "Voodoo Lounge"
        ],
        [
          "Tangents"
        ],
        [
          "Transmission"
        ],
        [
          "My Generation - The Very Best Of The Who"
        ],
        [
          "Serie Sem Limite (Disc 1)"
        ],
        [
          "Serie Sem Limite (Disc 2)"
        ],
        [
          "Ac\u00fastico"
        ],
        [
          "Volume Dois"
        ],
        [
          "Battlestar Galactica, Season 3"
        ],
        [
          "Heroes, Season 1"
        ],
        [
          "Lost, Season 3"
        ],
        [
          "Lost, Season 1"
        ],
        [
          "Lost, Season 2"
        ],
        [
          "Achtung Baby"
        ],
        [
          "All That You Can't Leave Behind"
        ],
        [
          "B-Sides 1980-1990"
        ],
        [
          "How To Dismantle An Atomic Bomb"
        ],
        [
          "Pop"
        ],
        [
          "Rattle And Hum"
        ],
        [
          "The Best Of 1980-1990"
        ],
        [
          "UB40 The Best Of - Volume Two UK"
        ],
        [
          "Diver Down"
        ],
        [
          "The Best Of Van Halen, Vol. I"
        ],
        [
          "Van Halen"
        ],
        [
          "Van Halen III"
        ],
        [
          "Contraband"
        ],
        [
          "Vinicius De Moraes"
        ],
        [
          "Ao Vivo IMPORT"
        ],
        [
          "The Office, Season 2"
        ],
        [
          "The Office, Season 3"
        ],
        [
          "Battlestar Galactica (Classic), Season 1"
        ],
        [
          "Instant Karma: The Amnesty International Campaign to Save Darfur"
        ],
        [
          "Speak of the Devil"
        ],
        [
          "20th Century Masters - The Millennium Collection: The Best of Scorpions"
        ],
        [
          "House of Pain"
        ],
        [
          "Radio Brasil (O Som da Jovem Vanguarda) - Seleccao de Henrique Amaro"
        ],
        [
          "LOST, Season 4"
        ],
        [
          "Carry On"
        ],
        [
          "Revelations"
        ],
        [
          "Back to Black"
        ],
        [
          "Frank"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('id').size().rename('count')\nanswer = albums[albums['id'].isin(t2[t2 > 10].index)]['title']",
      "t1 = pd.merge(albums, tracks, on='album_id')\nt2 = t1.groupby(['album_id', 'title']).size().rename('count').to_frame().reset_index()\nanswer = t2[t2['count'] > 10][['title']]",
      "t1 = pd.merge(albums, tracks, on='album_id')\nt2 = t1.groupby('title').size().rename('count').to_frame().reset_index()\nanswer = t2[t2['count'] > 10]['title']",
      "t1 = pd.merge(tracks, albums, on='album_id')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title']",
      "t1 = pd.merge(albums, tracks, on='id')\nt2 = t1.groupby('title').size().rename('count')\nt3 = t2[t2 > 10].to_frame().reset_index()\nanswer = t3['title']",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('id').size()\nanswer = albums[albums['id'].isin(t2[t2 > 10].index)]['title']",
      "t1 = pd.merge(albums, tracks, on='id').groupby(['album_id', 'title']).size().rename('count')\nanswer = t1[t1 > 10].to_frame().reset_index()",
      "t1 = pd.merge(albums, tracks, on='album_id')\nt2 = t1.groupby(['title', 'album_id']).size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title'].unique()",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('album_id').size().rename('count')\nt3 = pd.merge(t2, albums, left_on='album_id', right_on='id')\nanswer = t3[t3['count'] > 10]['title']",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id').groupby('id').size().rename('count')\nanswer = albums[albums['id'].isin(t1[t1 > 10].index)]['title']",
      "t1 = pd.merge(albums, tracks, on='id')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()",
      "t1 = pd.merge(albums, tracks, on='id', how='left')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title']",
      "t1 = pd.merge(albums, tracks, on='album_id')\nt2 = t1.groupby('id').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('id').size().rename('count')\nt3 = t2[t2 > 10].to_frame().reset_index()\nt4 = pd.merge(t3, albums, left_on='id', right_on='id')[['title']]\nanswer = t4['title']",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('id').size().rename('count')\nanswer = albums[albums['id'].isin(t2[t2 > 10].index)]['title']",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title']",
      "t1 = pd.merge(albums, tracks, on='id')\nt2 = t1.groupby('title').size()\nanswer = t2[t2 > 10].to_frame().reset_index()['title']",
      "t1 = pd.merge(albums, tracks, left_on='id', right_on='album_id')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title']",
      "t1 = pd.merge(albums, tracks, on='id')\nt2 = t1.groupby('title').size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()",
      "t1 = pd.merge(albums, tracks, on='album_id')\nt2 = t1.groupby(['album_id', 'title']).size().rename('count')\nanswer = t2[t2 > 10].to_frame().reset_index()['title']"
    ],
    "acc@20": 1,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "perpetrator",
      "query": "SELECT T1.Name FROM people AS T1 JOIN perpetrator AS T2 ON T1.People_ID  =  T2.People_ID",
      "query_toks": [
        "SELECT",
        "T1.Name",
        "FROM",
        "people",
        "AS",
        "T1",
        "JOIN",
        "perpetrator",
        "AS",
        "T2",
        "ON",
        "T1.People_ID",
        "=",
        "T2.People_ID"
      ],
      "query_toks_no_value": [
        "select",
        "t1",
        ".",
        "name",
        "from",
        "people",
        "as",
        "t1",
        "join",
        "perpetrator",
        "as",
        "t2",
        "on",
        "t1",
        ".",
        "people_id",
        "=",
        "t2",
        ".",
        "people_id"
      ],
      "question": "What are the names of perpetrators?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "perpetrators",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ],
            [
              "table_unit",
              0
            ]
          ],
          "conds": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  9,
                  false
                ],
                null
              ],
              [
                0,
                2,
                false
              ],
              null
            ]
          ]
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  10,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "perpetrator": [
          "Perpetrator_ID",
          "People_ID",
          "Date",
          "Year",
          "Location",
          "Country",
          "Killed",
          "Injured"
        ],
        "people": [
          "People_ID",
          "Name",
          "Height",
          "Weight",
          "Home Town"
        ]
      },
      "answer": [
        [
          "Ron Baxter"
        ],
        [
          "Tyrone Brayan"
        ],
        [
          "Rob Cunningham"
        ],
        [
          "Ovie Dotson"
        ],
        [
          "Henry Johnson"
        ]
      ]
    },
    "generated_programs": [
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1['name'].unique()",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "answer = pd.merge(people, perpetrator, on='people_id')['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name'].unique()",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1[['name']]",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1['name']",
      "t1 = pd.merge(perpetrator, people, on='people_id')\nanswer = t1['name']",
      "answer = pd.merge(people, perpetrator, on='people_id')['name']",
      "t1 = pd.merge(people, perpetrator, on='people_id')\nanswer = t1[['name']]",
      "t1 = pd.merge(people, perpetrator, left_on='people_id', right_on='people_id')\nanswer = t1['name']"
    ],
    "acc@20": 20,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "device",
      "query": "SELECT Shop_Name FROM shop ORDER BY Open_Year ASC",
      "query_toks": [
        "SELECT",
        "Shop_Name",
        "FROM",
        "shop",
        "ORDER",
        "BY",
        "Open_Year",
        "ASC"
      ],
      "query_toks_no_value": [
        "select",
        "shop_name",
        "from",
        "shop",
        "order",
        "by",
        "open_year",
        "asc"
      ],
      "question": "What are the names of shops in ascending order of open year?",
      "question_toks": [
        "What",
        "are",
        "the",
        "names",
        "of",
        "shops",
        "in",
        "ascending",
        "order",
        "of",
        "open",
        "year",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              1
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  8,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [],
        "groupBy": [],
        "having": [],
        "orderBy": [
          "asc",
          [
            [
              0,
              [
                0,
                11,
                false
              ],
              null
            ]
          ]
        ],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "device": [
          "Device_ID",
          "Device",
          "Carrier",
          "Package_Version",
          "Applications",
          "Software_Platform"
        ],
        "shop": [
          "Shop_ID",
          "Shop_Name",
          "Location",
          "Open_Date",
          "Open_Year"
        ],
        "stock": [
          "Shop_ID",
          "Device_ID",
          "Quantity"
        ]
      },
      "answer": [
        [
          "Best Buy"
        ],
        [
          "Tynewydd repair"
        ],
        [
          "Ferndale"
        ],
        [
          "Apple"
        ],
        [
          "Dinas store"
        ],
        [
          "Naval repair"
        ],
        [
          "Pentre store"
        ],
        [
          "Gelli repair"
        ],
        [
          "Dinas Device"
        ],
        [
          "Naval's shop"
        ],
        [
          "ATnT"
        ],
        [
          "National Cellphone"
        ]
      ]
    },
    "generated_programs": [
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop.sort_values('open_year')[['shop_name']]",
      "answer = shop['shop_name'].sort_values('open_year')",
      "answer = shop[['shop_name']].sort_values('open_year', ascending=True)",
      "answer = shop[['shop_name']].sort_values('open_year', ascending = True)",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop['shop_name'].sort_values(ascending=True)",
      "answer = shop.sort_values('open_year')[['shop_name']]",
      "answer = shop[['shop_name']].sort_values('open_year', ascending=True)",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop.sort_values('open_year')[['shop_name']]",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop[['shop_name']].sort_values('open_year').reset_index(drop=True)",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "t1 = shop.sort_values('open_year', ascending=True)\nanswer = t1['shop_name']",
      "answer = shop['shop_name'].sort_values(ascending = True)",
      "t1 = shop[['shop_name', 'open_year']]\nanswer = t1.sort_values('open_year', ascending=True)",
      "answer = shop[['shop_name']].sort_values('open_year')",
      "answer = shop[['shop_name']]"
    ],
    "acc@20": 4,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "college_3",
      "query": "SELECT count(*) FROM DEPARTMENT WHERE Division  =  \"AS\"",
      "query_toks": [
        "SELECT",
        "count",
        "(",
        "*",
        ")",
        "FROM",
        "DEPARTMENT",
        "WHERE",
        "Division",
        "=",
        "``",
        "AS",
        "''"
      ],
      "query_toks_no_value": [
        "select",
        "count",
        "(",
        "*",
        ")",
        "from",
        "department",
        "where",
        "division",
        "=",
        "value"
      ],
      "question": "How many departments are in the division AS?",
      "question_toks": [
        "How",
        "many",
        "departments",
        "are",
        "in",
        "the",
        "division",
        "AS",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              2
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              3,
              [
                0,
                [
                  0,
                  0,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                18,
                false
              ],
              null
            ],
            "\"AS\"",
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": null,
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "Student": [
          "StuID",
          "LName",
          "Fname",
          "Age",
          "Sex",
          "Major",
          "Advisor",
          "city_code"
        ],
        "Faculty": [
          "FacID",
          "Lname",
          "Fname",
          "Rank",
          "Sex",
          "Phone",
          "Room",
          "Building"
        ],
        "Department": [
          "DNO",
          "Division",
          "DName",
          "Room",
          "Building",
          "DPhone"
        ],
        "Member_of": [
          "FacID",
          "DNO",
          "Appt_Type"
        ],
        "Course": [
          "CID",
          "CName",
          "Credits",
          "Instructor",
          "Days",
          "Hours",
          "DNO"
        ],
        "Minor_in": [
          "StuID",
          "DNO"
        ],
        "Enrolled_in": [
          "StuID",
          "CID",
          "Grade"
        ],
        "Gradeconversion": [
          "lettergrade",
          "gradepoint"
        ]
      },
      "answer": [
        [
          19
        ]
      ]
    },
    "generated_programs": [
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'as'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "t1 = Department[Department['division'] == 'as']\nanswer = t1['dno'].unique().size",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = Department[Department['division'] == 'AS'].shape[0]",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "answer = pd.Series(Department[Department['division'] == 'AS'].shape[0])",
      "t1 = Department[Department['division'] == 'AS']\nanswer = pd.Series(t1.shape[0])"
    ],
    "acc@20": 18,
    "pass@20": 1.0
  },
  {
    "example": {
      "db_id": "culture_company",
      "query": "SELECT publisher FROM book_club WHERE YEAR  =  1989 INTERSECT SELECT publisher FROM book_club WHERE YEAR  =  1990",
      "query_toks": [
        "SELECT",
        "publisher",
        "FROM",
        "book_club",
        "WHERE",
        "YEAR",
        "=",
        "1989",
        "INTERSECT",
        "SELECT",
        "publisher",
        "FROM",
        "book_club",
        "WHERE",
        "YEAR",
        "=",
        "1990"
      ],
      "query_toks_no_value": [
        "select",
        "publisher",
        "from",
        "book_club",
        "where",
        "year",
        "=",
        "value",
        "intersect",
        "select",
        "publisher",
        "from",
        "book_club",
        "where",
        "year",
        "=",
        "value"
      ],
      "question": "What are the publishers who have published a book in both 1989 and 1990?",
      "question_toks": [
        "What",
        "are",
        "the",
        "publishers",
        "who",
        "have",
        "published",
        "a",
        "book",
        "in",
        "both",
        "1989",
        "and",
        "1990",
        "?"
      ],
      "sql": {
        "from": {
          "table_units": [
            [
              "table_unit",
              0
            ]
          ],
          "conds": []
        },
        "select": [
          false,
          [
            [
              0,
              [
                0,
                [
                  0,
                  5,
                  false
                ],
                null
              ]
            ]
          ]
        ],
        "where": [
          [
            false,
            2,
            [
              0,
              [
                0,
                2,
                false
              ],
              null
            ],
            1989.0,
            null
          ]
        ],
        "groupBy": [],
        "having": [],
        "orderBy": [],
        "limit": null,
        "intersect": {
          "from": {
            "table_units": [
              [
                "table_unit",
                0
              ]
            ],
            "conds": []
          },
          "select": [
            false,
            [
              [
                0,
                [
                  0,
                  [
                    0,
                    5,
                    false
                  ],
                  null
                ]
              ]
            ]
          ],
          "where": [
            [
              false,
              2,
              [
                0,
                [
                  0,
                  2,
                  false
                ],
                null
              ],
              1990.0,
              null
            ]
          ],
          "groupBy": [],
          "having": [],
          "orderBy": [],
          "limit": null,
          "intersect": null,
          "union": null,
          "except": null
        },
        "union": null,
        "except": null
      },
      "db_table_headers": {
        "book_club": [
          "book_club_id",
          "Year",
          "Author_or_Editor",
          "Book_Title",
          "Publisher",
          "Category",
          "Result"
        ],
        "movie": [
          "movie_id",
          "Title",
          "Year",
          "Director",
          "Budget_million",
          "Gross_worldwide"
        ],
        "culture_company": [
          "Company_name",
          "Type",
          "Incorporated_in",
          "Group_Equity_Shareholding",
          "book_club_id",
          "movie_id"
        ]
      },
      "answer": [
        [
          "Alyson"
        ],
        [
          "Banned Books"
        ]
      ]
    },
    "generated_programs": [
      "t1 = book_club[book_club['year'] == 1989]\nt2 = book_club[book_club['year'] == 1990]\nanswer = t1['publisher'].merge(t2['publisher'], how='inner')",
      "t1 = book_club[book_club['year'] == 1989]\nt2 = book_club[book_club['year'] == 1990]\nt3 = pd.merge(t1, t2, on='publisher', how='inner')\nanswer = t3['publisher'].unique()",
      "t1 = book_club[book_club['year'] == 1989][['publisher']].rename('publisher_1989')\nt2 = book_club[book_club['year'] == 1990][['publisher']].rename('publisher_1990')\nt3 = pd.merge(t1, t2, how='inner')\nanswer = t3['publisher_1989']",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1.isin(t2)",
      "year1989 = book_club[book_club['year'] == 1989].groupby('publisher').size().rename('count')\nyear1990 = book_club[book_club['year'] == 1990].groupby('publisher').size().rename('count')\nanswer = year1990.loc[year1989.index[year1989 > 0]].index.values",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2)]",
      "t1 = book_club[book_club['year'] == 1989]\nt2 = book_club[book_club['year'] == 1990]\nanswer = pd.merge(t1, t2, on='publisher')['publisher'].unique()",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2)]",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2)]",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = pd.Series(list(set(t1).intersection(t2)))",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nt3 = t1[t1.isin(t2)]\nanswer = t3.drop_duplicates()",
      "t1 = book_club[book_club['year'] == 1989]\nt2 = book_club[book_club['year'] == 1990]\nanswer = pd.Series(t1['publisher'].isin(t2['publisher']).astype(int).sum())",
      "t1 = book_club[book_club['year'] == 1989].reset_index()[['index','publisher']]\nt2 = book_club[book_club['year'] == 1990].reset_index()[['index','publisher']]\nanswer = pd.merge(t1, t2, on=['publisher']).drop(columns='index_x')",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2)]",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = pd.merge(t1, t2, on='publisher')",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nt3 = np.intersect1d(t1, t2)\nanswer = pd.Series(t3)",
      "t1 = book_club[book_club['year'] == 1989]['publisher'].unique()\nt2 = book_club[book_club['year'] == 1990]['publisher'].unique()\nanswer = np.intersect1d(t1, t2)",
      "t1 = book_club[book_club['year'] == 1989][['publisher']]\nt2 = book_club[book_club['year'] == 1990][['publisher']]\nt3 = pd.merge(t1, t2, on='publisher')\nanswer = t3['publisher']",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2.unique())].unique()",
      "t1 = book_club[book_club['year'] == 1989]['publisher']\nt2 = book_club[book_club['year'] == 1990]['publisher']\nanswer = t1[t1.isin(t2)].unique()"
    ],
    "acc@20": 6,
    "pass@20": 1.0
  }
]